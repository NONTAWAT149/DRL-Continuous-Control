{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NONTAWAT149/DRL-Continuous-Control/blob/main/SETTrading_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abeQ_9pMLz2m"
      },
      "source": [
        "The idea of trading algorithm is from \"Python for Algorithmic Trading\" - O'Reilly 2021 (page 162)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oAxmQrsNqt3t"
      },
      "source": [
        "#### 1. Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8NiLnMuQSbd",
        "outputId": "4764b6e6-ccd5-4231-9d18-e069c77d2424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 11775253686338188030\n",
            "xla_global_id: -1\n",
            ", name: \"/device:GPU:0\"\n",
            "device_type: \"GPU\"\n",
            "memory_limit: 14626652160\n",
            "locality {\n",
            "  bus_id: 1\n",
            "  links {\n",
            "  }\n",
            "}\n",
            "incarnation: 10383230313109506723\n",
            "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\"\n",
            "xla_global_id: 416903419\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "print(device_lib.list_local_devices())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sKPLiPe7aJLa"
      },
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkRD37sarBRx"
      },
      "source": [
        "#### 2. Import Data and Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MCBRr0Sqkl-Z"
      },
      "outputs": [],
      "source": [
        "# import data\n",
        "\n",
        "df = pd.read_csv('setth_dataset.csv', index_col = 'Date')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df[df['ticker'] == 'SCB.BK']"
      ],
      "metadata": {
        "id": "ZMagSpWTRIOv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "7sdBfQB8GZF8",
        "outputId": "cd4c2b4f-c2ac-41f6-f0aa-3c89781019fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Close    Volume    return     lag_1     lag_2     lag_3  \\\n",
              "Date                                                                     \n",
              "2023-04-26  0.496309 -0.568551  0.790396 -2.196122  0.033924  0.035978   \n",
              "2023-04-27  0.674156 -0.338104  1.149153  0.788679 -2.196122  0.035978   \n",
              "2023-04-28  0.792720 -0.214725  0.762005  1.144563  0.788679 -2.195190   \n",
              "2023-05-02  0.614874 -0.504826 -1.073276  0.760515  1.144563  0.791112   \n",
              "2023-05-03  0.792720 -0.311945  1.132374 -1.060071  0.760515  1.147176   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2024-03-25 -0.310658 -0.442654 -0.242062 -0.007209  0.458152  0.221422   \n",
              "2024-03-26 -0.310658 -1.369240 -0.010728 -0.238835 -0.005993  0.454131   \n",
              "2024-03-27 -0.375093 -0.341047 -0.243028 -0.007209 -0.237582 -0.014231   \n",
              "2024-03-28 -0.375093 -1.369240 -0.010728 -0.239803 -0.005993 -0.247924   \n",
              "2024-03-29 -0.439528 -0.666753 -0.244002 -0.007209 -0.238549 -0.014231   \n",
              "\n",
              "               lag_4     lag_5     lag_6     lag_7     lag_8     lag_9  \\\n",
              "Date                                                                     \n",
              "2023-04-26 -1.034493 -0.655546  0.051037  0.397614 -0.309370  0.042895   \n",
              "2023-04-27  0.041080 -1.029527 -0.657899  0.043230  0.399234 -0.311531   \n",
              "2023-04-28  0.041080  0.053137 -1.032013 -0.668113  0.044932  0.397320   \n",
              "2023-05-02 -2.184263  0.053137  0.051037 -1.043497 -0.666249  0.042895   \n",
              "2023-05-03  0.794243 -2.186876  0.051037  0.043230 -1.041547 -0.668534   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2024-03-25 -0.252094 -0.489695 -0.017661  0.211554  0.211103 -0.029594   \n",
              "2024-03-26  0.218634 -0.256285 -0.487666 -0.023451  0.210123  0.206004   \n",
              "2024-03-27  0.451058  0.216442 -0.254140 -0.494443 -0.024773  0.205025   \n",
              "2024-03-28 -0.016730  0.449853  0.218819 -0.260427 -0.495546 -0.029594   \n",
              "2024-03-29 -0.250137 -0.019921  0.452345  0.213525 -0.261639 -0.499811   \n",
              "\n",
              "              lag_10  momentum  volatility  distance      data_type  ticker  \\\n",
              "Date                                                                          \n",
              "2023-04-26  0.400361 -1.115264    0.599902 -1.050739  training_data  AAV.BK   \n",
              "2023-04-27  0.045378 -0.089248    0.956138 -0.415456  training_data  AAV.BK   \n",
              "2023-04-28 -0.309605  0.251396    1.085820  0.008064  training_data  AAV.BK   \n",
              "2023-05-02  0.400361 -0.261496    1.345064 -0.477739  training_data  AAV.BK   \n",
              "2023-05-03  0.045378  1.296897   -0.030793  0.120172  training_data  AAV.BK   \n",
              "...              ...       ...         ...       ...            ...     ...   \n",
              "2024-03-25 -0.265055  0.089975   -1.430363  0.113490   testing_data  WHA.BK   \n",
              "2024-03-26 -0.029465  0.208078   -1.518772  0.037401   testing_data  WHA.BK   \n",
              "2024-03-27  0.206125 -0.027635   -1.473673 -0.143309   testing_data  WHA.BK   \n",
              "2024-03-28  0.205146 -0.262365   -1.835529 -0.171842   testing_data  WHA.BK   \n",
              "2024-03-29 -0.029465 -0.380468   -1.834912 -0.295486   testing_data  WHA.BK   \n",
              "\n",
              "            direction  \n",
              "Date                   \n",
              "2023-04-26          1  \n",
              "2023-04-27          1  \n",
              "2023-04-28          0  \n",
              "2023-05-02          1  \n",
              "2023-05-03          1  \n",
              "...               ...  \n",
              "2024-03-25          0  \n",
              "2024-03-26          0  \n",
              "2024-03-27          0  \n",
              "2024-03-28          0  \n",
              "2024-03-29          0  \n",
              "\n",
              "[22572 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb5b0291-ad7b-4416-972d-d07ea5839e7d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>return</th>\n",
              "      <th>lag_1</th>\n",
              "      <th>lag_2</th>\n",
              "      <th>lag_3</th>\n",
              "      <th>lag_4</th>\n",
              "      <th>lag_5</th>\n",
              "      <th>lag_6</th>\n",
              "      <th>lag_7</th>\n",
              "      <th>lag_8</th>\n",
              "      <th>lag_9</th>\n",
              "      <th>lag_10</th>\n",
              "      <th>momentum</th>\n",
              "      <th>volatility</th>\n",
              "      <th>distance</th>\n",
              "      <th>data_type</th>\n",
              "      <th>ticker</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-04-26</th>\n",
              "      <td>0.496309</td>\n",
              "      <td>-0.568551</td>\n",
              "      <td>0.790396</td>\n",
              "      <td>-2.196122</td>\n",
              "      <td>0.033924</td>\n",
              "      <td>0.035978</td>\n",
              "      <td>-1.034493</td>\n",
              "      <td>-0.655546</td>\n",
              "      <td>0.051037</td>\n",
              "      <td>0.397614</td>\n",
              "      <td>-0.309370</td>\n",
              "      <td>0.042895</td>\n",
              "      <td>0.400361</td>\n",
              "      <td>-1.115264</td>\n",
              "      <td>0.599902</td>\n",
              "      <td>-1.050739</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-27</th>\n",
              "      <td>0.674156</td>\n",
              "      <td>-0.338104</td>\n",
              "      <td>1.149153</td>\n",
              "      <td>0.788679</td>\n",
              "      <td>-2.196122</td>\n",
              "      <td>0.035978</td>\n",
              "      <td>0.041080</td>\n",
              "      <td>-1.029527</td>\n",
              "      <td>-0.657899</td>\n",
              "      <td>0.043230</td>\n",
              "      <td>0.399234</td>\n",
              "      <td>-0.311531</td>\n",
              "      <td>0.045378</td>\n",
              "      <td>-0.089248</td>\n",
              "      <td>0.956138</td>\n",
              "      <td>-0.415456</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-28</th>\n",
              "      <td>0.792720</td>\n",
              "      <td>-0.214725</td>\n",
              "      <td>0.762005</td>\n",
              "      <td>1.144563</td>\n",
              "      <td>0.788679</td>\n",
              "      <td>-2.195190</td>\n",
              "      <td>0.041080</td>\n",
              "      <td>0.053137</td>\n",
              "      <td>-1.032013</td>\n",
              "      <td>-0.668113</td>\n",
              "      <td>0.044932</td>\n",
              "      <td>0.397320</td>\n",
              "      <td>-0.309605</td>\n",
              "      <td>0.251396</td>\n",
              "      <td>1.085820</td>\n",
              "      <td>0.008064</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-02</th>\n",
              "      <td>0.614874</td>\n",
              "      <td>-0.504826</td>\n",
              "      <td>-1.073276</td>\n",
              "      <td>0.760515</td>\n",
              "      <td>1.144563</td>\n",
              "      <td>0.791112</td>\n",
              "      <td>-2.184263</td>\n",
              "      <td>0.053137</td>\n",
              "      <td>0.051037</td>\n",
              "      <td>-1.043497</td>\n",
              "      <td>-0.666249</td>\n",
              "      <td>0.042895</td>\n",
              "      <td>0.400361</td>\n",
              "      <td>-0.261496</td>\n",
              "      <td>1.345064</td>\n",
              "      <td>-0.477739</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-03</th>\n",
              "      <td>0.792720</td>\n",
              "      <td>-0.311945</td>\n",
              "      <td>1.132374</td>\n",
              "      <td>-1.060071</td>\n",
              "      <td>0.760515</td>\n",
              "      <td>1.147176</td>\n",
              "      <td>0.794243</td>\n",
              "      <td>-2.186876</td>\n",
              "      <td>0.051037</td>\n",
              "      <td>0.043230</td>\n",
              "      <td>-1.041547</td>\n",
              "      <td>-0.668534</td>\n",
              "      <td>0.045378</td>\n",
              "      <td>1.296897</td>\n",
              "      <td>-0.030793</td>\n",
              "      <td>0.120172</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-25</th>\n",
              "      <td>-0.310658</td>\n",
              "      <td>-0.442654</td>\n",
              "      <td>-0.242062</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>0.458152</td>\n",
              "      <td>0.221422</td>\n",
              "      <td>-0.252094</td>\n",
              "      <td>-0.489695</td>\n",
              "      <td>-0.017661</td>\n",
              "      <td>0.211554</td>\n",
              "      <td>0.211103</td>\n",
              "      <td>-0.029594</td>\n",
              "      <td>-0.265055</td>\n",
              "      <td>0.089975</td>\n",
              "      <td>-1.430363</td>\n",
              "      <td>0.113490</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-26</th>\n",
              "      <td>-0.310658</td>\n",
              "      <td>-1.369240</td>\n",
              "      <td>-0.010728</td>\n",
              "      <td>-0.238835</td>\n",
              "      <td>-0.005993</td>\n",
              "      <td>0.454131</td>\n",
              "      <td>0.218634</td>\n",
              "      <td>-0.256285</td>\n",
              "      <td>-0.487666</td>\n",
              "      <td>-0.023451</td>\n",
              "      <td>0.210123</td>\n",
              "      <td>0.206004</td>\n",
              "      <td>-0.029465</td>\n",
              "      <td>0.208078</td>\n",
              "      <td>-1.518772</td>\n",
              "      <td>0.037401</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-27</th>\n",
              "      <td>-0.375093</td>\n",
              "      <td>-0.341047</td>\n",
              "      <td>-0.243028</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>-0.237582</td>\n",
              "      <td>-0.014231</td>\n",
              "      <td>0.451058</td>\n",
              "      <td>0.216442</td>\n",
              "      <td>-0.254140</td>\n",
              "      <td>-0.494443</td>\n",
              "      <td>-0.024773</td>\n",
              "      <td>0.205025</td>\n",
              "      <td>0.206125</td>\n",
              "      <td>-0.027635</td>\n",
              "      <td>-1.473673</td>\n",
              "      <td>-0.143309</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-28</th>\n",
              "      <td>-0.375093</td>\n",
              "      <td>-1.369240</td>\n",
              "      <td>-0.010728</td>\n",
              "      <td>-0.239803</td>\n",
              "      <td>-0.005993</td>\n",
              "      <td>-0.247924</td>\n",
              "      <td>-0.016730</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.218819</td>\n",
              "      <td>-0.260427</td>\n",
              "      <td>-0.495546</td>\n",
              "      <td>-0.029594</td>\n",
              "      <td>0.205146</td>\n",
              "      <td>-0.262365</td>\n",
              "      <td>-1.835529</td>\n",
              "      <td>-0.171842</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-29</th>\n",
              "      <td>-0.439528</td>\n",
              "      <td>-0.666753</td>\n",
              "      <td>-0.244002</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>-0.238549</td>\n",
              "      <td>-0.014231</td>\n",
              "      <td>-0.250137</td>\n",
              "      <td>-0.019921</td>\n",
              "      <td>0.452345</td>\n",
              "      <td>0.213525</td>\n",
              "      <td>-0.261639</td>\n",
              "      <td>-0.499811</td>\n",
              "      <td>-0.029465</td>\n",
              "      <td>-0.380468</td>\n",
              "      <td>-1.834912</td>\n",
              "      <td>-0.295486</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22572 rows Ã— 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb5b0291-ad7b-4416-972d-d07ea5839e7d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb5b0291-ad7b-4416-972d-d07ea5839e7d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb5b0291-ad7b-4416-972d-d07ea5839e7d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-69c6e503-e6cb-4743-84ca-c6b21c6a0778\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-69c6e503-e6cb-4743-84ca-c6b21c6a0778')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-69c6e503-e6cb-4743-84ca-c6b21c6a0778 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 22572,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 228,\n        \"samples\": [\n          \"2024-03-13\",\n          \"2023-08-04\",\n          \"2023-05-12\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0405541444275745,\n        \"min\": -4.280754284999186,\n        \"max\": 3.485668593310419,\n        \"num_unique_values\": 5718,\n        \"samples\": [\n          1.4962932278474936,\n          -1.3579565276070684,\n          -0.1019887700524674\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0334950504642957,\n        \"min\": -2.101378932526864,\n        \"max\": 25.17911450842402,\n        \"num_unique_values\": 22151,\n        \"samples\": [\n          -0.8060697119649951,\n          1.5917304601020914,\n          -1.0939841319379269\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.987428790696371,\n        \"min\": -8.413393306038094,\n        \"max\": 7.117412791048348,\n        \"num_unique_values\": 14927,\n        \"samples\": [\n          0.4801362859994414,\n          0.9902247562191416,\n          -1.7762359739524949\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9900234443677416,\n        \"min\": -8.413393306038094,\n        \"max\": 7.11375890630616,\n        \"num_unique_values\": 14939,\n        \"samples\": [\n          -0.4195285205098844,\n          2.038201718633188,\n          -1.0198400475794034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9927038722584213,\n        \"min\": -8.399542828418474,\n        \"max\": 7.113185871000301,\n        \"num_unique_values\": 14988,\n        \"samples\": [\n          -0.1629203508118709,\n          -0.1884175481048029,\n          -0.5872062822214827\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9929203761981251,\n        \"min\": -9.89085226140396,\n        \"max\": 7.099775191443252,\n        \"num_unique_values\": 15005,\n        \"samples\": [\n          0.8413222228797372,\n          -0.9140795824494634,\n          -0.6059610465042778\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9952676195799819,\n        \"min\": -9.89085226140396,\n        \"max\": 7.006161247077795,\n        \"num_unique_values\": 15049,\n        \"samples\": [\n          0.5751393985361027,\n          -0.2814445288060384,\n          1.1168939316437696\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9939049215452828,\n        \"min\": -9.78127756288272,\n        \"max\": 6.967883239276386,\n        \"num_unique_values\": 15039,\n        \"samples\": [\n          -0.1576101033540118,\n          -0.6041364708926406,\n          0.7692190668779072\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9979652323529935,\n        \"min\": -9.798970122266969,\n        \"max\": 6.9719700753050615,\n        \"num_unique_values\": 15103,\n        \"samples\": [\n          0.3364321202774982,\n          0.9635212849592784,\n          0.4973216775749187\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9969434861705225,\n        \"min\": -9.79674377203502,\n        \"max\": 6.877629820502031,\n        \"num_unique_values\": 15099,\n        \"samples\": [\n          2.474622685211953,\n          0.6390932252207768,\n          0.4941564842491057\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9988998401722258,\n        \"min\": -9.792054618243814,\n        \"max\": 6.87959171713569,\n        \"num_unique_values\": 15130,\n        \"samples\": [\n          -0.2776297938776998,\n          0.3521291600199592,\n          0.8723679092210829\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9992306501297077,\n        \"min\": -9.802937349346353,\n        \"max\": 6.876095977688038,\n        \"num_unique_values\": 15128,\n        \"samples\": [\n          -0.7115610896220631,\n          -0.7047553579053536,\n          0.3532475975686145\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9985115344529925,\n        \"min\": -9.803714807047214,\n        \"max\": 6.876327806398884,\n        \"num_unique_values\": 15124,\n        \"samples\": [\n          -0.7120430242953697,\n          -0.3301127763278724,\n          -0.7341595687994281\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"momentum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9909143763944982,\n        \"min\": -6.013153654784603,\n        \"max\": 4.541327205250273,\n        \"num_unique_values\": 21448,\n        \"samples\": [\n          -0.052678809133154,\n          0.4024061562891148,\n          -1.256067608397864\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0107166322327128,\n        \"min\": -2.694655793728232,\n        \"max\": 8.11699345470993,\n        \"num_unique_values\": 21570,\n        \"samples\": [\n          -0.9535310094167712,\n          -1.209481987247739,\n          0.698275070735871\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9833063722353672,\n        \"min\": -5.020211999896247,\n        \"max\": 4.39989721279479,\n        \"num_unique_values\": 19569,\n        \"samples\": [\n          2.0338593130776044,\n          -2.5237690566349618,\n          -2.011872413352496\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"testing_data\",\n          \"training_data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"OSP.BK\",\n          \"GULF.BK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"direction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "feature_name = list(df.columns)"
      ],
      "metadata": {
        "id": "cf_8rPd4KLeX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_name.remove('data_type')\n",
        "feature_name.remove('ticker')\n",
        "feature_name.remove('direction')\n",
        "#feature_name.remove('Volume')"
      ],
      "metadata": {
        "id": "uXmG6WPvLWfe"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RIdCpLnLe5p",
        "outputId": "8d98879e-b06e-427a-cc8a-a6d72475017c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Close',\n",
              " 'Volume',\n",
              " 'return',\n",
              " 'lag_1',\n",
              " 'lag_2',\n",
              " 'lag_3',\n",
              " 'lag_4',\n",
              " 'lag_5',\n",
              " 'lag_6',\n",
              " 'lag_7',\n",
              " 'lag_8',\n",
              " 'lag_9',\n",
              " 'lag_10',\n",
              " 'momentum',\n",
              " 'volatility',\n",
              " 'distance']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jg7LkHxHrZwI"
      },
      "source": [
        "#### 4. Experiment with Deep Learning"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EmvOSem7KGqp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8UAoaEySw6v6"
      },
      "outputs": [],
      "source": [
        "training_data = df[df['data_type'] == 'training_data']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testing_data = df[df['data_type'] == 'testing_data']"
      ],
      "metadata": {
        "id": "9dECLIzJLuFq"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "s4mVP4v-LuIU",
        "outputId": "012787f5-03f8-484d-aa1b-6f53eaa74303"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Close    Volume    return     lag_1     lag_2     lag_3  \\\n",
              "Date                                                                     \n",
              "2023-04-26  0.496309 -0.568551  0.790396 -2.196122  0.033924  0.035978   \n",
              "2023-04-27  0.674156 -0.338104  1.149153  0.788679 -2.196122  0.035978   \n",
              "2023-04-28  0.792720 -0.214725  0.762005  1.144563  0.788679 -2.195190   \n",
              "2023-05-02  0.614874 -0.504826 -1.073276  0.760515  1.144563  0.791112   \n",
              "2023-05-03  0.792720 -0.311945  1.132374 -1.060071  0.760515  1.147176   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2024-02-22 -0.697270  1.290695 -1.650642  0.457012 -0.930448  0.217535   \n",
              "2024-02-23 -0.632835 -0.747718  0.226524 -1.649198  0.458152 -0.947084   \n",
              "2024-02-27 -1.148316  0.930419 -1.937699  0.230344 -1.647717  0.454131   \n",
              "2024-02-28 -1.148316 -0.012106 -0.010728 -1.936618  0.231522 -1.670869   \n",
              "2024-02-29 -0.955011  0.316111  0.719729 -0.007209 -1.935090  0.225441   \n",
              "\n",
              "               lag_4     lag_5     lag_6     lag_7     lag_8     lag_9  \\\n",
              "Date                                                                     \n",
              "2023-04-26 -1.034493 -0.655546  0.051037  0.397614 -0.309370  0.042895   \n",
              "2023-04-27  0.041080 -1.029527 -0.657899  0.043230  0.399234 -0.311531   \n",
              "2023-04-28  0.041080  0.053137 -1.032013 -0.668113  0.044932  0.397320   \n",
              "2023-05-02 -2.184263  0.053137  0.051037 -1.043497 -0.666249  0.042895   \n",
              "2023-05-03  0.794243 -2.186876  0.051037  0.043230 -1.041547 -0.668534   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2024-02-22 -0.248212 -0.251431 -0.248337 -0.253670 -0.024773  0.431027   \n",
              "2024-02-23  0.214752 -0.252386 -0.249285 -0.254612 -0.254885 -0.029594   \n",
              "2024-02-27 -0.948440  0.212543 -0.250240 -0.255561 -0.255827 -0.259434   \n",
              "2024-02-28  0.451058 -0.955587  0.214919 -0.256518 -0.256775 -0.260374   \n",
              "2024-02-29 -1.671338  0.449853 -0.953788  0.209616 -0.257732 -0.261322   \n",
              "\n",
              "              lag_10  momentum  volatility  distance      data_type  ticker  \\\n",
              "Date                                                                          \n",
              "2023-04-26  0.400361 -1.115264    0.599902 -1.050739  training_data  AAV.BK   \n",
              "2023-04-27  0.045378 -0.089248    0.956138 -0.415456  training_data  AAV.BK   \n",
              "2023-04-28 -0.309605  0.251396    1.085820  0.008064  training_data  AAV.BK   \n",
              "2023-05-02  0.400361 -0.261496    1.345064 -0.477739  training_data  AAV.BK   \n",
              "2023-05-03  0.045378  1.296897   -0.030793  0.120172  training_data  AAV.BK   \n",
              "...              ...       ...         ...       ...            ...     ...   \n",
              "2024-02-22 -0.490069 -1.090688   -0.138042 -1.237085  training_data  WHA.BK   \n",
              "2024-02-23  0.431140 -0.854415   -0.023781 -1.056374  training_data  WHA.BK   \n",
              "2024-02-27 -0.029465 -1.946165    0.358846 -2.112102  training_data  WHA.BK   \n",
              "2024-02-28 -0.259297 -1.478644    0.457465 -1.940903  training_data  WHA.BK   \n",
              "2024-02-29 -0.260237 -1.343556    0.609803 -1.360728  training_data  WHA.BK   \n",
              "\n",
              "            direction  \n",
              "Date                   \n",
              "2023-04-26          1  \n",
              "2023-04-27          1  \n",
              "2023-04-28          0  \n",
              "2023-05-02          1  \n",
              "2023-05-03          1  \n",
              "...               ...  \n",
              "2024-02-22          1  \n",
              "2024-02-23          0  \n",
              "2024-02-27          0  \n",
              "2024-02-28          1  \n",
              "2024-02-29          0  \n",
              "\n",
              "[20493 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-67fb9173-a1aa-4a45-bbe0-d8dedca009b6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>return</th>\n",
              "      <th>lag_1</th>\n",
              "      <th>lag_2</th>\n",
              "      <th>lag_3</th>\n",
              "      <th>lag_4</th>\n",
              "      <th>lag_5</th>\n",
              "      <th>lag_6</th>\n",
              "      <th>lag_7</th>\n",
              "      <th>lag_8</th>\n",
              "      <th>lag_9</th>\n",
              "      <th>lag_10</th>\n",
              "      <th>momentum</th>\n",
              "      <th>volatility</th>\n",
              "      <th>distance</th>\n",
              "      <th>data_type</th>\n",
              "      <th>ticker</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2023-04-26</th>\n",
              "      <td>0.496309</td>\n",
              "      <td>-0.568551</td>\n",
              "      <td>0.790396</td>\n",
              "      <td>-2.196122</td>\n",
              "      <td>0.033924</td>\n",
              "      <td>0.035978</td>\n",
              "      <td>-1.034493</td>\n",
              "      <td>-0.655546</td>\n",
              "      <td>0.051037</td>\n",
              "      <td>0.397614</td>\n",
              "      <td>-0.309370</td>\n",
              "      <td>0.042895</td>\n",
              "      <td>0.400361</td>\n",
              "      <td>-1.115264</td>\n",
              "      <td>0.599902</td>\n",
              "      <td>-1.050739</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-27</th>\n",
              "      <td>0.674156</td>\n",
              "      <td>-0.338104</td>\n",
              "      <td>1.149153</td>\n",
              "      <td>0.788679</td>\n",
              "      <td>-2.196122</td>\n",
              "      <td>0.035978</td>\n",
              "      <td>0.041080</td>\n",
              "      <td>-1.029527</td>\n",
              "      <td>-0.657899</td>\n",
              "      <td>0.043230</td>\n",
              "      <td>0.399234</td>\n",
              "      <td>-0.311531</td>\n",
              "      <td>0.045378</td>\n",
              "      <td>-0.089248</td>\n",
              "      <td>0.956138</td>\n",
              "      <td>-0.415456</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-04-28</th>\n",
              "      <td>0.792720</td>\n",
              "      <td>-0.214725</td>\n",
              "      <td>0.762005</td>\n",
              "      <td>1.144563</td>\n",
              "      <td>0.788679</td>\n",
              "      <td>-2.195190</td>\n",
              "      <td>0.041080</td>\n",
              "      <td>0.053137</td>\n",
              "      <td>-1.032013</td>\n",
              "      <td>-0.668113</td>\n",
              "      <td>0.044932</td>\n",
              "      <td>0.397320</td>\n",
              "      <td>-0.309605</td>\n",
              "      <td>0.251396</td>\n",
              "      <td>1.085820</td>\n",
              "      <td>0.008064</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-02</th>\n",
              "      <td>0.614874</td>\n",
              "      <td>-0.504826</td>\n",
              "      <td>-1.073276</td>\n",
              "      <td>0.760515</td>\n",
              "      <td>1.144563</td>\n",
              "      <td>0.791112</td>\n",
              "      <td>-2.184263</td>\n",
              "      <td>0.053137</td>\n",
              "      <td>0.051037</td>\n",
              "      <td>-1.043497</td>\n",
              "      <td>-0.666249</td>\n",
              "      <td>0.042895</td>\n",
              "      <td>0.400361</td>\n",
              "      <td>-0.261496</td>\n",
              "      <td>1.345064</td>\n",
              "      <td>-0.477739</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2023-05-03</th>\n",
              "      <td>0.792720</td>\n",
              "      <td>-0.311945</td>\n",
              "      <td>1.132374</td>\n",
              "      <td>-1.060071</td>\n",
              "      <td>0.760515</td>\n",
              "      <td>1.147176</td>\n",
              "      <td>0.794243</td>\n",
              "      <td>-2.186876</td>\n",
              "      <td>0.051037</td>\n",
              "      <td>0.043230</td>\n",
              "      <td>-1.041547</td>\n",
              "      <td>-0.668534</td>\n",
              "      <td>0.045378</td>\n",
              "      <td>1.296897</td>\n",
              "      <td>-0.030793</td>\n",
              "      <td>0.120172</td>\n",
              "      <td>training_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-22</th>\n",
              "      <td>-0.697270</td>\n",
              "      <td>1.290695</td>\n",
              "      <td>-1.650642</td>\n",
              "      <td>0.457012</td>\n",
              "      <td>-0.930448</td>\n",
              "      <td>0.217535</td>\n",
              "      <td>-0.248212</td>\n",
              "      <td>-0.251431</td>\n",
              "      <td>-0.248337</td>\n",
              "      <td>-0.253670</td>\n",
              "      <td>-0.024773</td>\n",
              "      <td>0.431027</td>\n",
              "      <td>-0.490069</td>\n",
              "      <td>-1.090688</td>\n",
              "      <td>-0.138042</td>\n",
              "      <td>-1.237085</td>\n",
              "      <td>training_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-23</th>\n",
              "      <td>-0.632835</td>\n",
              "      <td>-0.747718</td>\n",
              "      <td>0.226524</td>\n",
              "      <td>-1.649198</td>\n",
              "      <td>0.458152</td>\n",
              "      <td>-0.947084</td>\n",
              "      <td>0.214752</td>\n",
              "      <td>-0.252386</td>\n",
              "      <td>-0.249285</td>\n",
              "      <td>-0.254612</td>\n",
              "      <td>-0.254885</td>\n",
              "      <td>-0.029594</td>\n",
              "      <td>0.431140</td>\n",
              "      <td>-0.854415</td>\n",
              "      <td>-0.023781</td>\n",
              "      <td>-1.056374</td>\n",
              "      <td>training_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-27</th>\n",
              "      <td>-1.148316</td>\n",
              "      <td>0.930419</td>\n",
              "      <td>-1.937699</td>\n",
              "      <td>0.230344</td>\n",
              "      <td>-1.647717</td>\n",
              "      <td>0.454131</td>\n",
              "      <td>-0.948440</td>\n",
              "      <td>0.212543</td>\n",
              "      <td>-0.250240</td>\n",
              "      <td>-0.255561</td>\n",
              "      <td>-0.255827</td>\n",
              "      <td>-0.259434</td>\n",
              "      <td>-0.029465</td>\n",
              "      <td>-1.946165</td>\n",
              "      <td>0.358846</td>\n",
              "      <td>-2.112102</td>\n",
              "      <td>training_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-28</th>\n",
              "      <td>-1.148316</td>\n",
              "      <td>-0.012106</td>\n",
              "      <td>-0.010728</td>\n",
              "      <td>-1.936618</td>\n",
              "      <td>0.231522</td>\n",
              "      <td>-1.670869</td>\n",
              "      <td>0.451058</td>\n",
              "      <td>-0.955587</td>\n",
              "      <td>0.214919</td>\n",
              "      <td>-0.256518</td>\n",
              "      <td>-0.256775</td>\n",
              "      <td>-0.260374</td>\n",
              "      <td>-0.259297</td>\n",
              "      <td>-1.478644</td>\n",
              "      <td>0.457465</td>\n",
              "      <td>-1.940903</td>\n",
              "      <td>training_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-02-29</th>\n",
              "      <td>-0.955011</td>\n",
              "      <td>0.316111</td>\n",
              "      <td>0.719729</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>-1.935090</td>\n",
              "      <td>0.225441</td>\n",
              "      <td>-1.671338</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>-0.953788</td>\n",
              "      <td>0.209616</td>\n",
              "      <td>-0.257732</td>\n",
              "      <td>-0.261322</td>\n",
              "      <td>-0.260237</td>\n",
              "      <td>-1.343556</td>\n",
              "      <td>0.609803</td>\n",
              "      <td>-1.360728</td>\n",
              "      <td>training_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20493 rows Ã— 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67fb9173-a1aa-4a45-bbe0-d8dedca009b6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-67fb9173-a1aa-4a45-bbe0-d8dedca009b6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-67fb9173-a1aa-4a45-bbe0-d8dedca009b6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f35f87db-2f0a-4f43-92d5-7bc79731c501\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f35f87db-2f0a-4f43-92d5-7bc79731c501')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f35f87db-2f0a-4f43-92d5-7bc79731c501 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "training_data",
              "summary": "{\n  \"name\": \"training_data\",\n  \"rows\": 20493,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 207,\n        \"samples\": [\n          \"2023-12-22\",\n          \"2023-05-22\",\n          \"2023-08-16\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349192,\n        \"min\": -4.280754284999186,\n        \"max\": 3.485668593310419,\n        \"num_unique_values\": 5429,\n        \"samples\": [\n          0.5109378063034906,\n          0.4423550681582561,\n          2.319669691040753\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349192,\n        \"min\": -1.7757493611967363,\n        \"max\": 13.376974430710511,\n        \"num_unique_values\": 20470,\n        \"samples\": [\n          -1.0289538594882996,\n          -0.9227474683231108,\n          -0.9296008101284118\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -8.413393306038094,\n        \"max\": 6.895433715346177,\n        \"num_unique_values\": 13937,\n        \"samples\": [\n          -0.6783063745345926,\n          -0.6162116476295012,\n          0.6707193972169794\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -8.413393306038094,\n        \"max\": 6.892675600429356,\n        \"num_unique_values\": 13933,\n        \"samples\": [\n          -1.4726779171900366,\n          -0.3458925242297433,\n          0.3360618474742022\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -8.399542828418474,\n        \"max\": 6.894426376279646,\n        \"num_unique_values\": 13928,\n        \"samples\": [\n          0.6747259192105113,\n          -0.5322605211764827,\n          1.5884793177204506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -9.89085226140396,\n        \"max\": 6.89376773424197,\n        \"num_unique_values\": 13928,\n        \"samples\": [\n          1.8250658518750773,\n          -0.5298156617272018,\n          1.5919543409901695\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349192,\n        \"min\": -9.89085226140396,\n        \"max\": 6.890525393970335,\n        \"num_unique_values\": 13938,\n        \"samples\": [\n          -0.3210300123644037,\n          0.2124386151293148,\n          1.0144339652447396\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -9.78127756288272,\n        \"max\": 6.889873123855749,\n        \"num_unique_values\": 13946,\n        \"samples\": [\n          1.874748317387656,\n          -0.3092240708111921,\n          -2.086716461770765\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -9.798970122266969,\n        \"max\": 6.892340970856103,\n        \"num_unique_values\": 13943,\n        \"samples\": [\n          0.4274271275881755,\n          -1.476622024291054,\n          1.3566280530880448\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349192,\n        \"min\": -9.79674377203502,\n        \"max\": 6.877629820502031,\n        \"num_unique_values\": 13948,\n        \"samples\": [\n          -0.4622157242881572,\n          0.7762354479894354,\n          0.3599046038042095\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -9.792054618243814,\n        \"max\": 6.87959171713569,\n        \"num_unique_values\": 13948,\n        \"samples\": [\n          -0.4719134669495043,\n          -0.3088098309953973,\n          -0.8701523743405029\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -9.802937349346353,\n        \"max\": 6.876095977688038,\n        \"num_unique_values\": 13953,\n        \"samples\": [\n          -4.065054251269767,\n          -1.3104457606803457,\n          -0.6331655939436993\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349192,\n        \"min\": -9.803714807047214,\n        \"max\": 6.876327806398884,\n        \"num_unique_values\": 13958,\n        \"samples\": [\n          0.4387879192916518,\n          0.4710817127536522,\n          -2.393644453017341\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"momentum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -6.013153654784603,\n        \"max\": 4.541327205250273,\n        \"num_unique_values\": 19629,\n        \"samples\": [\n          0.0529645771162845,\n          -0.5677755908330773,\n          0.5175882641528511\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -2.694655793728232,\n        \"max\": 8.11699345470993,\n        \"num_unique_values\": 19730,\n        \"samples\": [\n          -1.0821760526517836,\n          -0.9763181474767304,\n          -0.0455306242688362\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9976059572349191,\n        \"min\": -5.020211999896247,\n        \"max\": 4.39989721279479,\n        \"num_unique_values\": 18004,\n        \"samples\": [\n          -0.2318099352755118,\n          -0.4429673674808609,\n          2.4574561993862667\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"training_data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"OSP.BK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"direction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbWqDbtyNbhS",
        "outputId": "c80a3030-542b-421a-991c-f54dc2841369"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20493, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "-57KzxqVxB3L",
        "outputId": "4a31b79e-1808-47f0-fa05-cdd9287f74a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               Close    Volume    return     lag_1     lag_2     lag_3  \\\n",
              "Date                                                                     \n",
              "2024-03-01 -0.452206 -0.479848  0.461919 -1.241627  0.033924  0.457671   \n",
              "2024-03-04 -0.452206 -0.039717  0.029549  0.462831 -1.241627  0.035978   \n",
              "2024-03-05 -0.392924 -0.284487  0.458143  0.033924  0.462831 -1.240214   \n",
              "2024-03-06 -0.274359 -0.268147  0.875668  0.459085  0.033924  0.465101   \n",
              "2024-03-07 -0.392924 -0.691498 -0.816569  0.873267  0.459085  0.035978   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2024-03-25 -0.310658 -0.442654 -0.242062 -0.007209  0.458152  0.221422   \n",
              "2024-03-26 -0.310658 -1.369240 -0.010728 -0.238835 -0.005993  0.454131   \n",
              "2024-03-27 -0.375093 -0.341047 -0.243028 -0.007209 -0.237582 -0.014231   \n",
              "2024-03-28 -0.375093 -1.369240 -0.010728 -0.239803 -0.005993 -0.247924   \n",
              "2024-03-29 -0.439528 -0.666753 -0.244002 -0.007209 -0.238549 -0.014231   \n",
              "\n",
              "               lag_4     lag_5     lag_6     lag_7     lag_8     lag_9  \\\n",
              "Date                                                                     \n",
              "2024-03-01  0.041080  1.784232 -0.387672 -1.254163  0.044932 -0.382110   \n",
              "2024-03-04  0.461672  0.053137  1.782748 -0.396969 -1.252164  0.042895   \n",
              "2024-03-05  0.041080  0.476502  0.051037  1.780823 -0.395166 -1.254653   \n",
              "2024-03-06 -1.231781  0.053137  0.474552  0.043230  1.782127 -0.397357   \n",
              "2024-03-07  0.469083 -1.228115  0.051037  0.468184  0.044932  1.780693   \n",
              "...              ...       ...       ...       ...       ...       ...   \n",
              "2024-03-25 -0.252094 -0.489695 -0.017661  0.211554  0.211103 -0.029594   \n",
              "2024-03-26  0.218634 -0.256285 -0.487666 -0.023451  0.210123  0.206004   \n",
              "2024-03-27  0.451058  0.216442 -0.254140 -0.494443 -0.024773  0.205025   \n",
              "2024-03-28 -0.016730  0.449853  0.218819 -0.260427 -0.495546 -0.029594   \n",
              "2024-03-29 -0.250137 -0.019921  0.452345  0.213525 -0.261639 -0.499811   \n",
              "\n",
              "              lag_10  momentum  volatility  distance     data_type  ticker  \\\n",
              "Date                                                                         \n",
              "2024-03-01  0.900443 -0.117617   -0.604639 -0.004393  testing_data  AAV.BK   \n",
              "2024-03-04 -0.380296 -0.117617   -0.604639  0.008064  testing_data  AAV.BK   \n",
              "2024-03-05  0.045378 -0.115891   -0.602901  0.219824  testing_data  AAV.BK   \n",
              "2024-03-06 -1.254213  0.277614   -0.300407  0.593518  testing_data  AAV.BK   \n",
              "2024-03-07 -0.395567  0.482119   -0.762508  0.207367  testing_data  AAV.BK   \n",
              "...              ...       ...         ...       ...           ...     ...   \n",
              "2024-03-25 -0.265055  0.089975   -1.430363  0.113490  testing_data  WHA.BK   \n",
              "2024-03-26 -0.029465  0.208078   -1.518772  0.037401  testing_data  WHA.BK   \n",
              "2024-03-27  0.206125 -0.027635   -1.473673 -0.143309  testing_data  WHA.BK   \n",
              "2024-03-28  0.205146 -0.262365   -1.835529 -0.171842  testing_data  WHA.BK   \n",
              "2024-03-29 -0.029465 -0.380468   -1.834912 -0.295486  testing_data  WHA.BK   \n",
              "\n",
              "            direction  \n",
              "Date                   \n",
              "2024-03-01          1  \n",
              "2024-03-04          1  \n",
              "2024-03-05          1  \n",
              "2024-03-06          0  \n",
              "2024-03-07          1  \n",
              "...               ...  \n",
              "2024-03-25          0  \n",
              "2024-03-26          0  \n",
              "2024-03-27          0  \n",
              "2024-03-28          0  \n",
              "2024-03-29          0  \n",
              "\n",
              "[2079 rows x 19 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b89dc8f1-f4c6-462c-879c-a7225bf80bf2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>return</th>\n",
              "      <th>lag_1</th>\n",
              "      <th>lag_2</th>\n",
              "      <th>lag_3</th>\n",
              "      <th>lag_4</th>\n",
              "      <th>lag_5</th>\n",
              "      <th>lag_6</th>\n",
              "      <th>lag_7</th>\n",
              "      <th>lag_8</th>\n",
              "      <th>lag_9</th>\n",
              "      <th>lag_10</th>\n",
              "      <th>momentum</th>\n",
              "      <th>volatility</th>\n",
              "      <th>distance</th>\n",
              "      <th>data_type</th>\n",
              "      <th>ticker</th>\n",
              "      <th>direction</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2024-03-01</th>\n",
              "      <td>-0.452206</td>\n",
              "      <td>-0.479848</td>\n",
              "      <td>0.461919</td>\n",
              "      <td>-1.241627</td>\n",
              "      <td>0.033924</td>\n",
              "      <td>0.457671</td>\n",
              "      <td>0.041080</td>\n",
              "      <td>1.784232</td>\n",
              "      <td>-0.387672</td>\n",
              "      <td>-1.254163</td>\n",
              "      <td>0.044932</td>\n",
              "      <td>-0.382110</td>\n",
              "      <td>0.900443</td>\n",
              "      <td>-0.117617</td>\n",
              "      <td>-0.604639</td>\n",
              "      <td>-0.004393</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-04</th>\n",
              "      <td>-0.452206</td>\n",
              "      <td>-0.039717</td>\n",
              "      <td>0.029549</td>\n",
              "      <td>0.462831</td>\n",
              "      <td>-1.241627</td>\n",
              "      <td>0.035978</td>\n",
              "      <td>0.461672</td>\n",
              "      <td>0.053137</td>\n",
              "      <td>1.782748</td>\n",
              "      <td>-0.396969</td>\n",
              "      <td>-1.252164</td>\n",
              "      <td>0.042895</td>\n",
              "      <td>-0.380296</td>\n",
              "      <td>-0.117617</td>\n",
              "      <td>-0.604639</td>\n",
              "      <td>0.008064</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-05</th>\n",
              "      <td>-0.392924</td>\n",
              "      <td>-0.284487</td>\n",
              "      <td>0.458143</td>\n",
              "      <td>0.033924</td>\n",
              "      <td>0.462831</td>\n",
              "      <td>-1.240214</td>\n",
              "      <td>0.041080</td>\n",
              "      <td>0.476502</td>\n",
              "      <td>0.051037</td>\n",
              "      <td>1.780823</td>\n",
              "      <td>-0.395166</td>\n",
              "      <td>-1.254653</td>\n",
              "      <td>0.045378</td>\n",
              "      <td>-0.115891</td>\n",
              "      <td>-0.602901</td>\n",
              "      <td>0.219824</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-06</th>\n",
              "      <td>-0.274359</td>\n",
              "      <td>-0.268147</td>\n",
              "      <td>0.875668</td>\n",
              "      <td>0.459085</td>\n",
              "      <td>0.033924</td>\n",
              "      <td>0.465101</td>\n",
              "      <td>-1.231781</td>\n",
              "      <td>0.053137</td>\n",
              "      <td>0.474552</td>\n",
              "      <td>0.043230</td>\n",
              "      <td>1.782127</td>\n",
              "      <td>-0.397357</td>\n",
              "      <td>-1.254213</td>\n",
              "      <td>0.277614</td>\n",
              "      <td>-0.300407</td>\n",
              "      <td>0.593518</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-07</th>\n",
              "      <td>-0.392924</td>\n",
              "      <td>-0.691498</td>\n",
              "      <td>-0.816569</td>\n",
              "      <td>0.873267</td>\n",
              "      <td>0.459085</td>\n",
              "      <td>0.035978</td>\n",
              "      <td>0.469083</td>\n",
              "      <td>-1.228115</td>\n",
              "      <td>0.051037</td>\n",
              "      <td>0.468184</td>\n",
              "      <td>0.044932</td>\n",
              "      <td>1.780693</td>\n",
              "      <td>-0.395567</td>\n",
              "      <td>0.482119</td>\n",
              "      <td>-0.762508</td>\n",
              "      <td>0.207367</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>AAV.BK</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-25</th>\n",
              "      <td>-0.310658</td>\n",
              "      <td>-0.442654</td>\n",
              "      <td>-0.242062</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>0.458152</td>\n",
              "      <td>0.221422</td>\n",
              "      <td>-0.252094</td>\n",
              "      <td>-0.489695</td>\n",
              "      <td>-0.017661</td>\n",
              "      <td>0.211554</td>\n",
              "      <td>0.211103</td>\n",
              "      <td>-0.029594</td>\n",
              "      <td>-0.265055</td>\n",
              "      <td>0.089975</td>\n",
              "      <td>-1.430363</td>\n",
              "      <td>0.113490</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-26</th>\n",
              "      <td>-0.310658</td>\n",
              "      <td>-1.369240</td>\n",
              "      <td>-0.010728</td>\n",
              "      <td>-0.238835</td>\n",
              "      <td>-0.005993</td>\n",
              "      <td>0.454131</td>\n",
              "      <td>0.218634</td>\n",
              "      <td>-0.256285</td>\n",
              "      <td>-0.487666</td>\n",
              "      <td>-0.023451</td>\n",
              "      <td>0.210123</td>\n",
              "      <td>0.206004</td>\n",
              "      <td>-0.029465</td>\n",
              "      <td>0.208078</td>\n",
              "      <td>-1.518772</td>\n",
              "      <td>0.037401</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-27</th>\n",
              "      <td>-0.375093</td>\n",
              "      <td>-0.341047</td>\n",
              "      <td>-0.243028</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>-0.237582</td>\n",
              "      <td>-0.014231</td>\n",
              "      <td>0.451058</td>\n",
              "      <td>0.216442</td>\n",
              "      <td>-0.254140</td>\n",
              "      <td>-0.494443</td>\n",
              "      <td>-0.024773</td>\n",
              "      <td>0.205025</td>\n",
              "      <td>0.206125</td>\n",
              "      <td>-0.027635</td>\n",
              "      <td>-1.473673</td>\n",
              "      <td>-0.143309</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-28</th>\n",
              "      <td>-0.375093</td>\n",
              "      <td>-1.369240</td>\n",
              "      <td>-0.010728</td>\n",
              "      <td>-0.239803</td>\n",
              "      <td>-0.005993</td>\n",
              "      <td>-0.247924</td>\n",
              "      <td>-0.016730</td>\n",
              "      <td>0.449853</td>\n",
              "      <td>0.218819</td>\n",
              "      <td>-0.260427</td>\n",
              "      <td>-0.495546</td>\n",
              "      <td>-0.029594</td>\n",
              "      <td>0.205146</td>\n",
              "      <td>-0.262365</td>\n",
              "      <td>-1.835529</td>\n",
              "      <td>-0.171842</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2024-03-29</th>\n",
              "      <td>-0.439528</td>\n",
              "      <td>-0.666753</td>\n",
              "      <td>-0.244002</td>\n",
              "      <td>-0.007209</td>\n",
              "      <td>-0.238549</td>\n",
              "      <td>-0.014231</td>\n",
              "      <td>-0.250137</td>\n",
              "      <td>-0.019921</td>\n",
              "      <td>0.452345</td>\n",
              "      <td>0.213525</td>\n",
              "      <td>-0.261639</td>\n",
              "      <td>-0.499811</td>\n",
              "      <td>-0.029465</td>\n",
              "      <td>-0.380468</td>\n",
              "      <td>-1.834912</td>\n",
              "      <td>-0.295486</td>\n",
              "      <td>testing_data</td>\n",
              "      <td>WHA.BK</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2079 rows Ã— 19 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b89dc8f1-f4c6-462c-879c-a7225bf80bf2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b89dc8f1-f4c6-462c-879c-a7225bf80bf2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b89dc8f1-f4c6-462c-879c-a7225bf80bf2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ba61cccd-5930-48dc-a3dc-09c22ed28d18\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ba61cccd-5930-48dc-a3dc-09c22ed28d18')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ba61cccd-5930-48dc-a3dc-09c22ed28d18 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "testing_data",
              "summary": "{\n  \"name\": \"testing_data\",\n  \"rows\": 2079,\n  \"fields\": [\n    {\n      \"column\": \"Date\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"2024-03-01\",\n          \"2024-03-26\",\n          \"2024-03-22\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Close\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2434536499257294,\n        \"min\": -4.112992662142739,\n        \"max\": 2.7513557933418227,\n        \"num_unique_values\": 942,\n        \"samples\": [\n          -1.4045609688242453,\n          -2.4944961404070294,\n          -1.4015692660472538\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Volume\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2954971064250271,\n        \"min\": -2.101378932526864,\n        \"max\": 25.17911450842402,\n        \"num_unique_values\": 1697,\n        \"samples\": [\n          -0.3325987160782345,\n          -0.5231489592883309,\n          2.433248932325377\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"return\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8798322619446228,\n        \"min\": -5.832725001865157,\n        \"max\": 7.117412791048348,\n        \"num_unique_values\": 1373,\n        \"samples\": [\n          -1.2108329360916612,\n          0.6610940193569792,\n          0.0120945445874509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9115733952905609,\n        \"min\": -6.760378471755009,\n        \"max\": 7.11375890630616,\n        \"num_unique_values\": 1385,\n        \"samples\": [\n          1.1349096943163497,\n          0.3006503196420069,\n          -1.3707211931737109\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9429495149710526,\n        \"min\": -6.7632676039666215,\n        \"max\": 7.113185871000301,\n        \"num_unique_values\": 1442,\n        \"samples\": [\n          0.7207777184957016,\n          0.4212768619115404,\n          -0.8225007478036721\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9456632682714872,\n        \"min\": -6.783913222258138,\n        \"max\": 7.099775191443252,\n        \"num_unique_values\": 1453,\n        \"samples\": [\n          1.4418597695402486,\n          -0.8159572608788086,\n          -0.7308489533550192\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9715262944369116,\n        \"min\": -6.738280188606215,\n        \"max\": 7.006161247077795,\n        \"num_unique_values\": 1501,\n        \"samples\": [\n          -0.7741963574093498,\n          0.0163356179180551,\n          1.0743990701654809\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_5\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9565751637236144,\n        \"min\": -6.734800398493528,\n        \"max\": 6.967883239276386,\n        \"num_unique_values\": 1482,\n        \"samples\": [\n          0.1282658155125212,\n          -1.3254669619132171,\n          1.3976558890744517\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_6\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9998883385117846,\n        \"min\": -6.742452851045868,\n        \"max\": 6.9719700753050615,\n        \"num_unique_values\": 1566,\n        \"samples\": [\n          -0.6411029890914444,\n          0.2796409849741583,\n          -0.4970247170527279\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_7\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9904375022538215,\n        \"min\": -6.748760697303131,\n        \"max\": 5.799211182885139,\n        \"num_unique_values\": 1562,\n        \"samples\": [\n          -0.5314524357120095,\n          -1.0211835964121154,\n          -0.8082256989649179\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_8\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0111540457329224,\n        \"min\": -6.739092945659927,\n        \"max\": 5.799372007223036,\n        \"num_unique_values\": 1599,\n        \"samples\": [\n          -0.0414815279651728,\n          -0.8070893541010766,\n          0.7874109853726337\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_9\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.014686355339938,\n        \"min\": -6.729561298520132,\n        \"max\": 5.799527517779969,\n        \"num_unique_values\": 1602,\n        \"samples\": [\n          -0.2691775032933259,\n          -0.4879640849652097,\n          1.4349931947613956\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lag_10\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0064683280488997,\n        \"min\": -6.727545841760126,\n        \"max\": 5.787943863352062,\n        \"num_unique_values\": 1603,\n        \"samples\": [\n          -0.3010426181259592,\n          0.680509515148075,\n          -0.3076484935992087\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"momentum\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9221466579435565,\n        \"min\": -3.9500548271734415,\n        \"max\": 3.566743640531711,\n        \"num_unique_values\": 1843,\n        \"samples\": [\n          -0.0632913150740849,\n          1.2072670725861978,\n          0.2539367630269599\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatility\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1090488099641782,\n        \"min\": -2.652268751309227,\n        \"max\": 6.45270604982189,\n        \"num_unique_values\": 1843,\n        \"samples\": [\n          -0.3076116338701378,\n          0.3985395843332122,\n          0.0643539525912978\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"distance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.8218654961853236,\n        \"min\": -3.291967993276093,\n        \"max\": 3.721284308555284,\n        \"num_unique_values\": 2001,\n        \"samples\": [\n          -0.345721693624218,\n          0.1394338337092583,\n          0.6078663815100283\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"data_type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"testing_data\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"OSP.BK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"direction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "testing_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6yMOXLvOxZBk"
      },
      "source": [
        "#### 4.2 Build Sequence model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xDQ93O7MxGxI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional, LSTM, BatchNormalization\n",
        "#from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.losses import BinaryCrossentropy\n",
        "from keras.losses import sparse_categorical_crossentropy\n",
        "from keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7pSJtmx1tVC",
        "outputId": "37c6c5d8-db51-40a8-ad07-5ac85cbeae3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2079, 19)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "testing_data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ozgpc_a9zmeN"
      },
      "outputs": [],
      "source": [
        "feature_num = len(feature_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rOYbHPbYCHT7"
      },
      "source": [
        "#### 4.3 Train and Run Model Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dmYeopFUQsnM"
      },
      "outputs": [],
      "source": [
        "# Training data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "26BjO9170RVd"
      },
      "outputs": [],
      "source": [
        "x_metric = training_data[feature_name].to_numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDslJtA_7eSB",
        "outputId": "b65feb47-0557-4c95-b30c-51d1e22de92a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20493, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "x_metric.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nq2AASWi8H1v",
        "outputId": "0aee052b-c217-4b12-9ee7-758f5775939f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.49630903, -0.5685512 ,  0.79039626, -2.196122  ,  0.03392359,\n",
              "        0.03597782, -1.03449321, -0.65554648,  0.05103665,  0.39761357,\n",
              "       -0.30936997,  0.04289456,  0.40036135, -1.11526402,  0.5999023 ,\n",
              "       -1.05073909])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "x_metric[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YA_OlbZs7A7q"
      },
      "outputs": [],
      "source": [
        "x = x_metric.reshape((x_metric.shape[0], 1, feature_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfWrhdbh8dHV",
        "outputId": "36aa3e62-41d5-4452-ca5f-761fc614373e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.49630903, -0.5685512 ,  0.79039626, -2.196122  ,  0.03392359,\n",
              "         0.03597782, -1.03449321, -0.65554648,  0.05103665,  0.39761357,\n",
              "        -0.30936997,  0.04289456,  0.40036135, -1.11526402,  0.5999023 ,\n",
              "        -1.05073909]])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "x[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiEnlCHG-mlk",
        "outputId": "39fec913-5025-486a-cab6-0eff9cba84b0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20493, 1, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qfJMVsdO-w0J"
      },
      "outputs": [],
      "source": [
        "y = training_data['direction'].to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0agm8pK-1M4",
        "outputId": "a73bc884-07d1-4c69-ebb3-8c696ee31dd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20493,)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwjReZ88QpUQ",
        "outputId": "45ba0877-4cd4-4c37-a7ab-820b82e0cf69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 0, ..., 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rtaUshdHQ0Rn"
      },
      "outputs": [],
      "source": [
        "# Testing data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "0PjQs3J_19Hz"
      },
      "outputs": [],
      "source": [
        "x_testing_metric = testing_data[feature_name].to_numpy()\n",
        "x_test = x_testing_metric.reshape((x_testing_metric.shape[0], 1, feature_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OJWO_O6q19KN"
      },
      "outputs": [],
      "source": [
        "y_test = testing_data['direction'].to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Structure"
      ],
      "metadata": {
        "id": "DnuaUWf5Nkyc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "RSwAkCfU19E4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "checkpoint_path = \"training_1/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "irjuZgcs19NM"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "\n",
        "def sequence_model(learning_rate, feature_num):\n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LSTM(8, activation = 'relu', input_shape=(1, feature_num), return_sequences=True))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LSTM(1, activation = 'relu', return_sequences=False))\n",
        "  model.add(Dense(1, activation = 'sigmoid'))\n",
        "  model.compile(loss=BinaryCrossentropy(from_logits=True),\n",
        "                    optimizer=Adam(learning_rate),\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vBEpsKs2UFE"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EO4UzWSK2uaO",
        "outputId": "b3059579-db0c-4c1b-dc28-31b68133684e"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "638/641 [============================>.] - ETA: 0s - loss: 0.6926 - accuracy: 0.5180\n",
            "Epoch 1: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 11s 9ms/step - loss: 0.6926 - accuracy: 0.5182 - val_loss: 0.6863 - val_accuracy: 0.5777\n",
            "Epoch 2/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6907 - accuracy: 0.5328\n",
            "Epoch 2: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6907 - accuracy: 0.5327 - val_loss: 0.6824 - val_accuracy: 0.5878\n",
            "Epoch 3/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6880 - accuracy: 0.5496\n",
            "Epoch 3: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6878 - accuracy: 0.5500 - val_loss: 0.6800 - val_accuracy: 0.5859\n",
            "Epoch 4/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6867 - accuracy: 0.5522\n",
            "Epoch 4: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6867 - accuracy: 0.5520 - val_loss: 0.6796 - val_accuracy: 0.5897\n",
            "Epoch 5/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6862 - accuracy: 0.5539\n",
            "Epoch 5: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6862 - accuracy: 0.5539 - val_loss: 0.6782 - val_accuracy: 0.5835\n",
            "Epoch 6/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6847 - accuracy: 0.5579\n",
            "Epoch 6: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6847 - accuracy: 0.5579 - val_loss: 0.6773 - val_accuracy: 0.5926\n",
            "Epoch 7/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6846 - accuracy: 0.5556\n",
            "Epoch 7: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6846 - accuracy: 0.5554 - val_loss: 0.6766 - val_accuracy: 0.5907\n",
            "Epoch 8/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6844 - accuracy: 0.5567\n",
            "Epoch 8: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6844 - accuracy: 0.5567 - val_loss: 0.6767 - val_accuracy: 0.5849\n",
            "Epoch 9/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6839 - accuracy: 0.5573\n",
            "Epoch 9: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6839 - accuracy: 0.5573 - val_loss: 0.6780 - val_accuracy: 0.5844\n",
            "Epoch 10/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6837 - accuracy: 0.5562\n",
            "Epoch 10: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6837 - accuracy: 0.5565 - val_loss: 0.6787 - val_accuracy: 0.5777\n",
            "Epoch 11/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6831 - accuracy: 0.5606\n",
            "Epoch 11: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6831 - accuracy: 0.5606 - val_loss: 0.6789 - val_accuracy: 0.5762\n",
            "Epoch 12/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6823 - accuracy: 0.5614\n",
            "Epoch 12: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6824 - accuracy: 0.5607 - val_loss: 0.6781 - val_accuracy: 0.5806\n",
            "Epoch 13/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.5621\n",
            "Epoch 13: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6825 - accuracy: 0.5622 - val_loss: 0.6814 - val_accuracy: 0.5666\n",
            "Epoch 14/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6828 - accuracy: 0.5597\n",
            "Epoch 14: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6829 - accuracy: 0.5593 - val_loss: 0.6808 - val_accuracy: 0.5690\n",
            "Epoch 15/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6826 - accuracy: 0.5612\n",
            "Epoch 15: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6826 - accuracy: 0.5612 - val_loss: 0.6794 - val_accuracy: 0.5685\n",
            "Epoch 16/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6823 - accuracy: 0.5652\n",
            "Epoch 16: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6823 - accuracy: 0.5652 - val_loss: 0.6803 - val_accuracy: 0.5661\n",
            "Epoch 17/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6814 - accuracy: 0.5686\n",
            "Epoch 17: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6814 - accuracy: 0.5684 - val_loss: 0.6791 - val_accuracy: 0.5719\n",
            "Epoch 18/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6819 - accuracy: 0.5621\n",
            "Epoch 18: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6819 - accuracy: 0.5621 - val_loss: 0.6822 - val_accuracy: 0.5690\n",
            "Epoch 19/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6810 - accuracy: 0.5659\n",
            "Epoch 19: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6810 - accuracy: 0.5660 - val_loss: 0.6794 - val_accuracy: 0.5666\n",
            "Epoch 20/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6812 - accuracy: 0.5666\n",
            "Epoch 20: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6812 - accuracy: 0.5667 - val_loss: 0.6805 - val_accuracy: 0.5724\n",
            "Epoch 21/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6811 - accuracy: 0.5662\n",
            "Epoch 21: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6811 - accuracy: 0.5662 - val_loss: 0.6812 - val_accuracy: 0.5642\n",
            "Epoch 22/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6805 - accuracy: 0.5684\n",
            "Epoch 22: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6805 - accuracy: 0.5688 - val_loss: 0.6828 - val_accuracy: 0.5671\n",
            "Epoch 23/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6809 - accuracy: 0.5647\n",
            "Epoch 23: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6808 - accuracy: 0.5651 - val_loss: 0.6817 - val_accuracy: 0.5676\n",
            "Epoch 24/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6807 - accuracy: 0.5639\n",
            "Epoch 24: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6807 - accuracy: 0.5641 - val_loss: 0.6805 - val_accuracy: 0.5719\n",
            "Epoch 25/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6798 - accuracy: 0.5682\n",
            "Epoch 25: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6797 - accuracy: 0.5686 - val_loss: 0.6829 - val_accuracy: 0.5613\n",
            "Epoch 26/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6806 - accuracy: 0.5653\n",
            "Epoch 26: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6804 - accuracy: 0.5659 - val_loss: 0.6837 - val_accuracy: 0.5599\n",
            "Epoch 27/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6793 - accuracy: 0.5679\n",
            "Epoch 27: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6794 - accuracy: 0.5677 - val_loss: 0.6841 - val_accuracy: 0.5613\n",
            "Epoch 28/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6801 - accuracy: 0.5674\n",
            "Epoch 28: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6801 - accuracy: 0.5674 - val_loss: 0.6816 - val_accuracy: 0.5637\n",
            "Epoch 29/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6794 - accuracy: 0.5677\n",
            "Epoch 29: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6795 - accuracy: 0.5675 - val_loss: 0.6844 - val_accuracy: 0.5546\n",
            "Epoch 30/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.5674\n",
            "Epoch 30: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6796 - accuracy: 0.5673 - val_loss: 0.6840 - val_accuracy: 0.5556\n",
            "Epoch 31/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6796 - accuracy: 0.5698\n",
            "Epoch 31: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6797 - accuracy: 0.5697 - val_loss: 0.6796 - val_accuracy: 0.5724\n",
            "Epoch 32/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6792 - accuracy: 0.5690\n",
            "Epoch 32: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6793 - accuracy: 0.5688 - val_loss: 0.6836 - val_accuracy: 0.5522\n",
            "Epoch 33/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6784 - accuracy: 0.5684\n",
            "Epoch 33: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6784 - accuracy: 0.5685 - val_loss: 0.6799 - val_accuracy: 0.5613\n",
            "Epoch 34/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6798 - accuracy: 0.5696\n",
            "Epoch 34: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6798 - accuracy: 0.5695 - val_loss: 0.6792 - val_accuracy: 0.5608\n",
            "Epoch 35/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6787 - accuracy: 0.5688\n",
            "Epoch 35: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6787 - accuracy: 0.5690 - val_loss: 0.6826 - val_accuracy: 0.5604\n",
            "Epoch 36/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6785 - accuracy: 0.5715\n",
            "Epoch 36: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6785 - accuracy: 0.5712 - val_loss: 0.6833 - val_accuracy: 0.5589\n",
            "Epoch 37/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6781 - accuracy: 0.5706\n",
            "Epoch 37: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6780 - accuracy: 0.5707 - val_loss: 0.6843 - val_accuracy: 0.5532\n",
            "Epoch 38/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6795 - accuracy: 0.5677\n",
            "Epoch 38: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6794 - accuracy: 0.5681 - val_loss: 0.6842 - val_accuracy: 0.5474\n",
            "Epoch 39/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6791 - accuracy: 0.5690\n",
            "Epoch 39: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6791 - accuracy: 0.5690 - val_loss: 0.6832 - val_accuracy: 0.5556\n",
            "Epoch 40/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.5727\n",
            "Epoch 40: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6777 - accuracy: 0.5727 - val_loss: 0.6831 - val_accuracy: 0.5541\n",
            "Epoch 41/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6787 - accuracy: 0.5716\n",
            "Epoch 41: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6786 - accuracy: 0.5718 - val_loss: 0.6831 - val_accuracy: 0.5556\n",
            "Epoch 42/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6780 - accuracy: 0.5702\n",
            "Epoch 42: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6781 - accuracy: 0.5701 - val_loss: 0.6826 - val_accuracy: 0.5584\n",
            "Epoch 43/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6769 - accuracy: 0.5738\n",
            "Epoch 43: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6770 - accuracy: 0.5737 - val_loss: 0.6849 - val_accuracy: 0.5536\n",
            "Epoch 44/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6777 - accuracy: 0.5739\n",
            "Epoch 44: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6778 - accuracy: 0.5734 - val_loss: 0.6842 - val_accuracy: 0.5522\n",
            "Epoch 45/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6782 - accuracy: 0.5722\n",
            "Epoch 45: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6783 - accuracy: 0.5720 - val_loss: 0.6857 - val_accuracy: 0.5512\n",
            "Epoch 46/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6791 - accuracy: 0.5685\n",
            "Epoch 46: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6791 - accuracy: 0.5685 - val_loss: 0.6838 - val_accuracy: 0.5479\n",
            "Epoch 47/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6771 - accuracy: 0.5687\n",
            "Epoch 47: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6771 - accuracy: 0.5689 - val_loss: 0.6859 - val_accuracy: 0.5435\n",
            "Epoch 48/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6779 - accuracy: 0.5689\n",
            "Epoch 48: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6779 - accuracy: 0.5689 - val_loss: 0.6837 - val_accuracy: 0.5483\n",
            "Epoch 49/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6774 - accuracy: 0.5720\n",
            "Epoch 49: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6773 - accuracy: 0.5724 - val_loss: 0.6847 - val_accuracy: 0.5421\n",
            "Epoch 50/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6776 - accuracy: 0.5695\n",
            "Epoch 50: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6776 - accuracy: 0.5696 - val_loss: 0.6857 - val_accuracy: 0.5430\n",
            "Epoch 51/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6769 - accuracy: 0.5721\n",
            "Epoch 51: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6769 - accuracy: 0.5721 - val_loss: 0.6851 - val_accuracy: 0.5426\n",
            "Epoch 52/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6773 - accuracy: 0.5699\n",
            "Epoch 52: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6773 - accuracy: 0.5699 - val_loss: 0.6864 - val_accuracy: 0.5455\n",
            "Epoch 53/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6772 - accuracy: 0.5718\n",
            "Epoch 53: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6772 - accuracy: 0.5719 - val_loss: 0.6829 - val_accuracy: 0.5488\n",
            "Epoch 54/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6769 - accuracy: 0.5762\n",
            "Epoch 54: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6769 - accuracy: 0.5760 - val_loss: 0.6833 - val_accuracy: 0.5426\n",
            "Epoch 55/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6774 - accuracy: 0.5722\n",
            "Epoch 55: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6775 - accuracy: 0.5721 - val_loss: 0.6837 - val_accuracy: 0.5551\n",
            "Epoch 56/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6764 - accuracy: 0.5755\n",
            "Epoch 56: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6764 - accuracy: 0.5759 - val_loss: 0.6852 - val_accuracy: 0.5411\n",
            "Epoch 57/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6768 - accuracy: 0.5746\n",
            "Epoch 57: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6768 - accuracy: 0.5745 - val_loss: 0.6868 - val_accuracy: 0.5435\n",
            "Epoch 58/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6764 - accuracy: 0.5759\n",
            "Epoch 58: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6762 - accuracy: 0.5765 - val_loss: 0.6893 - val_accuracy: 0.5450\n",
            "Epoch 59/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6764 - accuracy: 0.5754\n",
            "Epoch 59: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6764 - accuracy: 0.5754 - val_loss: 0.6849 - val_accuracy: 0.5426\n",
            "Epoch 60/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6762 - accuracy: 0.5747\n",
            "Epoch 60: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6760 - accuracy: 0.5751 - val_loss: 0.6866 - val_accuracy: 0.5354\n",
            "Epoch 61/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6768 - accuracy: 0.5710\n",
            "Epoch 61: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6768 - accuracy: 0.5710 - val_loss: 0.6899 - val_accuracy: 0.5301\n",
            "Epoch 62/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.5772\n",
            "Epoch 62: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6764 - accuracy: 0.5775 - val_loss: 0.6883 - val_accuracy: 0.5426\n",
            "Epoch 63/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6772 - accuracy: 0.5730\n",
            "Epoch 63: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6771 - accuracy: 0.5733 - val_loss: 0.6868 - val_accuracy: 0.5406\n",
            "Epoch 64/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6760 - accuracy: 0.5754\n",
            "Epoch 64: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6760 - accuracy: 0.5752 - val_loss: 0.6864 - val_accuracy: 0.5426\n",
            "Epoch 65/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6755 - accuracy: 0.5759\n",
            "Epoch 65: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6756 - accuracy: 0.5758 - val_loss: 0.6912 - val_accuracy: 0.5382\n",
            "Epoch 66/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6759 - accuracy: 0.5719\n",
            "Epoch 66: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6760 - accuracy: 0.5719 - val_loss: 0.6891 - val_accuracy: 0.5358\n",
            "Epoch 67/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6759 - accuracy: 0.5750\n",
            "Epoch 67: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6758 - accuracy: 0.5752 - val_loss: 0.6885 - val_accuracy: 0.5430\n",
            "Epoch 68/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6760 - accuracy: 0.5773\n",
            "Epoch 68: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6761 - accuracy: 0.5770 - val_loss: 0.6875 - val_accuracy: 0.5402\n",
            "Epoch 69/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6759 - accuracy: 0.5754\n",
            "Epoch 69: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6758 - accuracy: 0.5754 - val_loss: 0.6860 - val_accuracy: 0.5411\n",
            "Epoch 70/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6763 - accuracy: 0.5777\n",
            "Epoch 70: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6762 - accuracy: 0.5778 - val_loss: 0.6899 - val_accuracy: 0.5354\n",
            "Epoch 71/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6755 - accuracy: 0.5763\n",
            "Epoch 71: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6756 - accuracy: 0.5763 - val_loss: 0.6899 - val_accuracy: 0.5392\n",
            "Epoch 72/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6767 - accuracy: 0.5750\n",
            "Epoch 72: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6767 - accuracy: 0.5749 - val_loss: 0.6885 - val_accuracy: 0.5368\n",
            "Epoch 73/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6763 - accuracy: 0.5767\n",
            "Epoch 73: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6763 - accuracy: 0.5767 - val_loss: 0.6891 - val_accuracy: 0.5363\n",
            "Epoch 74/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6753 - accuracy: 0.5807\n",
            "Epoch 74: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6754 - accuracy: 0.5806 - val_loss: 0.6906 - val_accuracy: 0.5397\n",
            "Epoch 75/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6756 - accuracy: 0.5765\n",
            "Epoch 75: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6755 - accuracy: 0.5767 - val_loss: 0.6887 - val_accuracy: 0.5382\n",
            "Epoch 76/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6763 - accuracy: 0.5765\n",
            "Epoch 76: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6763 - accuracy: 0.5766 - val_loss: 0.6887 - val_accuracy: 0.5402\n",
            "Epoch 77/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6763 - accuracy: 0.5800\n",
            "Epoch 77: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6762 - accuracy: 0.5802 - val_loss: 0.6899 - val_accuracy: 0.5426\n",
            "Epoch 78/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6769 - accuracy: 0.5744\n",
            "Epoch 78: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6769 - accuracy: 0.5743 - val_loss: 0.6882 - val_accuracy: 0.5430\n",
            "Epoch 79/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6764 - accuracy: 0.5770\n",
            "Epoch 79: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6764 - accuracy: 0.5771 - val_loss: 0.6905 - val_accuracy: 0.5354\n",
            "Epoch 80/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6761 - accuracy: 0.5751\n",
            "Epoch 80: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6760 - accuracy: 0.5755 - val_loss: 0.6905 - val_accuracy: 0.5354\n",
            "Epoch 81/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6753 - accuracy: 0.5781\n",
            "Epoch 81: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6752 - accuracy: 0.5779 - val_loss: 0.6889 - val_accuracy: 0.5392\n",
            "Epoch 82/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6747 - accuracy: 0.5794\n",
            "Epoch 82: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6747 - accuracy: 0.5796 - val_loss: 0.6898 - val_accuracy: 0.5406\n",
            "Epoch 83/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.5748\n",
            "Epoch 83: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6765 - accuracy: 0.5748 - val_loss: 0.6852 - val_accuracy: 0.5455\n",
            "Epoch 84/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6754 - accuracy: 0.5778\n",
            "Epoch 84: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6754 - accuracy: 0.5778 - val_loss: 0.6879 - val_accuracy: 0.5397\n",
            "Epoch 85/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6752 - accuracy: 0.5784\n",
            "Epoch 85: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6752 - accuracy: 0.5784 - val_loss: 0.6897 - val_accuracy: 0.5344\n",
            "Epoch 86/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6755 - accuracy: 0.5771\n",
            "Epoch 86: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6755 - accuracy: 0.5772 - val_loss: 0.6868 - val_accuracy: 0.5382\n",
            "Epoch 87/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6765 - accuracy: 0.5751\n",
            "Epoch 87: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6765 - accuracy: 0.5752 - val_loss: 0.6887 - val_accuracy: 0.5397\n",
            "Epoch 88/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6750 - accuracy: 0.5823\n",
            "Epoch 88: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6750 - accuracy: 0.5822 - val_loss: 0.6891 - val_accuracy: 0.5402\n",
            "Epoch 89/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6741 - accuracy: 0.5801\n",
            "Epoch 89: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6741 - accuracy: 0.5802 - val_loss: 0.6920 - val_accuracy: 0.5406\n",
            "Epoch 90/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6743 - accuracy: 0.5808\n",
            "Epoch 90: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6742 - accuracy: 0.5808 - val_loss: 0.6871 - val_accuracy: 0.5455\n",
            "Epoch 91/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6761 - accuracy: 0.5761\n",
            "Epoch 91: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6761 - accuracy: 0.5761 - val_loss: 0.6846 - val_accuracy: 0.5455\n",
            "Epoch 92/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6754 - accuracy: 0.5800\n",
            "Epoch 92: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6754 - accuracy: 0.5801 - val_loss: 0.6864 - val_accuracy: 0.5445\n",
            "Epoch 93/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6751 - accuracy: 0.5774\n",
            "Epoch 93: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6751 - accuracy: 0.5773 - val_loss: 0.6840 - val_accuracy: 0.5503\n",
            "Epoch 94/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6745 - accuracy: 0.5816\n",
            "Epoch 94: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6743 - accuracy: 0.5820 - val_loss: 0.6851 - val_accuracy: 0.5459\n",
            "Epoch 95/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6747 - accuracy: 0.5798\n",
            "Epoch 95: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6747 - accuracy: 0.5798 - val_loss: 0.6849 - val_accuracy: 0.5493\n",
            "Epoch 96/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6752 - accuracy: 0.5758\n",
            "Epoch 96: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6751 - accuracy: 0.5759 - val_loss: 0.6879 - val_accuracy: 0.5464\n",
            "Epoch 97/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6751 - accuracy: 0.5801\n",
            "Epoch 97: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6750 - accuracy: 0.5802 - val_loss: 0.6877 - val_accuracy: 0.5445\n",
            "Epoch 98/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6753 - accuracy: 0.5797\n",
            "Epoch 98: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6753 - accuracy: 0.5796 - val_loss: 0.6885 - val_accuracy: 0.5479\n",
            "Epoch 99/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6751 - accuracy: 0.5787\n",
            "Epoch 99: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6754 - accuracy: 0.5780 - val_loss: 0.6873 - val_accuracy: 0.5378\n",
            "Epoch 100/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6736 - accuracy: 0.5792\n",
            "Epoch 100: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6735 - accuracy: 0.5795 - val_loss: 0.6885 - val_accuracy: 0.5320\n",
            "Epoch 101/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.5774\n",
            "Epoch 101: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6749 - accuracy: 0.5774 - val_loss: 0.6887 - val_accuracy: 0.5455\n",
            "Epoch 102/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6750 - accuracy: 0.5781\n",
            "Epoch 102: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6749 - accuracy: 0.5781 - val_loss: 0.6906 - val_accuracy: 0.5450\n",
            "Epoch 103/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.5799\n",
            "Epoch 103: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6742 - accuracy: 0.5801 - val_loss: 0.6867 - val_accuracy: 0.5488\n",
            "Epoch 104/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6740 - accuracy: 0.5787\n",
            "Epoch 104: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6739 - accuracy: 0.5788 - val_loss: 0.6888 - val_accuracy: 0.5426\n",
            "Epoch 105/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6740 - accuracy: 0.5765\n",
            "Epoch 105: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6740 - accuracy: 0.5765 - val_loss: 0.6883 - val_accuracy: 0.5416\n",
            "Epoch 106/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6746 - accuracy: 0.5794\n",
            "Epoch 106: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6745 - accuracy: 0.5796 - val_loss: 0.6878 - val_accuracy: 0.5430\n",
            "Epoch 107/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6752 - accuracy: 0.5792\n",
            "Epoch 107: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6753 - accuracy: 0.5790 - val_loss: 0.6858 - val_accuracy: 0.5426\n",
            "Epoch 108/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.5847\n",
            "Epoch 108: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6731 - accuracy: 0.5846 - val_loss: 0.6895 - val_accuracy: 0.5402\n",
            "Epoch 109/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6752 - accuracy: 0.5741\n",
            "Epoch 109: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6752 - accuracy: 0.5741 - val_loss: 0.6875 - val_accuracy: 0.5435\n",
            "Epoch 110/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6747 - accuracy: 0.5780\n",
            "Epoch 110: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6747 - accuracy: 0.5779 - val_loss: 0.6893 - val_accuracy: 0.5397\n",
            "Epoch 111/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6745 - accuracy: 0.5781\n",
            "Epoch 111: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6746 - accuracy: 0.5780 - val_loss: 0.6906 - val_accuracy: 0.5358\n",
            "Epoch 112/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6749 - accuracy: 0.5783\n",
            "Epoch 112: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6749 - accuracy: 0.5780 - val_loss: 0.6899 - val_accuracy: 0.5392\n",
            "Epoch 113/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6748 - accuracy: 0.5788\n",
            "Epoch 113: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6749 - accuracy: 0.5789 - val_loss: 0.6902 - val_accuracy: 0.5382\n",
            "Epoch 114/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6752 - accuracy: 0.5789\n",
            "Epoch 114: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6752 - accuracy: 0.5789 - val_loss: 0.6874 - val_accuracy: 0.5435\n",
            "Epoch 115/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5788\n",
            "Epoch 115: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6732 - accuracy: 0.5788 - val_loss: 0.6894 - val_accuracy: 0.5416\n",
            "Epoch 116/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6755 - accuracy: 0.5744\n",
            "Epoch 116: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6756 - accuracy: 0.5740 - val_loss: 0.6921 - val_accuracy: 0.5378\n",
            "Epoch 117/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6745 - accuracy: 0.5791\n",
            "Epoch 117: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6745 - accuracy: 0.5792 - val_loss: 0.6887 - val_accuracy: 0.5430\n",
            "Epoch 118/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6748 - accuracy: 0.5794\n",
            "Epoch 118: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6747 - accuracy: 0.5794 - val_loss: 0.6915 - val_accuracy: 0.5392\n",
            "Epoch 119/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6738 - accuracy: 0.5787\n",
            "Epoch 119: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6736 - accuracy: 0.5791 - val_loss: 0.6863 - val_accuracy: 0.5532\n",
            "Epoch 120/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5821\n",
            "Epoch 120: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6732 - accuracy: 0.5821 - val_loss: 0.6953 - val_accuracy: 0.5426\n",
            "Epoch 121/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6737 - accuracy: 0.5812\n",
            "Epoch 121: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6740 - accuracy: 0.5806 - val_loss: 0.6884 - val_accuracy: 0.5435\n",
            "Epoch 122/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.5873\n",
            "Epoch 122: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6724 - accuracy: 0.5871 - val_loss: 0.6904 - val_accuracy: 0.5459\n",
            "Epoch 123/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5811\n",
            "Epoch 123: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6734 - accuracy: 0.5806 - val_loss: 0.6870 - val_accuracy: 0.5512\n",
            "Epoch 124/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5817\n",
            "Epoch 124: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6733 - accuracy: 0.5815 - val_loss: 0.6891 - val_accuracy: 0.5512\n",
            "Epoch 125/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6738 - accuracy: 0.5792\n",
            "Epoch 125: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6738 - accuracy: 0.5794 - val_loss: 0.6908 - val_accuracy: 0.5450\n",
            "Epoch 126/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6724 - accuracy: 0.5800\n",
            "Epoch 126: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6726 - accuracy: 0.5795 - val_loss: 0.6879 - val_accuracy: 0.5488\n",
            "Epoch 127/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6730 - accuracy: 0.5835\n",
            "Epoch 127: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6730 - accuracy: 0.5835 - val_loss: 0.6896 - val_accuracy: 0.5450\n",
            "Epoch 128/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6740 - accuracy: 0.5808\n",
            "Epoch 128: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6740 - accuracy: 0.5807 - val_loss: 0.6880 - val_accuracy: 0.5507\n",
            "Epoch 129/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.5847\n",
            "Epoch 129: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5848 - val_loss: 0.6860 - val_accuracy: 0.5479\n",
            "Epoch 130/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.5815\n",
            "Epoch 130: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6743 - accuracy: 0.5816 - val_loss: 0.6871 - val_accuracy: 0.5493\n",
            "Epoch 131/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.5826\n",
            "Epoch 131: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6731 - accuracy: 0.5825 - val_loss: 0.6881 - val_accuracy: 0.5469\n",
            "Epoch 132/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.5809\n",
            "Epoch 132: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6731 - accuracy: 0.5809 - val_loss: 0.6882 - val_accuracy: 0.5512\n",
            "Epoch 133/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5790\n",
            "Epoch 133: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6733 - accuracy: 0.5789 - val_loss: 0.6859 - val_accuracy: 0.5512\n",
            "Epoch 134/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5823\n",
            "Epoch 134: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6727 - accuracy: 0.5822 - val_loss: 0.6933 - val_accuracy: 0.5397\n",
            "Epoch 135/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6747 - accuracy: 0.5791\n",
            "Epoch 135: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6747 - accuracy: 0.5793 - val_loss: 0.6866 - val_accuracy: 0.5570\n",
            "Epoch 136/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.5816\n",
            "Epoch 136: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5817 - val_loss: 0.6854 - val_accuracy: 0.5589\n",
            "Epoch 137/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6746 - accuracy: 0.5771\n",
            "Epoch 137: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6746 - accuracy: 0.5771 - val_loss: 0.6872 - val_accuracy: 0.5541\n",
            "Epoch 138/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.5799\n",
            "Epoch 138: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6732 - accuracy: 0.5802 - val_loss: 0.6909 - val_accuracy: 0.5469\n",
            "Epoch 139/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5835\n",
            "Epoch 139: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6727 - accuracy: 0.5833 - val_loss: 0.6899 - val_accuracy: 0.5498\n",
            "Epoch 140/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6735 - accuracy: 0.5804\n",
            "Epoch 140: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6735 - accuracy: 0.5804 - val_loss: 0.6924 - val_accuracy: 0.5483\n",
            "Epoch 141/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6739 - accuracy: 0.5782\n",
            "Epoch 141: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6740 - accuracy: 0.5781 - val_loss: 0.6880 - val_accuracy: 0.5584\n",
            "Epoch 142/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6732 - accuracy: 0.5809\n",
            "Epoch 142: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6732 - accuracy: 0.5809 - val_loss: 0.6895 - val_accuracy: 0.5512\n",
            "Epoch 143/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6727 - accuracy: 0.5829\n",
            "Epoch 143: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6727 - accuracy: 0.5829 - val_loss: 0.6878 - val_accuracy: 0.5551\n",
            "Epoch 144/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6728 - accuracy: 0.5813\n",
            "Epoch 144: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6727 - accuracy: 0.5815 - val_loss: 0.6914 - val_accuracy: 0.5483\n",
            "Epoch 145/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6736 - accuracy: 0.5821\n",
            "Epoch 145: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6736 - accuracy: 0.5822 - val_loss: 0.6895 - val_accuracy: 0.5522\n",
            "Epoch 146/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6728 - accuracy: 0.5831\n",
            "Epoch 146: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6728 - accuracy: 0.5832 - val_loss: 0.6904 - val_accuracy: 0.5493\n",
            "Epoch 147/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.5820\n",
            "Epoch 147: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6725 - accuracy: 0.5817 - val_loss: 0.6882 - val_accuracy: 0.5560\n",
            "Epoch 148/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.5814\n",
            "Epoch 148: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6723 - accuracy: 0.5815 - val_loss: 0.6872 - val_accuracy: 0.5599\n",
            "Epoch 149/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6732 - accuracy: 0.5818\n",
            "Epoch 149: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6734 - accuracy: 0.5815 - val_loss: 0.6895 - val_accuracy: 0.5493\n",
            "Epoch 150/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6728 - accuracy: 0.5802\n",
            "Epoch 150: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6727 - accuracy: 0.5803 - val_loss: 0.6918 - val_accuracy: 0.5464\n",
            "Epoch 151/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5839\n",
            "Epoch 151: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5842 - val_loss: 0.6871 - val_accuracy: 0.5522\n",
            "Epoch 152/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.5782\n",
            "Epoch 152: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5788 - val_loss: 0.6872 - val_accuracy: 0.5570\n",
            "Epoch 153/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6727 - accuracy: 0.5787\n",
            "Epoch 153: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6727 - accuracy: 0.5788 - val_loss: 0.6892 - val_accuracy: 0.5488\n",
            "Epoch 154/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6728 - accuracy: 0.5832\n",
            "Epoch 154: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6727 - accuracy: 0.5833 - val_loss: 0.6879 - val_accuracy: 0.5575\n",
            "Epoch 155/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.5806\n",
            "Epoch 155: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6726 - accuracy: 0.5805 - val_loss: 0.6862 - val_accuracy: 0.5642\n",
            "Epoch 156/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6724 - accuracy: 0.5824\n",
            "Epoch 156: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6723 - accuracy: 0.5825 - val_loss: 0.6913 - val_accuracy: 0.5430\n",
            "Epoch 157/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5850\n",
            "Epoch 157: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5846 - val_loss: 0.6897 - val_accuracy: 0.5440\n",
            "Epoch 158/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.5858\n",
            "Epoch 158: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6724 - accuracy: 0.5857 - val_loss: 0.6864 - val_accuracy: 0.5594\n",
            "Epoch 159/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5860\n",
            "Epoch 159: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6713 - accuracy: 0.5861 - val_loss: 0.6916 - val_accuracy: 0.5493\n",
            "Epoch 160/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6728 - accuracy: 0.5810\n",
            "Epoch 160: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6731 - accuracy: 0.5804 - val_loss: 0.6920 - val_accuracy: 0.5450\n",
            "Epoch 161/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5865\n",
            "Epoch 161: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5863 - val_loss: 0.6880 - val_accuracy: 0.5517\n",
            "Epoch 162/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6727 - accuracy: 0.5798\n",
            "Epoch 162: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6728 - accuracy: 0.5799 - val_loss: 0.6916 - val_accuracy: 0.5411\n",
            "Epoch 163/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5857\n",
            "Epoch 163: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5854 - val_loss: 0.6902 - val_accuracy: 0.5488\n",
            "Epoch 164/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6738 - accuracy: 0.5814\n",
            "Epoch 164: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6737 - accuracy: 0.5816 - val_loss: 0.6875 - val_accuracy: 0.5560\n",
            "Epoch 165/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5844\n",
            "Epoch 165: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5843 - val_loss: 0.6900 - val_accuracy: 0.5522\n",
            "Epoch 166/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.5857\n",
            "Epoch 166: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6724 - accuracy: 0.5858 - val_loss: 0.6868 - val_accuracy: 0.5584\n",
            "Epoch 167/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.5771\n",
            "Epoch 167: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6733 - accuracy: 0.5774 - val_loss: 0.6863 - val_accuracy: 0.5604\n",
            "Epoch 168/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.5806\n",
            "Epoch 168: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6728 - accuracy: 0.5809 - val_loss: 0.6878 - val_accuracy: 0.5546\n",
            "Epoch 169/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.5829\n",
            "Epoch 169: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6722 - accuracy: 0.5827 - val_loss: 0.6921 - val_accuracy: 0.5430\n",
            "Epoch 170/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.5854\n",
            "Epoch 170: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6724 - accuracy: 0.5849 - val_loss: 0.6908 - val_accuracy: 0.5455\n",
            "Epoch 171/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5856\n",
            "Epoch 171: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5855 - val_loss: 0.6865 - val_accuracy: 0.5589\n",
            "Epoch 172/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.5816\n",
            "Epoch 172: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6730 - accuracy: 0.5816 - val_loss: 0.6886 - val_accuracy: 0.5527\n",
            "Epoch 173/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6728 - accuracy: 0.5817\n",
            "Epoch 173: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6728 - accuracy: 0.5817 - val_loss: 0.6865 - val_accuracy: 0.5556\n",
            "Epoch 174/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5879\n",
            "Epoch 174: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5876 - val_loss: 0.6895 - val_accuracy: 0.5455\n",
            "Epoch 175/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.5828\n",
            "Epoch 175: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6721 - accuracy: 0.5827 - val_loss: 0.6875 - val_accuracy: 0.5580\n",
            "Epoch 176/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5831\n",
            "Epoch 176: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6725 - accuracy: 0.5833 - val_loss: 0.6880 - val_accuracy: 0.5575\n",
            "Epoch 177/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.5819\n",
            "Epoch 177: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6722 - accuracy: 0.5819 - val_loss: 0.6878 - val_accuracy: 0.5541\n",
            "Epoch 178/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5871\n",
            "Epoch 178: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5869 - val_loss: 0.6855 - val_accuracy: 0.5671\n",
            "Epoch 179/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.5842\n",
            "Epoch 179: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6734 - accuracy: 0.5840 - val_loss: 0.6886 - val_accuracy: 0.5532\n",
            "Epoch 180/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5797\n",
            "Epoch 180: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6724 - accuracy: 0.5801 - val_loss: 0.6893 - val_accuracy: 0.5565\n",
            "Epoch 181/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6735 - accuracy: 0.5789\n",
            "Epoch 181: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6736 - accuracy: 0.5790 - val_loss: 0.6912 - val_accuracy: 0.5363\n",
            "Epoch 182/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5832\n",
            "Epoch 182: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5831 - val_loss: 0.6849 - val_accuracy: 0.5661\n",
            "Epoch 183/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6720 - accuracy: 0.5825\n",
            "Epoch 183: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5825 - val_loss: 0.6891 - val_accuracy: 0.5556\n",
            "Epoch 184/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6735 - accuracy: 0.5800\n",
            "Epoch 184: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6735 - accuracy: 0.5798 - val_loss: 0.6881 - val_accuracy: 0.5580\n",
            "Epoch 185/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6733 - accuracy: 0.5805\n",
            "Epoch 185: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6734 - accuracy: 0.5803 - val_loss: 0.6862 - val_accuracy: 0.5580\n",
            "Epoch 186/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.5844\n",
            "Epoch 186: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6731 - accuracy: 0.5844 - val_loss: 0.6897 - val_accuracy: 0.5483\n",
            "Epoch 187/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5871\n",
            "Epoch 187: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5870 - val_loss: 0.6924 - val_accuracy: 0.5450\n",
            "Epoch 188/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6736 - accuracy: 0.5800\n",
            "Epoch 188: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6737 - accuracy: 0.5798 - val_loss: 0.6865 - val_accuracy: 0.5700\n",
            "Epoch 189/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5857\n",
            "Epoch 189: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5857 - val_loss: 0.6884 - val_accuracy: 0.5575\n",
            "Epoch 190/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.5827\n",
            "Epoch 190: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5833 - val_loss: 0.6900 - val_accuracy: 0.5498\n",
            "Epoch 191/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5839\n",
            "Epoch 191: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5841 - val_loss: 0.6876 - val_accuracy: 0.5580\n",
            "Epoch 192/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5851\n",
            "Epoch 192: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5848 - val_loss: 0.6884 - val_accuracy: 0.5565\n",
            "Epoch 193/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5821\n",
            "Epoch 193: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6727 - accuracy: 0.5820 - val_loss: 0.6905 - val_accuracy: 0.5440\n",
            "Epoch 194/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5836\n",
            "Epoch 194: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5836 - val_loss: 0.6893 - val_accuracy: 0.5455\n",
            "Epoch 195/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5870\n",
            "Epoch 195: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5870 - val_loss: 0.6892 - val_accuracy: 0.5469\n",
            "Epoch 196/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6719 - accuracy: 0.5861\n",
            "Epoch 196: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5861 - val_loss: 0.6878 - val_accuracy: 0.5575\n",
            "Epoch 197/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5828\n",
            "Epoch 197: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5826 - val_loss: 0.6907 - val_accuracy: 0.5469\n",
            "Epoch 198/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5845\n",
            "Epoch 198: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5845 - val_loss: 0.6899 - val_accuracy: 0.5402\n",
            "Epoch 199/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5881\n",
            "Epoch 199: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5881 - val_loss: 0.6898 - val_accuracy: 0.5522\n",
            "Epoch 200/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6744 - accuracy: 0.5773\n",
            "Epoch 200: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6745 - accuracy: 0.5773 - val_loss: 0.6918 - val_accuracy: 0.5416\n",
            "Epoch 201/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.5829\n",
            "Epoch 201: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6725 - accuracy: 0.5828 - val_loss: 0.6876 - val_accuracy: 0.5512\n",
            "Epoch 202/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5841\n",
            "Epoch 202: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5841 - val_loss: 0.6872 - val_accuracy: 0.5532\n",
            "Epoch 203/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5823\n",
            "Epoch 203: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5820 - val_loss: 0.6887 - val_accuracy: 0.5570\n",
            "Epoch 204/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.5844\n",
            "Epoch 204: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6723 - accuracy: 0.5842 - val_loss: 0.6908 - val_accuracy: 0.5464\n",
            "Epoch 205/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5848\n",
            "Epoch 205: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5849 - val_loss: 0.6941 - val_accuracy: 0.5426\n",
            "Epoch 206/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5807\n",
            "Epoch 206: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5801 - val_loss: 0.6896 - val_accuracy: 0.5493\n",
            "Epoch 207/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5848\n",
            "Epoch 207: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5851 - val_loss: 0.6930 - val_accuracy: 0.5368\n",
            "Epoch 208/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5856\n",
            "Epoch 208: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5854 - val_loss: 0.6909 - val_accuracy: 0.5498\n",
            "Epoch 209/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6719 - accuracy: 0.5839\n",
            "Epoch 209: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5839 - val_loss: 0.6882 - val_accuracy: 0.5594\n",
            "Epoch 210/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5822\n",
            "Epoch 210: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5824 - val_loss: 0.6885 - val_accuracy: 0.5575\n",
            "Epoch 211/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6731 - accuracy: 0.5799\n",
            "Epoch 211: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6732 - accuracy: 0.5801 - val_loss: 0.6896 - val_accuracy: 0.5479\n",
            "Epoch 212/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5826\n",
            "Epoch 212: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5824 - val_loss: 0.6918 - val_accuracy: 0.5421\n",
            "Epoch 213/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5854\n",
            "Epoch 213: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5852 - val_loss: 0.6911 - val_accuracy: 0.5474\n",
            "Epoch 214/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5814\n",
            "Epoch 214: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5816 - val_loss: 0.6874 - val_accuracy: 0.5580\n",
            "Epoch 215/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5829\n",
            "Epoch 215: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6725 - accuracy: 0.5831 - val_loss: 0.6909 - val_accuracy: 0.5488\n",
            "Epoch 216/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5832\n",
            "Epoch 216: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5832 - val_loss: 0.6917 - val_accuracy: 0.5402\n",
            "Epoch 217/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5861\n",
            "Epoch 217: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5862 - val_loss: 0.6924 - val_accuracy: 0.5411\n",
            "Epoch 218/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.5838\n",
            "Epoch 218: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5838 - val_loss: 0.6897 - val_accuracy: 0.5455\n",
            "Epoch 219/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5863\n",
            "Epoch 219: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5861 - val_loss: 0.6903 - val_accuracy: 0.5503\n",
            "Epoch 220/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5848\n",
            "Epoch 220: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5847 - val_loss: 0.6898 - val_accuracy: 0.5570\n",
            "Epoch 221/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5832\n",
            "Epoch 221: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5831 - val_loss: 0.6911 - val_accuracy: 0.5512\n",
            "Epoch 222/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5845\n",
            "Epoch 222: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5852 - val_loss: 0.6924 - val_accuracy: 0.5445\n",
            "Epoch 223/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6729 - accuracy: 0.5855\n",
            "Epoch 223: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5856 - val_loss: 0.6864 - val_accuracy: 0.5560\n",
            "Epoch 224/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5814\n",
            "Epoch 224: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6726 - accuracy: 0.5815 - val_loss: 0.6908 - val_accuracy: 0.5488\n",
            "Epoch 225/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5864\n",
            "Epoch 225: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5863 - val_loss: 0.6894 - val_accuracy: 0.5507\n",
            "Epoch 226/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5832\n",
            "Epoch 226: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6705 - accuracy: 0.5833 - val_loss: 0.6899 - val_accuracy: 0.5503\n",
            "Epoch 227/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.5865\n",
            "Epoch 227: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6721 - accuracy: 0.5865 - val_loss: 0.6919 - val_accuracy: 0.5474\n",
            "Epoch 228/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6707 - accuracy: 0.5878\n",
            "Epoch 228: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5878 - val_loss: 0.6881 - val_accuracy: 0.5527\n",
            "Epoch 229/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5864\n",
            "Epoch 229: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5864 - val_loss: 0.6901 - val_accuracy: 0.5483\n",
            "Epoch 230/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.5825\n",
            "Epoch 230: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6723 - accuracy: 0.5825 - val_loss: 0.6903 - val_accuracy: 0.5421\n",
            "Epoch 231/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5846\n",
            "Epoch 231: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5847 - val_loss: 0.6892 - val_accuracy: 0.5455\n",
            "Epoch 232/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6724 - accuracy: 0.5809\n",
            "Epoch 232: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6723 - accuracy: 0.5811 - val_loss: 0.6882 - val_accuracy: 0.5512\n",
            "Epoch 233/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.5841\n",
            "Epoch 233: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6722 - accuracy: 0.5842 - val_loss: 0.6862 - val_accuracy: 0.5589\n",
            "Epoch 234/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5841\n",
            "Epoch 234: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5841 - val_loss: 0.6888 - val_accuracy: 0.5512\n",
            "Epoch 235/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5868\n",
            "Epoch 235: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5875 - val_loss: 0.6902 - val_accuracy: 0.5430\n",
            "Epoch 236/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5824\n",
            "Epoch 236: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5824 - val_loss: 0.6931 - val_accuracy: 0.5349\n",
            "Epoch 237/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5875\n",
            "Epoch 237: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6707 - accuracy: 0.5875 - val_loss: 0.6942 - val_accuracy: 0.5339\n",
            "Epoch 238/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5834\n",
            "Epoch 238: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6711 - accuracy: 0.5835 - val_loss: 0.6920 - val_accuracy: 0.5450\n",
            "Epoch 239/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.5845\n",
            "Epoch 239: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6721 - accuracy: 0.5845 - val_loss: 0.6881 - val_accuracy: 0.5522\n",
            "Epoch 240/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5842\n",
            "Epoch 240: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5841 - val_loss: 0.6924 - val_accuracy: 0.5493\n",
            "Epoch 241/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5840\n",
            "Epoch 241: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5842 - val_loss: 0.6917 - val_accuracy: 0.5445\n",
            "Epoch 242/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6723 - accuracy: 0.5827\n",
            "Epoch 242: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6723 - accuracy: 0.5828 - val_loss: 0.6886 - val_accuracy: 0.5493\n",
            "Epoch 243/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5884\n",
            "Epoch 243: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5882 - val_loss: 0.6919 - val_accuracy: 0.5349\n",
            "Epoch 244/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.5849\n",
            "Epoch 244: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6724 - accuracy: 0.5850 - val_loss: 0.6919 - val_accuracy: 0.5378\n",
            "Epoch 245/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6725 - accuracy: 0.5836\n",
            "Epoch 245: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6724 - accuracy: 0.5838 - val_loss: 0.6902 - val_accuracy: 0.5382\n",
            "Epoch 246/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5850\n",
            "Epoch 246: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5849 - val_loss: 0.6920 - val_accuracy: 0.5402\n",
            "Epoch 247/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5835\n",
            "Epoch 247: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5835 - val_loss: 0.6908 - val_accuracy: 0.5426\n",
            "Epoch 248/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6713 - accuracy: 0.5820\n",
            "Epoch 248: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5820 - val_loss: 0.6916 - val_accuracy: 0.5421\n",
            "Epoch 249/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5870\n",
            "Epoch 249: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5873 - val_loss: 0.6902 - val_accuracy: 0.5450\n",
            "Epoch 250/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5833\n",
            "Epoch 250: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6709 - accuracy: 0.5832 - val_loss: 0.6984 - val_accuracy: 0.5310\n",
            "Epoch 251/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5839\n",
            "Epoch 251: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5835 - val_loss: 0.6947 - val_accuracy: 0.5416\n",
            "Epoch 252/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6713 - accuracy: 0.5842\n",
            "Epoch 252: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5842 - val_loss: 0.6908 - val_accuracy: 0.5440\n",
            "Epoch 253/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5818\n",
            "Epoch 253: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5819 - val_loss: 0.6924 - val_accuracy: 0.5411\n",
            "Epoch 254/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.5837\n",
            "Epoch 254: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5837 - val_loss: 0.6881 - val_accuracy: 0.5450\n",
            "Epoch 255/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.5846\n",
            "Epoch 255: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5846 - val_loss: 0.6889 - val_accuracy: 0.5507\n",
            "Epoch 256/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5850\n",
            "Epoch 256: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5852 - val_loss: 0.6901 - val_accuracy: 0.5479\n",
            "Epoch 257/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5810\n",
            "Epoch 257: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5810 - val_loss: 0.6894 - val_accuracy: 0.5498\n",
            "Epoch 258/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5839\n",
            "Epoch 258: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5836 - val_loss: 0.6915 - val_accuracy: 0.5406\n",
            "Epoch 259/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5837\n",
            "Epoch 259: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5837 - val_loss: 0.6917 - val_accuracy: 0.5378\n",
            "Epoch 260/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5868\n",
            "Epoch 260: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5867 - val_loss: 0.6903 - val_accuracy: 0.5445\n",
            "Epoch 261/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5826\n",
            "Epoch 261: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5824 - val_loss: 0.6905 - val_accuracy: 0.5455\n",
            "Epoch 262/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.5847\n",
            "Epoch 262: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6716 - accuracy: 0.5847 - val_loss: 0.6909 - val_accuracy: 0.5406\n",
            "Epoch 263/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5833\n",
            "Epoch 263: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5836 - val_loss: 0.6899 - val_accuracy: 0.5474\n",
            "Epoch 264/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5828\n",
            "Epoch 264: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5828 - val_loss: 0.6899 - val_accuracy: 0.5406\n",
            "Epoch 265/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5878\n",
            "Epoch 265: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5881 - val_loss: 0.6873 - val_accuracy: 0.5546\n",
            "Epoch 266/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5838\n",
            "Epoch 266: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5839 - val_loss: 0.6914 - val_accuracy: 0.5464\n",
            "Epoch 267/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6713 - accuracy: 0.5871\n",
            "Epoch 267: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5871 - val_loss: 0.6928 - val_accuracy: 0.5421\n",
            "Epoch 268/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5842\n",
            "Epoch 268: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5836 - val_loss: 0.6931 - val_accuracy: 0.5445\n",
            "Epoch 269/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5870\n",
            "Epoch 269: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5869 - val_loss: 0.6926 - val_accuracy: 0.5426\n",
            "Epoch 270/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5848\n",
            "Epoch 270: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5847 - val_loss: 0.6896 - val_accuracy: 0.5469\n",
            "Epoch 271/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5872\n",
            "Epoch 271: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5870 - val_loss: 0.6873 - val_accuracy: 0.5512\n",
            "Epoch 272/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5863\n",
            "Epoch 272: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5863 - val_loss: 0.6887 - val_accuracy: 0.5522\n",
            "Epoch 273/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5839\n",
            "Epoch 273: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5836 - val_loss: 0.6894 - val_accuracy: 0.5488\n",
            "Epoch 274/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5841\n",
            "Epoch 274: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5842 - val_loss: 0.6913 - val_accuracy: 0.5392\n",
            "Epoch 275/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5878\n",
            "Epoch 275: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6702 - accuracy: 0.5879 - val_loss: 0.6906 - val_accuracy: 0.5464\n",
            "Epoch 276/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6724 - accuracy: 0.5843\n",
            "Epoch 276: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6724 - accuracy: 0.5846 - val_loss: 0.6901 - val_accuracy: 0.5498\n",
            "Epoch 277/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5827\n",
            "Epoch 277: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5832 - val_loss: 0.6888 - val_accuracy: 0.5517\n",
            "Epoch 278/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5841\n",
            "Epoch 278: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5840 - val_loss: 0.6923 - val_accuracy: 0.5421\n",
            "Epoch 279/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5829\n",
            "Epoch 279: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5828 - val_loss: 0.6903 - val_accuracy: 0.5450\n",
            "Epoch 280/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5822\n",
            "Epoch 280: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5820 - val_loss: 0.6893 - val_accuracy: 0.5560\n",
            "Epoch 281/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5865\n",
            "Epoch 281: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5867 - val_loss: 0.6856 - val_accuracy: 0.5551\n",
            "Epoch 282/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.5901\n",
            "Epoch 282: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6701 - accuracy: 0.5901 - val_loss: 0.6883 - val_accuracy: 0.5507\n",
            "Epoch 283/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6726 - accuracy: 0.5823\n",
            "Epoch 283: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6726 - accuracy: 0.5822 - val_loss: 0.6878 - val_accuracy: 0.5541\n",
            "Epoch 284/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5827\n",
            "Epoch 284: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5830 - val_loss: 0.6913 - val_accuracy: 0.5479\n",
            "Epoch 285/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5805\n",
            "Epoch 285: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5806 - val_loss: 0.6903 - val_accuracy: 0.5532\n",
            "Epoch 286/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5872\n",
            "Epoch 286: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5876 - val_loss: 0.6884 - val_accuracy: 0.5483\n",
            "Epoch 287/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5847\n",
            "Epoch 287: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5846 - val_loss: 0.6879 - val_accuracy: 0.5512\n",
            "Epoch 288/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.5817\n",
            "Epoch 288: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6723 - accuracy: 0.5819 - val_loss: 0.6882 - val_accuracy: 0.5589\n",
            "Epoch 289/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5854\n",
            "Epoch 289: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5855 - val_loss: 0.6923 - val_accuracy: 0.5450\n",
            "Epoch 290/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5863\n",
            "Epoch 290: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5865 - val_loss: 0.6887 - val_accuracy: 0.5522\n",
            "Epoch 291/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5886\n",
            "Epoch 291: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5882 - val_loss: 0.6899 - val_accuracy: 0.5455\n",
            "Epoch 292/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5833\n",
            "Epoch 292: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5832 - val_loss: 0.6887 - val_accuracy: 0.5474\n",
            "Epoch 293/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6717 - accuracy: 0.5827\n",
            "Epoch 293: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5827 - val_loss: 0.6923 - val_accuracy: 0.5430\n",
            "Epoch 294/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.5857\n",
            "Epoch 294: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5857 - val_loss: 0.6879 - val_accuracy: 0.5430\n",
            "Epoch 295/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5834\n",
            "Epoch 295: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6713 - accuracy: 0.5834 - val_loss: 0.6876 - val_accuracy: 0.5469\n",
            "Epoch 296/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5808\n",
            "Epoch 296: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5808 - val_loss: 0.6906 - val_accuracy: 0.5416\n",
            "Epoch 297/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5878\n",
            "Epoch 297: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5881 - val_loss: 0.6875 - val_accuracy: 0.5503\n",
            "Epoch 298/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5894\n",
            "Epoch 298: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5893 - val_loss: 0.6881 - val_accuracy: 0.5512\n",
            "Epoch 299/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5835\n",
            "Epoch 299: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5836 - val_loss: 0.6916 - val_accuracy: 0.5498\n",
            "Epoch 300/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5827\n",
            "Epoch 300: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5830 - val_loss: 0.6888 - val_accuracy: 0.5474\n",
            "Epoch 301/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5820\n",
            "Epoch 301: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6715 - accuracy: 0.5819 - val_loss: 0.6890 - val_accuracy: 0.5474\n",
            "Epoch 302/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5872\n",
            "Epoch 302: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5872 - val_loss: 0.6945 - val_accuracy: 0.5358\n",
            "Epoch 303/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5840\n",
            "Epoch 303: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6705 - accuracy: 0.5837 - val_loss: 0.6935 - val_accuracy: 0.5397\n",
            "Epoch 304/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6701 - accuracy: 0.5849\n",
            "Epoch 304: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6700 - accuracy: 0.5851 - val_loss: 0.6903 - val_accuracy: 0.5421\n",
            "Epoch 305/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5845\n",
            "Epoch 305: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6702 - accuracy: 0.5846 - val_loss: 0.6923 - val_accuracy: 0.5402\n",
            "Epoch 306/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6714 - accuracy: 0.5866\n",
            "Epoch 306: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5866 - val_loss: 0.6873 - val_accuracy: 0.5488\n",
            "Epoch 307/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5834\n",
            "Epoch 307: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5840 - val_loss: 0.6932 - val_accuracy: 0.5455\n",
            "Epoch 308/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5822\n",
            "Epoch 308: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6718 - accuracy: 0.5825 - val_loss: 0.6909 - val_accuracy: 0.5469\n",
            "Epoch 309/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5856\n",
            "Epoch 309: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5856 - val_loss: 0.6904 - val_accuracy: 0.5479\n",
            "Epoch 310/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5830\n",
            "Epoch 310: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5830 - val_loss: 0.6863 - val_accuracy: 0.5556\n",
            "Epoch 311/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5846\n",
            "Epoch 311: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5845 - val_loss: 0.6886 - val_accuracy: 0.5488\n",
            "Epoch 312/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5844\n",
            "Epoch 312: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5845 - val_loss: 0.6870 - val_accuracy: 0.5450\n",
            "Epoch 313/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5820\n",
            "Epoch 313: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5820 - val_loss: 0.6906 - val_accuracy: 0.5430\n",
            "Epoch 314/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5839\n",
            "Epoch 314: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5837 - val_loss: 0.6869 - val_accuracy: 0.5498\n",
            "Epoch 315/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6730 - accuracy: 0.5827\n",
            "Epoch 315: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5827 - val_loss: 0.6876 - val_accuracy: 0.5503\n",
            "Epoch 316/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5841\n",
            "Epoch 316: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5840 - val_loss: 0.6883 - val_accuracy: 0.5483\n",
            "Epoch 317/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.5863\n",
            "Epoch 317: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5863 - val_loss: 0.6901 - val_accuracy: 0.5445\n",
            "Epoch 318/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5824\n",
            "Epoch 318: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5826 - val_loss: 0.6899 - val_accuracy: 0.5483\n",
            "Epoch 319/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5835\n",
            "Epoch 319: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5834 - val_loss: 0.6918 - val_accuracy: 0.5416\n",
            "Epoch 320/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6716 - accuracy: 0.5818\n",
            "Epoch 320: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6716 - accuracy: 0.5818 - val_loss: 0.6874 - val_accuracy: 0.5503\n",
            "Epoch 321/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5874\n",
            "Epoch 321: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5877 - val_loss: 0.6920 - val_accuracy: 0.5392\n",
            "Epoch 322/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6701 - accuracy: 0.5853\n",
            "Epoch 322: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6700 - accuracy: 0.5855 - val_loss: 0.6907 - val_accuracy: 0.5469\n",
            "Epoch 323/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.5822\n",
            "Epoch 323: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5822 - val_loss: 0.6893 - val_accuracy: 0.5493\n",
            "Epoch 324/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5815\n",
            "Epoch 324: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5813 - val_loss: 0.6916 - val_accuracy: 0.5493\n",
            "Epoch 325/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5845\n",
            "Epoch 325: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5843 - val_loss: 0.6907 - val_accuracy: 0.5464\n",
            "Epoch 326/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5866\n",
            "Epoch 326: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5868 - val_loss: 0.6911 - val_accuracy: 0.5479\n",
            "Epoch 327/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5840\n",
            "Epoch 327: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5839 - val_loss: 0.6921 - val_accuracy: 0.5435\n",
            "Epoch 328/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6698 - accuracy: 0.5871\n",
            "Epoch 328: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6698 - accuracy: 0.5872 - val_loss: 0.6882 - val_accuracy: 0.5416\n",
            "Epoch 329/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5874\n",
            "Epoch 329: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5873 - val_loss: 0.6898 - val_accuracy: 0.5406\n",
            "Epoch 330/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5851\n",
            "Epoch 330: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5851 - val_loss: 0.6830 - val_accuracy: 0.5599\n",
            "Epoch 331/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6725 - accuracy: 0.5811\n",
            "Epoch 331: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6725 - accuracy: 0.5811 - val_loss: 0.6903 - val_accuracy: 0.5445\n",
            "Epoch 332/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5818\n",
            "Epoch 332: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5816 - val_loss: 0.6869 - val_accuracy: 0.5498\n",
            "Epoch 333/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5847\n",
            "Epoch 333: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5845 - val_loss: 0.6940 - val_accuracy: 0.5358\n",
            "Epoch 334/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5883\n",
            "Epoch 334: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6705 - accuracy: 0.5881 - val_loss: 0.6923 - val_accuracy: 0.5430\n",
            "Epoch 335/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5835\n",
            "Epoch 335: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5835 - val_loss: 0.6908 - val_accuracy: 0.5397\n",
            "Epoch 336/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5846\n",
            "Epoch 336: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6702 - accuracy: 0.5852 - val_loss: 0.6873 - val_accuracy: 0.5459\n",
            "Epoch 337/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.5812\n",
            "Epoch 337: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6721 - accuracy: 0.5815 - val_loss: 0.6871 - val_accuracy: 0.5445\n",
            "Epoch 338/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5826\n",
            "Epoch 338: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5825 - val_loss: 0.6883 - val_accuracy: 0.5464\n",
            "Epoch 339/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5846\n",
            "Epoch 339: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5846 - val_loss: 0.6871 - val_accuracy: 0.5435\n",
            "Epoch 340/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5857\n",
            "Epoch 340: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5859 - val_loss: 0.6874 - val_accuracy: 0.5464\n",
            "Epoch 341/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5893\n",
            "Epoch 341: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5890 - val_loss: 0.6890 - val_accuracy: 0.5517\n",
            "Epoch 342/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5863\n",
            "Epoch 342: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5862 - val_loss: 0.6888 - val_accuracy: 0.5430\n",
            "Epoch 343/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5806\n",
            "Epoch 343: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5807 - val_loss: 0.6903 - val_accuracy: 0.5440\n",
            "Epoch 344/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6722 - accuracy: 0.5849\n",
            "Epoch 344: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6722 - accuracy: 0.5850 - val_loss: 0.6904 - val_accuracy: 0.5397\n",
            "Epoch 345/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6728 - accuracy: 0.5822\n",
            "Epoch 345: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6729 - accuracy: 0.5821 - val_loss: 0.6853 - val_accuracy: 0.5532\n",
            "Epoch 346/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5854\n",
            "Epoch 346: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5853 - val_loss: 0.6871 - val_accuracy: 0.5483\n",
            "Epoch 347/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6696 - accuracy: 0.5871\n",
            "Epoch 347: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6698 - accuracy: 0.5871 - val_loss: 0.6878 - val_accuracy: 0.5440\n",
            "Epoch 348/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5845\n",
            "Epoch 348: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5844 - val_loss: 0.6898 - val_accuracy: 0.5430\n",
            "Epoch 349/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6711 - accuracy: 0.5867\n",
            "Epoch 349: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5867 - val_loss: 0.6928 - val_accuracy: 0.5435\n",
            "Epoch 350/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5878\n",
            "Epoch 350: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5877 - val_loss: 0.6882 - val_accuracy: 0.5512\n",
            "Epoch 351/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5868\n",
            "Epoch 351: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5865 - val_loss: 0.6869 - val_accuracy: 0.5532\n",
            "Epoch 352/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6710 - accuracy: 0.5869\n",
            "Epoch 352: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5869 - val_loss: 0.6878 - val_accuracy: 0.5546\n",
            "Epoch 353/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5848\n",
            "Epoch 353: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5848 - val_loss: 0.6915 - val_accuracy: 0.5459\n",
            "Epoch 354/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6692 - accuracy: 0.5863\n",
            "Epoch 354: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6692 - accuracy: 0.5862 - val_loss: 0.6913 - val_accuracy: 0.5382\n",
            "Epoch 355/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5873\n",
            "Epoch 355: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5873 - val_loss: 0.6900 - val_accuracy: 0.5459\n",
            "Epoch 356/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.5885\n",
            "Epoch 356: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6700 - accuracy: 0.5886 - val_loss: 0.6896 - val_accuracy: 0.5450\n",
            "Epoch 357/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5831\n",
            "Epoch 357: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5830 - val_loss: 0.6895 - val_accuracy: 0.5469\n",
            "Epoch 358/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5851\n",
            "Epoch 358: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5851 - val_loss: 0.6886 - val_accuracy: 0.5488\n",
            "Epoch 359/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6727 - accuracy: 0.5832\n",
            "Epoch 359: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6726 - accuracy: 0.5832 - val_loss: 0.6912 - val_accuracy: 0.5363\n",
            "Epoch 360/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5867\n",
            "Epoch 360: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5868 - val_loss: 0.6919 - val_accuracy: 0.5387\n",
            "Epoch 361/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5844\n",
            "Epoch 361: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5845 - val_loss: 0.6924 - val_accuracy: 0.5397\n",
            "Epoch 362/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6697 - accuracy: 0.5892\n",
            "Epoch 362: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6697 - accuracy: 0.5892 - val_loss: 0.6890 - val_accuracy: 0.5426\n",
            "Epoch 363/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5837\n",
            "Epoch 363: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5833 - val_loss: 0.6912 - val_accuracy: 0.5406\n",
            "Epoch 364/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6721 - accuracy: 0.5830\n",
            "Epoch 364: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6721 - accuracy: 0.5830 - val_loss: 0.6892 - val_accuracy: 0.5387\n",
            "Epoch 365/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6718 - accuracy: 0.5845\n",
            "Epoch 365: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5846 - val_loss: 0.6896 - val_accuracy: 0.5416\n",
            "Epoch 366/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5843\n",
            "Epoch 366: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6714 - accuracy: 0.5839 - val_loss: 0.6873 - val_accuracy: 0.5430\n",
            "Epoch 367/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5898\n",
            "Epoch 367: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5896 - val_loss: 0.6890 - val_accuracy: 0.5459\n",
            "Epoch 368/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5833\n",
            "Epoch 368: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6719 - accuracy: 0.5832 - val_loss: 0.6891 - val_accuracy: 0.5445\n",
            "Epoch 369/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5831\n",
            "Epoch 369: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5832 - val_loss: 0.6888 - val_accuracy: 0.5450\n",
            "Epoch 370/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5867\n",
            "Epoch 370: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5866 - val_loss: 0.6874 - val_accuracy: 0.5469\n",
            "Epoch 371/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5874\n",
            "Epoch 371: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5870 - val_loss: 0.6876 - val_accuracy: 0.5450\n",
            "Epoch 372/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6706 - accuracy: 0.5857\n",
            "Epoch 372: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5857 - val_loss: 0.6891 - val_accuracy: 0.5426\n",
            "Epoch 373/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5903\n",
            "Epoch 373: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5903 - val_loss: 0.6922 - val_accuracy: 0.5411\n",
            "Epoch 374/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5842\n",
            "Epoch 374: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5842 - val_loss: 0.6913 - val_accuracy: 0.5459\n",
            "Epoch 375/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5849\n",
            "Epoch 375: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5848 - val_loss: 0.6887 - val_accuracy: 0.5464\n",
            "Epoch 376/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5853\n",
            "Epoch 376: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5853 - val_loss: 0.6886 - val_accuracy: 0.5546\n",
            "Epoch 377/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.5898\n",
            "Epoch 377: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6701 - accuracy: 0.5895 - val_loss: 0.6923 - val_accuracy: 0.5459\n",
            "Epoch 378/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5851\n",
            "Epoch 378: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5852 - val_loss: 0.6882 - val_accuracy: 0.5445\n",
            "Epoch 379/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5868\n",
            "Epoch 379: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6705 - accuracy: 0.5869 - val_loss: 0.6872 - val_accuracy: 0.5464\n",
            "Epoch 380/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5839\n",
            "Epoch 380: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6720 - accuracy: 0.5839 - val_loss: 0.6903 - val_accuracy: 0.5440\n",
            "Epoch 381/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5897\n",
            "Epoch 381: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5897 - val_loss: 0.6915 - val_accuracy: 0.5363\n",
            "Epoch 382/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5862\n",
            "Epoch 382: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5857 - val_loss: 0.6913 - val_accuracy: 0.5378\n",
            "Epoch 383/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5825\n",
            "Epoch 383: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5822 - val_loss: 0.6888 - val_accuracy: 0.5411\n",
            "Epoch 384/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6702 - accuracy: 0.5843\n",
            "Epoch 384: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6701 - accuracy: 0.5844 - val_loss: 0.6937 - val_accuracy: 0.5378\n",
            "Epoch 385/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5845\n",
            "Epoch 385: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5847 - val_loss: 0.6908 - val_accuracy: 0.5378\n",
            "Epoch 386/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6698 - accuracy: 0.5841\n",
            "Epoch 386: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6701 - accuracy: 0.5833 - val_loss: 0.6910 - val_accuracy: 0.5411\n",
            "Epoch 387/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.5804\n",
            "Epoch 387: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6721 - accuracy: 0.5804 - val_loss: 0.6909 - val_accuracy: 0.5334\n",
            "Epoch 388/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6696 - accuracy: 0.5885\n",
            "Epoch 388: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6698 - accuracy: 0.5882 - val_loss: 0.6897 - val_accuracy: 0.5315\n",
            "Epoch 389/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5824\n",
            "Epoch 389: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6716 - accuracy: 0.5824 - val_loss: 0.6930 - val_accuracy: 0.5392\n",
            "Epoch 390/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6727 - accuracy: 0.5837\n",
            "Epoch 390: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6726 - accuracy: 0.5841 - val_loss: 0.6917 - val_accuracy: 0.5426\n",
            "Epoch 391/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5878\n",
            "Epoch 391: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5877 - val_loss: 0.6914 - val_accuracy: 0.5421\n",
            "Epoch 392/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6709 - accuracy: 0.5841\n",
            "Epoch 392: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6709 - accuracy: 0.5841 - val_loss: 0.6885 - val_accuracy: 0.5493\n",
            "Epoch 393/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5809\n",
            "Epoch 393: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5807 - val_loss: 0.6937 - val_accuracy: 0.5406\n",
            "Epoch 394/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6695 - accuracy: 0.5881\n",
            "Epoch 394: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6695 - accuracy: 0.5881 - val_loss: 0.6901 - val_accuracy: 0.5416\n",
            "Epoch 395/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6699 - accuracy: 0.5873\n",
            "Epoch 395: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6699 - accuracy: 0.5873 - val_loss: 0.6889 - val_accuracy: 0.5435\n",
            "Epoch 396/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.5849\n",
            "Epoch 396: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6699 - accuracy: 0.5850 - val_loss: 0.6895 - val_accuracy: 0.5397\n",
            "Epoch 397/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5838\n",
            "Epoch 397: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5837 - val_loss: 0.6920 - val_accuracy: 0.5378\n",
            "Epoch 398/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5837\n",
            "Epoch 398: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5840 - val_loss: 0.6898 - val_accuracy: 0.5474\n",
            "Epoch 399/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5873\n",
            "Epoch 399: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5871 - val_loss: 0.6889 - val_accuracy: 0.5445\n",
            "Epoch 400/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5858\n",
            "Epoch 400: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5857 - val_loss: 0.6907 - val_accuracy: 0.5373\n",
            "Epoch 401/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5840\n",
            "Epoch 401: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5841 - val_loss: 0.6906 - val_accuracy: 0.5382\n",
            "Epoch 402/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6712 - accuracy: 0.5818\n",
            "Epoch 402: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5819 - val_loss: 0.6880 - val_accuracy: 0.5411\n",
            "Epoch 403/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5836\n",
            "Epoch 403: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5837 - val_loss: 0.6887 - val_accuracy: 0.5464\n",
            "Epoch 404/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5869\n",
            "Epoch 404: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5868 - val_loss: 0.6927 - val_accuracy: 0.5382\n",
            "Epoch 405/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5876\n",
            "Epoch 405: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6705 - accuracy: 0.5876 - val_loss: 0.6930 - val_accuracy: 0.5373\n",
            "Epoch 406/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5861\n",
            "Epoch 406: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5858 - val_loss: 0.6901 - val_accuracy: 0.5421\n",
            "Epoch 407/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5870\n",
            "Epoch 407: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5863 - val_loss: 0.6913 - val_accuracy: 0.5445\n",
            "Epoch 408/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5823\n",
            "Epoch 408: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6721 - accuracy: 0.5820 - val_loss: 0.6912 - val_accuracy: 0.5445\n",
            "Epoch 409/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6696 - accuracy: 0.5896\n",
            "Epoch 409: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6693 - accuracy: 0.5901 - val_loss: 0.6944 - val_accuracy: 0.5363\n",
            "Epoch 410/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5860\n",
            "Epoch 410: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5860 - val_loss: 0.6888 - val_accuracy: 0.5445\n",
            "Epoch 411/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.5836\n",
            "Epoch 411: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6701 - accuracy: 0.5835 - val_loss: 0.6909 - val_accuracy: 0.5402\n",
            "Epoch 412/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6691 - accuracy: 0.5913\n",
            "Epoch 412: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6691 - accuracy: 0.5912 - val_loss: 0.6932 - val_accuracy: 0.5397\n",
            "Epoch 413/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6719 - accuracy: 0.5805\n",
            "Epoch 413: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5806 - val_loss: 0.6905 - val_accuracy: 0.5445\n",
            "Epoch 414/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5873\n",
            "Epoch 414: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5869 - val_loss: 0.6921 - val_accuracy: 0.5426\n",
            "Epoch 415/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5849\n",
            "Epoch 415: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5849 - val_loss: 0.6918 - val_accuracy: 0.5430\n",
            "Epoch 416/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.5874\n",
            "Epoch 416: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6699 - accuracy: 0.5877 - val_loss: 0.6897 - val_accuracy: 0.5474\n",
            "Epoch 417/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5859\n",
            "Epoch 417: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5855 - val_loss: 0.6918 - val_accuracy: 0.5416\n",
            "Epoch 418/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6715 - accuracy: 0.5858\n",
            "Epoch 418: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6715 - accuracy: 0.5858 - val_loss: 0.6909 - val_accuracy: 0.5426\n",
            "Epoch 419/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5872\n",
            "Epoch 419: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5873 - val_loss: 0.6876 - val_accuracy: 0.5532\n",
            "Epoch 420/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5852\n",
            "Epoch 420: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5850 - val_loss: 0.6875 - val_accuracy: 0.5469\n",
            "Epoch 421/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5869\n",
            "Epoch 421: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5871 - val_loss: 0.6911 - val_accuracy: 0.5402\n",
            "Epoch 422/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5854\n",
            "Epoch 422: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5856 - val_loss: 0.6891 - val_accuracy: 0.5483\n",
            "Epoch 423/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.5895\n",
            "Epoch 423: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6699 - accuracy: 0.5894 - val_loss: 0.6884 - val_accuracy: 0.5445\n",
            "Epoch 424/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.5895\n",
            "Epoch 424: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6699 - accuracy: 0.5895 - val_loss: 0.6961 - val_accuracy: 0.5430\n",
            "Epoch 425/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.5846\n",
            "Epoch 425: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6712 - accuracy: 0.5846 - val_loss: 0.6899 - val_accuracy: 0.5430\n",
            "Epoch 426/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5843\n",
            "Epoch 426: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5844 - val_loss: 0.6865 - val_accuracy: 0.5532\n",
            "Epoch 427/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5854\n",
            "Epoch 427: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5857 - val_loss: 0.6930 - val_accuracy: 0.5416\n",
            "Epoch 428/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6688 - accuracy: 0.5885\n",
            "Epoch 428: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6689 - accuracy: 0.5883 - val_loss: 0.6944 - val_accuracy: 0.5339\n",
            "Epoch 429/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6717 - accuracy: 0.5829\n",
            "Epoch 429: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6718 - accuracy: 0.5827 - val_loss: 0.6877 - val_accuracy: 0.5479\n",
            "Epoch 430/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6713 - accuracy: 0.5848\n",
            "Epoch 430: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6712 - accuracy: 0.5852 - val_loss: 0.6909 - val_accuracy: 0.5479\n",
            "Epoch 431/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6695 - accuracy: 0.5868\n",
            "Epoch 431: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6694 - accuracy: 0.5870 - val_loss: 0.6938 - val_accuracy: 0.5426\n",
            "Epoch 432/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5857\n",
            "Epoch 432: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5857 - val_loss: 0.6867 - val_accuracy: 0.5493\n",
            "Epoch 433/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6696 - accuracy: 0.5877\n",
            "Epoch 433: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6696 - accuracy: 0.5877 - val_loss: 0.6914 - val_accuracy: 0.5435\n",
            "Epoch 434/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5861\n",
            "Epoch 434: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5867 - val_loss: 0.6926 - val_accuracy: 0.5435\n",
            "Epoch 435/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6697 - accuracy: 0.5881\n",
            "Epoch 435: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6697 - accuracy: 0.5883 - val_loss: 0.6881 - val_accuracy: 0.5498\n",
            "Epoch 436/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6712 - accuracy: 0.5870\n",
            "Epoch 436: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5870 - val_loss: 0.6941 - val_accuracy: 0.5411\n",
            "Epoch 437/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5871\n",
            "Epoch 437: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6711 - accuracy: 0.5869 - val_loss: 0.6908 - val_accuracy: 0.5368\n",
            "Epoch 438/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6703 - accuracy: 0.5865\n",
            "Epoch 438: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6703 - accuracy: 0.5865 - val_loss: 0.6941 - val_accuracy: 0.5397\n",
            "Epoch 439/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5870\n",
            "Epoch 439: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5870 - val_loss: 0.6956 - val_accuracy: 0.5387\n",
            "Epoch 440/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5857\n",
            "Epoch 440: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5855 - val_loss: 0.6891 - val_accuracy: 0.5474\n",
            "Epoch 441/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5857\n",
            "Epoch 441: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5860 - val_loss: 0.6902 - val_accuracy: 0.5397\n",
            "Epoch 442/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5856\n",
            "Epoch 442: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5853 - val_loss: 0.6946 - val_accuracy: 0.5426\n",
            "Epoch 443/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6708 - accuracy: 0.5854\n",
            "Epoch 443: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5854 - val_loss: 0.6927 - val_accuracy: 0.5363\n",
            "Epoch 444/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5864\n",
            "Epoch 444: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6705 - accuracy: 0.5864 - val_loss: 0.6925 - val_accuracy: 0.5378\n",
            "Epoch 445/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5869\n",
            "Epoch 445: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5869 - val_loss: 0.6901 - val_accuracy: 0.5430\n",
            "Epoch 446/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5851\n",
            "Epoch 446: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6705 - accuracy: 0.5853 - val_loss: 0.6875 - val_accuracy: 0.5483\n",
            "Epoch 447/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6707 - accuracy: 0.5869\n",
            "Epoch 447: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5868 - val_loss: 0.6920 - val_accuracy: 0.5368\n",
            "Epoch 448/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5805\n",
            "Epoch 448: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6713 - accuracy: 0.5806 - val_loss: 0.6898 - val_accuracy: 0.5488\n",
            "Epoch 449/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6698 - accuracy: 0.5880\n",
            "Epoch 449: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6698 - accuracy: 0.5882 - val_loss: 0.6896 - val_accuracy: 0.5488\n",
            "Epoch 450/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6695 - accuracy: 0.5883\n",
            "Epoch 450: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6696 - accuracy: 0.5882 - val_loss: 0.6914 - val_accuracy: 0.5479\n",
            "Epoch 451/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6708 - accuracy: 0.5869\n",
            "Epoch 451: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5869 - val_loss: 0.6881 - val_accuracy: 0.5483\n",
            "Epoch 452/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5883\n",
            "Epoch 452: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5879 - val_loss: 0.6899 - val_accuracy: 0.5488\n",
            "Epoch 453/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6695 - accuracy: 0.5880\n",
            "Epoch 453: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6694 - accuracy: 0.5882 - val_loss: 0.6907 - val_accuracy: 0.5411\n",
            "Epoch 454/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6704 - accuracy: 0.5885\n",
            "Epoch 454: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 4s 7ms/step - loss: 0.6704 - accuracy: 0.5885 - val_loss: 0.6883 - val_accuracy: 0.5445\n",
            "Epoch 455/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5873\n",
            "Epoch 455: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5874 - val_loss: 0.6880 - val_accuracy: 0.5440\n",
            "Epoch 456/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.5864\n",
            "Epoch 456: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6700 - accuracy: 0.5861 - val_loss: 0.6880 - val_accuracy: 0.5426\n",
            "Epoch 457/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5870\n",
            "Epoch 457: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6712 - accuracy: 0.5873 - val_loss: 0.6910 - val_accuracy: 0.5455\n",
            "Epoch 458/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6721 - accuracy: 0.5815\n",
            "Epoch 458: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6722 - accuracy: 0.5813 - val_loss: 0.6897 - val_accuracy: 0.5435\n",
            "Epoch 459/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5884\n",
            "Epoch 459: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6705 - accuracy: 0.5885 - val_loss: 0.6871 - val_accuracy: 0.5455\n",
            "Epoch 460/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6694 - accuracy: 0.5854\n",
            "Epoch 460: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6696 - accuracy: 0.5851 - val_loss: 0.6921 - val_accuracy: 0.5426\n",
            "Epoch 461/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5843\n",
            "Epoch 461: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5842 - val_loss: 0.6913 - val_accuracy: 0.5402\n",
            "Epoch 462/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5878\n",
            "Epoch 462: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5880 - val_loss: 0.6886 - val_accuracy: 0.5503\n",
            "Epoch 463/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6697 - accuracy: 0.5879\n",
            "Epoch 463: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 8ms/step - loss: 0.6696 - accuracy: 0.5882 - val_loss: 0.6890 - val_accuracy: 0.5455\n",
            "Epoch 464/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5896\n",
            "Epoch 464: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5894 - val_loss: 0.6885 - val_accuracy: 0.5488\n",
            "Epoch 465/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5857\n",
            "Epoch 465: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6705 - accuracy: 0.5858 - val_loss: 0.6892 - val_accuracy: 0.5426\n",
            "Epoch 466/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5871\n",
            "Epoch 466: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6705 - accuracy: 0.5868 - val_loss: 0.6872 - val_accuracy: 0.5440\n",
            "Epoch 467/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6700 - accuracy: 0.5896\n",
            "Epoch 467: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6700 - accuracy: 0.5898 - val_loss: 0.6882 - val_accuracy: 0.5464\n",
            "Epoch 468/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5856\n",
            "Epoch 468: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6704 - accuracy: 0.5857 - val_loss: 0.6890 - val_accuracy: 0.5503\n",
            "Epoch 469/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5859\n",
            "Epoch 469: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6707 - accuracy: 0.5863 - val_loss: 0.6917 - val_accuracy: 0.5445\n",
            "Epoch 470/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6704 - accuracy: 0.5831\n",
            "Epoch 470: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5832 - val_loss: 0.6951 - val_accuracy: 0.5483\n",
            "Epoch 471/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6701 - accuracy: 0.5827\n",
            "Epoch 471: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6701 - accuracy: 0.5825 - val_loss: 0.6899 - val_accuracy: 0.5464\n",
            "Epoch 472/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5871\n",
            "Epoch 472: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5870 - val_loss: 0.6883 - val_accuracy: 0.5416\n",
            "Epoch 473/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6690 - accuracy: 0.5879\n",
            "Epoch 473: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6690 - accuracy: 0.5879 - val_loss: 0.6902 - val_accuracy: 0.5532\n",
            "Epoch 474/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6705 - accuracy: 0.5856\n",
            "Epoch 474: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5854 - val_loss: 0.6895 - val_accuracy: 0.5479\n",
            "Epoch 475/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5859\n",
            "Epoch 475: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5863 - val_loss: 0.6873 - val_accuracy: 0.5464\n",
            "Epoch 476/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5848\n",
            "Epoch 476: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5848 - val_loss: 0.6867 - val_accuracy: 0.5488\n",
            "Epoch 477/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6716 - accuracy: 0.5859\n",
            "Epoch 477: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6717 - accuracy: 0.5860 - val_loss: 0.6882 - val_accuracy: 0.5488\n",
            "Epoch 478/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6701 - accuracy: 0.5872\n",
            "Epoch 478: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6701 - accuracy: 0.5871 - val_loss: 0.6927 - val_accuracy: 0.5507\n",
            "Epoch 479/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5870\n",
            "Epoch 479: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6702 - accuracy: 0.5874 - val_loss: 0.6899 - val_accuracy: 0.5493\n",
            "Epoch 480/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6692 - accuracy: 0.5882\n",
            "Epoch 480: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6692 - accuracy: 0.5882 - val_loss: 0.6887 - val_accuracy: 0.5498\n",
            "Epoch 481/500\n",
            "636/641 [============================>.] - ETA: 0s - loss: 0.6720 - accuracy: 0.5822\n",
            "Epoch 481: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6721 - accuracy: 0.5822 - val_loss: 0.6876 - val_accuracy: 0.5455\n",
            "Epoch 482/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6696 - accuracy: 0.5918\n",
            "Epoch 482: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6695 - accuracy: 0.5918 - val_loss: 0.6909 - val_accuracy: 0.5493\n",
            "Epoch 483/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6696 - accuracy: 0.5879\n",
            "Epoch 483: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6695 - accuracy: 0.5881 - val_loss: 0.6915 - val_accuracy: 0.5474\n",
            "Epoch 484/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5845\n",
            "Epoch 484: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6708 - accuracy: 0.5844 - val_loss: 0.6872 - val_accuracy: 0.5517\n",
            "Epoch 485/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6709 - accuracy: 0.5858\n",
            "Epoch 485: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5860 - val_loss: 0.6908 - val_accuracy: 0.5541\n",
            "Epoch 486/500\n",
            "641/641 [==============================] - ETA: 0s - loss: 0.6702 - accuracy: 0.5868\n",
            "Epoch 486: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6702 - accuracy: 0.5868 - val_loss: 0.6870 - val_accuracy: 0.5522\n",
            "Epoch 487/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5871\n",
            "Epoch 487: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5867 - val_loss: 0.6906 - val_accuracy: 0.5560\n",
            "Epoch 488/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5877\n",
            "Epoch 488: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6702 - accuracy: 0.5875 - val_loss: 0.6900 - val_accuracy: 0.5498\n",
            "Epoch 489/500\n",
            "640/641 [============================>.] - ETA: 0s - loss: 0.6697 - accuracy: 0.5881\n",
            "Epoch 489: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6698 - accuracy: 0.5881 - val_loss: 0.6907 - val_accuracy: 0.5512\n",
            "Epoch 490/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6697 - accuracy: 0.5920\n",
            "Epoch 490: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6698 - accuracy: 0.5918 - val_loss: 0.6907 - val_accuracy: 0.5556\n",
            "Epoch 491/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.5855\n",
            "Epoch 491: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6698 - accuracy: 0.5860 - val_loss: 0.6884 - val_accuracy: 0.5546\n",
            "Epoch 492/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6698 - accuracy: 0.5893\n",
            "Epoch 492: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6699 - accuracy: 0.5891 - val_loss: 0.6900 - val_accuracy: 0.5406\n",
            "Epoch 493/500\n",
            "639/641 [============================>.] - ETA: 0s - loss: 0.6706 - accuracy: 0.5866\n",
            "Epoch 493: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6706 - accuracy: 0.5865 - val_loss: 0.6882 - val_accuracy: 0.5450\n",
            "Epoch 494/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6711 - accuracy: 0.5825\n",
            "Epoch 494: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6711 - accuracy: 0.5827 - val_loss: 0.6883 - val_accuracy: 0.5507\n",
            "Epoch 495/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6714 - accuracy: 0.5807\n",
            "Epoch 495: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6713 - accuracy: 0.5810 - val_loss: 0.6898 - val_accuracy: 0.5536\n",
            "Epoch 496/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6701 - accuracy: 0.5882\n",
            "Epoch 496: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5881 - val_loss: 0.6889 - val_accuracy: 0.5459\n",
            "Epoch 497/500\n",
            "638/641 [============================>.] - ETA: 0s - loss: 0.6708 - accuracy: 0.5884\n",
            "Epoch 497: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6709 - accuracy: 0.5883 - val_loss: 0.6897 - val_accuracy: 0.5488\n",
            "Epoch 498/500\n",
            "634/641 [============================>.] - ETA: 0s - loss: 0.6703 - accuracy: 0.5892\n",
            "Epoch 498: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6703 - accuracy: 0.5889 - val_loss: 0.6877 - val_accuracy: 0.5517\n",
            "Epoch 499/500\n",
            "637/641 [============================>.] - ETA: 0s - loss: 0.6710 - accuracy: 0.5851\n",
            "Epoch 499: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6710 - accuracy: 0.5851 - val_loss: 0.6904 - val_accuracy: 0.5483\n",
            "Epoch 500/500\n",
            "635/641 [============================>.] - ETA: 0s - loss: 0.6699 - accuracy: 0.5844\n",
            "Epoch 500: saving model to training_1/cp.ckpt\n",
            "641/641 [==============================] - 5s 7ms/step - loss: 0.6701 - accuracy: 0.5842 - val_loss: 0.6888 - val_accuracy: 0.5517\n"
          ]
        }
      ],
      "source": [
        "model = sequence_model(learning_rate, feature_num)\n",
        "\n",
        "history = model.fit(x, y, epochs=500,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[cp_callback])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 927
        },
        "id": "a_AwDlSZclVa",
        "outputId": "78a8ccf8-02d5-4df1-8155-1e621d9b1b97"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAADXA0lEQVR4nOydd3gU1frHv7ub7KYnQAoBQi8CUhQVAbsIWLHca71XseDvIlxRrl7Bq9ixXRELinovivWq2FAQRJqiSFNBpQYIPQlJSC9bf3/MzsyZM2d2Zzeb7CZ5P8+TJ7uzszNndmfnfOf7vuc9Fp/P5wNBEARBEAShYI12AwiCIAiCIGINEkgEQRAEQRAcJJAIgiAIgiA4SCARBEEQBEFwkEAiCIIgCILgIIFEEARBEATBQQKJIAiCIAiCgwQSQRAEQRAEBwkkgiAIgiAIDhJIBEG0CQoKCmCxWPDWW2+F/N7Vq1fDYrFg9erVAdd76623YLFYUFBQEFYbCYKIHUggEQRBEARBcJBAIgiCIAiC4CCBRBAEQRAEwUECiSCIZuHhhx+GxWLBrl278Je//AXp6enIysrCgw8+CJ/Ph4MHD2L8+PFIS0tDx44d8dxzz+m2UVxcjFtvvRU5OTlISEjAkCFDsGDBAt165eXlmDBhAtLT05GRkYGbbroJ5eXlwnbt2LEDf/rTn9C+fXskJCTglFNOwaJFiyJ67K+88goGDhwIh8OBTp06YfLkybr27N69G1dddRU6duyIhIQEdOnSBddeey0qKiqUdZYvX44zzjgDGRkZSElJQb9+/XD//fdHtK0EQUjERbsBBEG0La655hr0798fTz31FBYvXozHH38c7du3x2uvvYbzzjsPTz/9NN577z3cc889OPXUU3HWWWcBAOrq6nDOOecgPz8fU6ZMQY8ePfDxxx9jwoQJKC8vx9SpUwEAPp8P48ePx9q1a/G3v/0N/fv3x2effYabbrpJ15Y//vgDo0aNQufOnTF9+nQkJyfjo48+wuWXX45PPvkEV1xxRaOP9+GHH8YjjzyC0aNHY9KkSdi5cydeffVVbNy4ET/88APi4+PhdDoxduxYNDQ04O9//zs6duyIw4cP46uvvkJ5eTnS09Pxxx9/4JJLLsHgwYPx6KOPwuFwID8/Hz/88EOj20gQhAAfQRBEM/DQQw/5APhuv/12ZZnb7fZ16dLFZ7FYfE899ZSy/Pjx477ExETfTTfdpCybM2eOD4Dv3XffVZY5nU7fiBEjfCkpKb7Kykqfz+fzff755z4AvmeeeUaznzPPPNMHwPfmm28qy88//3zfoEGDfPX19coyr9frGzlypK9Pnz7KslWrVvkA+FatWhXwGN98800fAN++fft8Pp/PV1xc7LPb7b4xY8b4PB6Pst7LL7/sA+CbP3++z+fz+X755RcfAN/HH39suO3nn3/eB8B37NixgG0gCCIyUIiNIIhm5bbbblMe22w2nHLKKfD5fLj11luV5RkZGejXrx/27t2rLFuyZAk6duyI6667TlkWHx+PO++8E9XV1VizZo2yXlxcHCZNmqTZz9///ndNO8rKyrBy5UpcffXVqKqqQklJCUpKSlBaWoqxY8di9+7dOHz4cKOO9dtvv4XT6cRdd90Fq1W93E6cOBFpaWlYvHgxACA9PR0AsGzZMtTW1gq3lZGRAQD44osv4PV6G9UugiCCQwKJIIhmpWvXrprn6enpSEhIQGZmpm758ePHlef79+9Hnz59NEIDAPr376+8Lv/Pzc1FSkqKZr1+/fppnufn58Pn8+HBBx9EVlaW5u+hhx4CIOU8NQa5Tfy+7XY7evbsqbzeo0cPTJs2Df/5z3+QmZmJsWPHYu7cuZr8o2uuuQajRo3CbbfdhpycHFx77bX46KOPSCwRRBNBOUgEQTQrNpvN1DJAyidqKmRhcc8992Ds2LHCdXr37t1k++d57rnnMGHCBHzxxRf45ptvcOedd+LJJ5/ETz/9hC5duiAxMRHfffcdVq1ahcWLF2Pp0qX48MMPcd555+Gbb74x/AwJgggPcpAIgmgRdOvWDbt379Y5Jjt27FBel/8fPXoU1dXVmvV27typed6zZ08AUphu9OjRwr/U1NRGt1m0b6fTiX379imvywwaNAgPPPAAvvvuO3z//fc4fPgw5s2bp7xutVpx/vnnY/bs2di2bRueeOIJrFy5EqtWrWpUOwmC0EMCiSCIFsFFF12EwsJCfPjhh8oyt9uNl156CSkpKTj77LOV9dxuN1599VVlPY/Hg5deekmzvezsbJxzzjl47bXXcPToUd3+jh071ug2jx49Gna7HS+++KLGDfvvf/+LiooKXHzxxQCAyspKuN1uzXsHDRoEq9WKhoYGAFLOFM/QoUMBQFmHIIjIQSE2giBaBLfffjtee+01TJgwAZs3b0b37t2xcOFC/PDDD5gzZ47i9lx66aUYNWoUpk+fjoKCAgwYMACffvqpJp9HZu7cuTjjjDMwaNAgTJw4ET179kRRURHWrVuHQ4cOYcuWLY1qc1ZWFmbMmIFHHnkE48aNw2WXXYadO3filVdewamnnoq//OUvAICVK1diypQp+POf/4y+ffvC7XbjnXfegc1mw1VXXQUAePTRR/Hdd9/h4osvRrdu3VBcXIxXXnkFXbp0wRlnnNGodhIEoYcEEkEQLYLExESsXr0a06dPx4IFC1BZWYl+/frhzTffxIQJE5T1rFYrFi1ahLvuugvvvvsuLBYLLrvsMjz33HM46aSTNNscMGAANm3ahEceeQRvvfUWSktLkZ2djZNOOgkzZ86MSLsffvhhZGVl4eWXX8bdd9+N9u3b4/bbb8esWbMQHx8PABgyZAjGjh2LL7/8EocPH0ZSUhKGDBmCr7/+GqeffjoA4LLLLkNBQQHmz5+PkpISZGZm4uyzz8YjjzyijIIjCCJyWHxNmQVJEARBEATRAqEcJIIgCIIgCA4SSARBEARBEBwkkAiCIAiCIDhIIBEEQRAEQXCQQCIIgiAIguAggUQQBEEQBMFBdZDCxOv14siRI0hNTYXFYol2cwiCIAiCMIHP50NVVRU6deqkm/yahQRSmBw5cgR5eXnRbgZBEARBEGFw8OBBdOnSxfB1EkhhIk9rcPDgQaSlpUW5NQRBEARBmKGyshJ5eXlBJ6MmgRQmclgtLS2NBBJBEARBtDCCpcdQkjZBEARBEAQHCSSCIAiCIAgOEkgEQRAEQRAclIPUxHg8Hrhcrmg3o0Vit9sDDsEkCIIgiKaCBFIT4fP5UFhYiPLy8mg3pcVitVrRo0cP2O32aDeFIAiCaGOQQGoiZHGUnZ2NpKQkKiYZInIhzqNHj6Jr1670+REEQRDNCgmkJsDj8SjiqEOHDtFuToslKysLR44cgdvtRnx8fLSbQxAEQbQhKMGjCZBzjpKSkqLckpaNHFrzeDxRbglBEATR1iCB1IRQWKhx0OdHEARBRAsSSARBEARBEBwkkIgmo3v37pgzZ060m0EQBEEQIUNJ2oSGc845B0OHDo2IsNm4cSOSk5Mb3yiCIAiCaGZIIBEh4fP54PF4EBcX/NTJyspqhhYRRBPgrAXsNMiCINoyFGIjFCZMmIA1a9bghRdegMVigcViwVtvvQWLxYKvv/4aw4YNg8PhwNq1a7Fnzx6MHz8eOTk5SElJwamnnopvv/1Wsz0+xGaxWPCf//wHV1xxBZKSktCnTx8sWrSomY+SIIKweQHwZBdg59fRbglBEFGEBFIz4PP5UOt0R+XP5/OZbucLL7yAESNGYOLEiTh69CiOHj2KvLw8AMD06dPx1FNPYfv27Rg8eDCqq6tx0UUXYcWKFfjll18wbtw4XHrppThw4EDAfTzyyCO4+uqrsXXrVlx00UW44YYbUFZW1qjPlyAiypGfAZ8HOPJLtFtCEEQUoRBbM1Dn8mDAzGVR2fe2R8ciyW7ua05PT4fdbkdSUhI6duwIANixYwcA4NFHH8UFF1ygrNu+fXsMGTJEef7YY4/hs88+w6JFizBlyhTDfUyYMAHXXXcdAGDWrFl48cUXsWHDBowbNy7kYyOIJsHrr7vloTkUCaItQw4SYYpTTjlF87y6uhr33HMP+vfvj4yMDKSkpGD79u1BHaTBgwcrj5OTk5GWlobi4uImaTNBhIXsunqc0W0HQRBRhRykZiAx3oZtj46N2r4jAT8a7Z577sHy5cvx73//G71790ZiYiL+9Kc/wekM3KnwU4ZYLBZ4vd6ItJEgIoLP7yB53dFtB0EQUYUEUjNgsVhMh7mijd1uNzW1xw8//IAJEybgiiuuACA5SgUFBU3cOoJoBnx+wU4OEkG0aSjERmjo3r071q9fj4KCApSUlBi6O3369MGnn36KX3/9FVu2bMH1119PThDROqAcJIIgQAKJ4Ljnnntgs9kwYMAAZGVlGeYUzZ49G+3atcPIkSNx6aWXYuzYsTj55JObubUE0QTIDhKF2AiiTdMy4j5Es9G3b1+sW7dOs2zChAm69bp3746VK1dqlk2ePFnznA+5iUoOlJeXh9VOgmgy5BwkCrERRJuGHCSCIAgWJQeJQmwE0ZYhgUQQBMHiJYFEEAQJJIIgCC1KDhIJJIJoy5BAIgiCYKEQG0EQIIFEEAShxUfD/AmCIIFEEAShhUJsBEGABBJBEIQWLw3zJwiCBBJBEIQWJQeJCkUSRFuGBBJBEAQLhdgIggAJJIIgCC00WS1BECCBRHCcc845uOuuuyK2vQkTJuDyyy+P2PYIoslRcpAoxEYQbRkSSARBECzkIBEEARJIBMOECROwZs0avPDCC7BYLLBYLCgoKMDvv/+OCy+8ECkpKcjJycFf//pXlJSUKO9buHAhBg0ahMTERHTo0AGjR49GTU0NHn74YSxYsABffPGFsr3Vq1dH7wAJwgxyHSTKQSKINk1ctBvQJvD5AFdtdPYdnwRYLKZWfeGFF7Br1y6ceOKJePTRR6W3x8fjtNNOw2233Ybnn38edXV1uO+++3D11Vdj5cqVOHr0KK677jo888wzuOKKK1BVVYXvv/8ePp8P99xzD7Zv347Kykq8+eabAID27ds32aESRESgUWwEQYAEUvPgqgVmdYrOvu8/AtiTTa2anp4Ou92OpKQkdOzYEQDw+OOP46STTsKsWbOU9ebPn4+8vDzs2rUL1dXVcLvduPLKK9GtWzcAwKBBg5R1ExMT0dDQoGyPIGIeL4XYCIIggUQEYcuWLVi1ahVSUlJ0r+3ZswdjxozB+eefj0GDBmHs2LEYM2YM/vSnP6Fdu3ZRaC1BRAAa5k8QBEggNQ/xSZKTE619N4Lq6mpceumlePrpp3Wv5ebmwmazYfny5fjxxx/xzTff4KWXXsK//vUvrF+/Hj169GjUvgkiKsg5SD6vNKLNaotue4i2QcUhIDWXzrcYggRSc2CxmA5zRRu73Q6Px6M8P/nkk/HJJ5+ge/fuiIsTny4WiwWjRo3CqFGjMHPmTHTr1g2fffYZpk2bptseQcQ8soMESBPWUodFNDW7vwXeuwroMwa44eNot4bwQ6PYCA3du3fH+vXrUVBQgJKSEkyePBllZWW47rrrsHHjRuzZswfLli3DzTffDI/Hg/Xr12PWrFnYtGkTDhw4gE8//RTHjh1D//79le1t3boVO3fuRElJCVwuClsQMY6XEfQUZiOag5/mSv93fxPddhAaSCARGu655x7YbDYMGDAAWVlZcDqd+OGHH+DxeDBmzBgMGjQId911FzIyMmC1WpGWlobvvvsOF110Efr27YsHHngAzz33HC688EIAwMSJE9GvXz+ccsopyMrKwg8//BDlIySIIPAOEkE0OeZGGhPNC4XYCA19+/bFunXrdMs//fRT4fr9+/fH0qVLDbeXlZWFb76huyKiBeFjHCQSSERzYLIUC9G8kINEEATB4vOpjynERhBtFhJIBEEQLGwOEtVCIpqFRjhI5HI2GSSQCIIgWDQ5SFRNm4hhvrobeKYXUHE42i1plZBAIgiCYPGRg0Q0M+HmIG2aDzRUABtej2x7CAAkkJoUH5vLQIQMfX5EVGAdJMpBIpqFRiZpt5A6ey2NqAukuXPnonv37khISMDw4cOxYcOGgOuXl5dj8uTJyM3NhcPhQN++fbFkyRLl9aqqKtx1113o1q0bEhMTMXLkSGzcuFGzjQkTJiizy8t/48aNi9gxxcfHAwBqa6M0QW0rwemU7t5tthgt1OfzAZ/+H/DlXdFuCRFJNDlIFGIjWgCNnDGBEBPVYf4ffvghpk2bhnnz5mH48OGYM2cOxo4di507dyI7O1u3vtPpxAUXXIDs7GwsXLgQnTt3xv79+5GRkaGsc9ttt+H333/HO++8g06dOuHdd9/F6NGjsW3bNnTu3FlZb9y4ccoM8wDgcDgidlw2mw0ZGRkoLi4GACQlJcFCwzhDwuv14tixY0hKSjKs4B11Kg8DW/8nPR73JBCfGN32EJGBdS4pxEY0B+H0D6yQt5NAagqi2vPMnj0bEydOxM033wwAmDdvHhYvXoz58+dj+vTpuvXnz5+PsrIy/Pjjj4pL0717d+X1uro6fPLJJ/jiiy9w1llnAQAefvhhfPnll3j11Vfx+OOPK+s6HI4mnWFe3rYskojQsVqt6Nq1a+yKS/YCReHA1gOF2IhmJ4xrXEOV+ji+mUJslUeB4m1Ar/PaRO2mqAkkp9OJzZs3Y8aMGcoyq9WK0aNHCwsVAsCiRYswYsQITJ48GV988QWysrJw/fXX47777oPNZoPb7YbH40FCQoLmfYmJiVi7dq1m2erVq5GdnY127drhvPPOw+OPP44OHToYtrehoQENDQ3K88rKyoDHZ7FYkJubi+zsbJpeI0zsdjus1qhHgc3BdqpEy4YKRRItAVYgNdd8gc8PlH4f134AnHBR8+wzikRNIJWUlMDj8SAnJ0ezPCcnBzt27BC+Z+/evVi5ciVuuOEGLFmyBPn5+bjjjjvgcrnw0EMPITU1FSNGjMBjjz2G/v37IycnBx988AHWrVuH3r17K9sZN24crrzySvTo0QN79uzB/fffjwsvvBDr1q0zzHd58skn8cgjj4R8nDabLXZzaIjGwd5B+WhC3lYDTTVCNDfhuDGsQPI20/VHvs7tXU0CKdbwer3Izs7G66+/DpvNhmHDhuHw4cN49tln8dBDDwEA3nnnHdxyyy3o3LkzbDYbTj75ZFx33XXYvHmzsp1rr71WeTxo0CAMHjwYvXr1wurVq3H++ecL9z1jxgxMmzZNeV5ZWYm8vLwmOlKiZcBc1JrrAkU0PTRZLdESYAVSc9+gWVqIs99IonaUmZmZsNlsKCoq0iwvKioyzA3Kzc1F3759NY5M//79UVhYqIx46tWrF9asWYPq6mocPHgQGzZsgMvlQs+ePQ3b0rNnT2RmZiI/P99wHYfDgbS0NM0fQShQiK31QA4S0ey0EAdJhgRS02K32zFs2DCsWLFCWeb1erFixQqMGDFC+J5Ro0YhPz8fXq96Adu1axdyc3Nht9s16yYnJyM3NxfHjx/HsmXLMH78eMO2HDp0CKWlpcjNzW3kURFtC3bOLnKQWg2Ug0Q0N2GF2Jg8WJ8HyF8BHAxcJiditIEEbSDKdZCmTZuGN954AwsWLMD27dsxadIk1NTUKKPabrzxRk0S96RJk1BWVoapU6di165dWLx4MWbNmoXJkycr6yxbtgxLly7Fvn37sHz5cpx77rk44YQTlG1WV1fj3nvvxU8//YSCggKsWLEC48ePR+/evTF27Njm/QCIlg3rNFAOUuuAH41Iw/yJWIUVSFWFwLtXAv+9oHlG1LYRBymqOUjXXHMNjh07hpkzZ6KwsBBDhw7F0qVLlcTtAwcOaEYx5eXlYdmyZbj77rsxePBgdO7cGVOnTsV9992nrFNRUYEZM2bg0KFDaN++Pa666io88cQTSlkAm82GrVu3YsGCBSgvL0enTp0wZswYPPbYYxGthUS0ATQCiUJsrQLeCWxpOUjF24H1rwFn/xNI6xTt1rRNyvYC1cVA19Obdj9siK2aSVXxOIG4Ju7LmmvUXJSJepL2lClTMGXKFOFrq1ev1i0bMWIEfvrpJ8PtXX311bj66qsNX09MTMSyZctCbidB6PCy9XLIQWoV8EK3pVXSfusSoLYEKPoduO3baLembfLiSdL/KZuAzD7hbaN4O7BnJXDqRCDOLl6HFUiso+OsaXqBRA4SQRABoRBb64P/HltaiK22RPp/aGPg9Yimp3ibeYHE5/S8wrhPIyZDiFGStqsWQHtz+w2XNiKQ2sZREkRToKm4TCG2mMVZAyy+ByhYG3xd3kFqaSE2InawhBKGMkh6Lvzd+C1sDhIr5F11Iew3BNhrHAkkgiACQg5Sy2D1U8DGN4C3Lg6+Lh8qbWkhtsbOCk9EjnBFBJtkbRdMIeJukEasVR9jltWrj5014e03GOzNAgkkgiACwooiykEyR0M18ObFwLpXmm+fhb+ZX1eXg9TCQmyJ7Zp3f/vXSXlPRduad7+xCnsdCEVEaKryM+egSCAtnSGNWNvN5NK61WmwpBBbE8D+FkggEQQREHKQQmfD68D+tcCyGcHXjRShhBxaeoituQXSbx8BBd8D2z5v3v3GKqyICGmkl0FVfnuKftVN/9UvaxaBxDpIbcOpJIFEEOHio1FsIcMmljYX7kYIpJZWKJIVSM1xTsqfT0N10++rJRAJl8XJfJb2ZCmctjvIiERNiK0ZHKRmKLUUC5BAIohwIQcpDKJwZQ3FQdLlILUwgZTATIFUW9b0+5PzZZxREL6xiCcCeTrs92axAv+7XvpjXSKe5g6xeVtabl54kEAiiHDx0ii2kIlGQU1XffB1ZFp6iI2l5ljwdRqLfGPQVInBTYWrHtixxNj58nqA3ctDF5msUAnlpokNWdUdVx87qyR3yNOgdYl0+22GJG1W/JFAIggiIOQghU40BFJIIbYW7iCxHZdcE6lJ99dCBdLS6cD/rgM+uVX8+qb5wHt/Al4/J7TtalyWUK4JBgKJdT/l7YnKBzTHMH9NiK1tXO9IIBFEuFAOUug0xzxRPKJOxoiWnoPEOpnN6SC1tBykzW9K/3ctFb++7Qvpf/n+0LarcVnCvCYYCST5tyNK/mYdJAqxRQwSSAQRLuQghU5UBBLTYQQKUwCCHKQWNsyf7biaIyFecZBamEAKVi8q3PyhcEUEe/2oY8J6GoEUwEFyM/ttlhBb27jekUAiiHAJpw5SVSHw0U3mqjq3Rpo7xOZxafcZLB9Jl4PUwu6U2fY2h/vla6ECKZgACncYe7hhKPa8CxZiC+ogNUOIraX9LsKEBBJBhEs4DtJXd0s1Y8xUdW6NNLdAYjsbIHg+UksPsbHnodyhbfwvsPXjJtqfPIqtheUgBatRFBEHKQSB5DUQSG6RgyRom2YUGyVpRwoSSAQRLhqBZDJ0dLygSZrSYmhugcSPQgp2d93SK2lrHCQnUHkEWDwN+PS2phlp2VKTtIPNkxYJgeRxAcsfUvOZAhGKgyQUSM1RB4kEEkEQZgkrSbttVKA1hhGSzZHHwDtIwQQS36ZwOoKKQ8CrZwDrXwv9vY2Fbb/Hpe0sPQHq6IQLG2KLRn5ZuIgcpIYqRlCH+DuVc4BYgbT9S+CHOcBHNwZ/P+v81QbJQRK1nX1/s4TYKAeJIIhAeClJO2RYUfn9c8DxEEcJhQofUguWpB0JB+nr+4Ci34Cv/xn6exsL23G5GwBbnPq8KTpOeX8+b9N1zE2ByEF6pifwTA9JKIXiIP3+CTArF/htodZlqThgfhvs9xZsFFsw96vJQmyUg0QQhFlomH/osC7DqieA/5zftPtzcwIn5BBbGDlIBzc07v2NgQ+xsU5IoErM4cLeGLSkMBufhO31qALg2M7QBNLCW6TP/cu7tJ+xJ5RRbOxAAoNRl4GStFkoxBYxSCARRLiEk6TdRiZ5NIQXIE1dq4cPKwUVSHyILUSBU10M1BSrz5vaIePhR7Gxz0MpmGl6f6xACrGsgNcbvbAcLzLYzt9VZ/53yrY/vbN2O6G4j6LkekArlgIlabPQKLaIQQKJIMKFHKTQae5QJO8gNfUotmM7tc9LdorXayq8XEfLHk+TOEiMQAjFQXI3AK8MBz78S+TbZAY+TMVXojbrIFUcUh9n9+dEBOu4BEmQZ19nz1mXwEGKiRCb4HdcWwZsXgDUVzTN/qMACSSCCBe2s4/GFBotkeYWkjoHKVihyEYKJL44Y8mu0N7fWHgngr3TbwpnIdwQW8Fa6bPZ8VXk22SGQA6SOwQH6dBG9bHFyo1i48OdAWCvH4EcJI8bsAbptisOATWlgdcJh2CFIj+6EfjyTuCzSZHfd5QggRRjvLp6D8bP/QEfbToY7aYQwSAHKXSae9g875o0tYPUUKl9XrI7tPc3Fj4HiU/ajvj+mO2HMt1ItG8oAjlIDdUwPYqt8oj62N3AiQhWdAUbHGAQYmPfV7IbeLp78FIhXjfwx6eB1wmHYCG2gu+l/zsXR37fUYIEUoxxuLwWWw6W49DxFjQipK0S1lQjBhder0cfDopV6iuDr2NEKJ202wls/QioKlKXeVz6ofuB4AVZU+cg8Q5Sc4cbdAKpiXOQNA5SmALJTB7S4c2hfe/B4ENorNPYUKl9PVD72PPD49JuR5OwHYqDZCCsvnnQfJ7X9kXm1gsFykEiok2SXRqWW+dsGydgi8YXwZo+884Anh8Y+yLp57eBp/KA9a+H9/5QHJk/PgU+nQisfExd9u5VwOyB+gKQhvvjPs+jW4FvHjAOQfDORtVR4NtHzCcTKw6SRbz/psbLdbS+ZnSQQhFI7PuC/XbyVwBvnAe8eVFobQsEH6Ziz8t6TiAFap8mKbtB+32zn0cocwAa1asyI7ZzBkn/mzzE1jb6JxJIMUZivGT91jopZBPzsBe1xiQfez1A8TZp9FNpM4dkQmXR36X/X98b3vtDEQyl+dJ/dqTbkV+lJFSzs6zzgnPr/4AfXwI+u128vjKUOl5dtnY2sPsbc/uTHaTkTP/+DTo7rxfY8iFQuifw9rweYMdi1UWrKpQKEBp12mzHVbxNEhcysZSDpAlPB+lsN82X/hdvM799mcqjQMEP+uWBQmz1FVqBFOic1bg9Tu3zUBLkNfM6GnweZpKvHSn+/QURZOFAhSKJaJNkl364dSSQYp9I5SCxF89gI1RaOqE4SFVHpf/y5+P1qg6N2WkzjO7G878VL5e/0ziHdrlZx0oWSEl+gWR0vH98Kom0l04OvL2f3wb+dz3wyunS85dPk0Z+/fy2eH22cy3bK9Wakmmsg+Tz6T93zSi2MENswcKY7EixYFQVAV9OBY5ukZ7PPgF46yL95NBskrbHzeUgcQIpUPu8ARwklqACKUI5WXZZIDWBW0ghNiLayAKJHKQYZevHwNzhUsKkJo/C5AVOlILE3u0FKwLXWPauAZbe3zQXUDOE4iDJron8HmcVlKlKzF6gQz1O+U6eF0jxCeberwikDtJ/I4HGjn4KxK5l0v86v0Br8IdZdi8Xrx/oc2mMq+DzAW9dArxxjnF4LNwk7WDfZeVh89tdcg+w+S3gtbO0y/d9p33O3oh4GgQhNuaHGkjU6xwkI4EU4ujJcLEnm9ufiIpDwJ5Vxq9TiI2INon+HKRaFwmksFj5BLB2TtNt/9PbgGM7gEV3No2D1NjCeZsXAF9PN97O25cBP80F1s1t3H7CRSQYjDqgqkLpv3yxZ3MwzIY05Q4rmDN3dKtU5FH+3OI4QcQ/N0JOYE/2CySjnDJrnHh5Y/D5An8uoXSaxws48VMJ7F8rOTOyswc0IsTG5twE6WxDKSZqOGqQuzNhb0TcnPPTUKmvJ2WEJim+wfj7/s/5wA8vGm8nUvXBHJyDxA8aCMRLw4B3LteGZVnIQSKijRpiaxsnYEQpPwB89wzw7UNNHyN3VnN1kBojkNhicI2YmsLrkeqQrH8VOPxz4HXDyeeIBCIxZJQbo4TY/BdmViDJ32/dceCLKcD+H8XbkDuKhDT9axWHpTyg3xYCr50J/LuPul3eQWJzkgKh5CBlSf+NHCSzAsmoHo9oeTAX06xA2voR8MIQ4IvJ6jI2xMiKTW+YAsmsGxHqDUNihnh5oLpGHs75qa/UVyTf+B9pIIUs2tnXZHihxbP8QWMBFfEQWz3w0zzgyS7Arx+Ye698fhjVpqIcJCLaJFKILXzYC3RT3+FYrOGF2ESwDlJj2l22V30crJhcc00sWpIP/PKuekEVdSCitnhcQG2J/7H/82HLC8if0zcPAL+8A7x5oXj/8v7kjoPltTOlPKBPblWXKTlInGNk9nuRc6SSgiRp20wKLqOyEKIOP1gbgxXJ9LiBJfdKIwcBYAvTsdYxAokV8RoHKQS3QnPOB7gpqGambRF9hzwJ6eb2ryl/wDk/9RV6gbT4H0Dhb8CqWdx2uKlFguXYffeM5PDWlXPbidD1Xv6MvC5g6X3S48//Fto22M+cxWPwvbdimsDnJRpDUjwlaYeNJjfCDcBhuGqjsVjCDLEJOjb2zj5QuOGzSVL14VuWaWdplyn8jWlPEMHWXBOLvjxM+u/zAiffKBZIcn2e754FincAV74OVDO1jwKF2Ip3BN6/3BHLuRkstYKh0HLHaLNzy5nOoaEa2PwmMPAKIL2Ldj1+FJuRo8A6Uj5fGHP0iQRSkHMwmIP063vABoPyDayDZDRSKyQHyWS4xuxoRRlWIGl+S/zktFy9KLMhNj4R3cMJrWA5dt89q+7j8lfU5RFzkATneagYhTQpxEZEG7kOEjlIYWBmqGyksFi19n+jQmwmHaTfFwKHNwEVB8SvF/3ObCfInayriWb8NkJOSg4UYlv5uHSMu5drQxnCEJu/Qwn2PXsCCCQR9eXS/0AO0ud/k5yrL6bo388naRs6SIzADeTmmQmx+XzA3tXa3CARwQRSucF55azVCiT2s/BGQiAF+O2wI9jMJPiz37PsQAr3HyA0Vl/BzaNmIAj51zxO45Aqz8H12ucRy0FKbfw2DB2ktieQyEGKMdQQW9s4ASNKc079YbFyjlVjQmxMB2kkbLwe9QJldGyFjEAqWCtdLHMGitd1NlYgheh4yI6JSDDwYq3ioD75FeAEklv73whZXJkVSHKdJz5HiHUKtn8p/d8rGPGjhNjkUWwGnTqbx+OqA+xJ5tqnbkB9uO0L4OObgr8lmEAStfXbR6Q6UIOvEa/HduyhjGLTVJkOIObZEWweZ3C3jT0f2I6efw9fmNHDCR12Dr2Ao9ic2sdmy1jwYjJSo9jiHNK51RjBZcpBahs38OQgxRjJDn+IjUaxhQ7biTX1Hc6hjWqMHzB/QRJd3M04SJpEboN1Kpj5+1Y+Brw60rgdjZ3x23QODbe+0EGq1y6vLdO6IcqIHCYHSf68g3VIgXKQAqHrUP37YTvdrBO067BOhJKkbZSUy5wv4XwXbPvkUgDBCJqDJPgs186W/m/9ULxeuJW0eTeitkwafcpXgK7ghvgHdQyZtmmcEIskrr5/TqqBpclBEgzPZ900jSDkksb5CWnNlpXgb1AiFWKzxpsfcWmE0fcYTq5k+QFjZ7IFQAIpxkiKl+5cXR4fnG6aIT4kPCbvSpuCRg3z53KQ6sqBxfcAB5laOWbuuEUXLaMLdmMdpFALWsqOjFGSNhtmqi3lQmwiB8n/eQftMMMUSHw9Knk/+5mqzPGc68MOqWYdJNFILPY7DCfExjpIZvOXwnGQRLCfebjD/Pkk7bXPS6NP+cKZlVyRyGBtZLfL10868BOw4lFpuhq2rYEKPALGOVdy21nMfga8CIlUiM0apx+BCUjC8K1LgotkGZGjFVQgceehsxaYM0j6a+7rcYQggRRjyCE2gBK1QyZSo8HCIWI5SC4pF2fjG8B/R6vL2U6UH2Gz/0fpLlh0zEYTyzZ2FFuodXxs8ZJQEAqkWm3nXXMMqGYEks8jCUc5PwhgQmxBLryBkrQDoZvM1L8fdvQR38nJAik+SVtYUgmNetX2sB0G26k2VAPH2cRkM6PYmlkgRdxB8gDF26XH9eXa4+cdpGBtZF+vPKI+tkB7/rAj7tgpQlJyBNs0WSgSAA7+FLh9Mvz1IlIOki1O7CCteBQo+B747aMA72UGJojytzxBrq/8TQU7bVJzjZqNMCSQYgx7nBVxVumCV+tqxXlINSVS1dbGFkZkiWYSYaQcJK9bm/8gXIfZ1zcPSEPcl/xDfMwNRgLJxJ3u0S3GU3KYqfjN3oVa4/3tE3zfvINUeURQb6ZBK/bkDiVYkcFQk7RleIEkf7ZsO/kifHJnabMDNuYuXhZF/7semN1fqt3EnqtsDtarI4AXBgcoeChoX8QcJJN3+ZqkZeb7dNWa/x1ocndcQIfe6nN2JnreBQolTFjFCCRYjIsmehrU8yQ9T/y6Anf+Ruo6E6mcHmu82EGSCfgdM+eRaISn5kZO0F7+N8Mm2LfQpG4SSDFIm6iF9MrpUtXWPz6N3DaD/YCbEtN3gEFykDwucX6PkYO0fp70/+e3xcdsJJDMXLBeO0sKR7D1lWTMOEhsh2yLDzANAyeQKg7pBZK7IbwQW6hJ2jJ8CFERSIyY4TtcWTjY4rV34/Jx7/pa6nh+/9Q4xCbna8gigRU/mrBHGCG2oOIiDAeJd0LMhph4t5fdd43fvXA79SOqZp8A/Pp+gLYx22W/H59PX3uIbYt8TA5BKJZNPtflIDUidOTzSZPpVh+LcIgtQA5SoNxBvjYUT7A8SPY34/ORQCKahjYxYa08UmK7QdXWcGhqBymQWxExB8kjrtpsptp2KCE2ILB7x74mmizUjEBiO35rnHEH7KrTjuSrOqrfp8dpMIotWJJ2hENs7DE5q7WiRV7HGi8V6pQ/I76zqSvjausIRIXyvTHix6g0A99Wm4GD0NQhNsC8QNL8Vl1cnSn/sdeWAPBJHS+bQ/b5JHNtYwWS1609f1j++Ez9bES5akY3GXLbw6WqUBJ8/+4duRs6m0EOkoxRRXh+mhphvbIg11fWVfa6taFSykEiIkWbqoXUmAsMT1PnIAWqcWL6DpATJVWF2lFIXpc4fGV098Ze8IKF2PiLcKAOk72giTpcUw4SIyZ8XuOLpKtW6274PNp8EUBqq6hQZLAQW7gOEn9eegUCCZBEknzeKUUm/Z+N/Lnxw8hrOYEkys8QdcqsQNKIIs5Bik/UvxdoohBbJBwkj3bf8vcstzc+UV+408x2NQLJpT+nZHZ8JSUxA+I6Qux2+M9I9Jmd+Q9TTUXxH+rjSBVuDdVBKtsLfHU3UJqvXS46V4zC/DKsg+RukObzU9ZvmQ4S1UGKQRLj21AtpGAdXEjbamKBFGgIL3vBqDwKpOWa2+bLp3Iixm0QYjO4OMUnAg0u9b08ouk52NeMOlO2M47zd06anCITOUh8WNDQQarXiillH/FSwnNDhSR0RGLPdKHIEEex6erU+PfHt/PLO4GdS4HbV2kdJED63Fw1UtvZz7O2VCtwRPlgcqfMhs/YNrHLeQfJyEFoSgdJnnrH7HQjfA6SUCD5v7s4h/m58DQVsZnQmCeAQGIROkjMMfEunuj8k0cwBkMT8otQLmawHCSeD66TJt/esUS7XDRnHF//iq9JxT72OLUCyWz5gxiDHKQYpE2E2GQi6iA1cYgt0I9cvpNe+7xkm//4ksGKXAVk3inwuAxCbHXadWTYu8VgOUj83a5RyAEQuxXsBdJUiI3Zhsdl/Pm5asUuSkqOOhqMd5C+vg9Y84yJUWxhOki8QBKF2AB/eKYO2PhfbQ4SwDhITm1Zheri4A6SKDTKtokNgfI5SEbfTbBCjqYdJMEwf9l5CSvExolnnUBKMO8gaUKXJkNsLMEcJF5kikRlYvvg+wGMCzI2hmAOEv8dH/NP1cOOGgXEbjl/7Pz1hj0n3Q3aMPncU7WTH/PrxygkkGKQNpGkLWP2rtXUtqIYYpMvFt8+LP3/5oHg2xMJGq9H6yDJro3LIMQWH0QgaRwkvmZLgLt9jfsjuydMGwIJpGO7gHeulEYpsvs2+q49TrFIiE9URUZ9ufa4vS5g1RMhOEhhCKQrmHnJlBCbQR5QYjuxgwT4j495X+VhriP3v8Z2GLKwZY9PMxkz+13yAsnA3ast0U4ZwmPaQfKvx7bXka5vYyD4cDh7nCIHyWxhUo2DxIXGjJK0WexJ0H2eGgepDijdo44yFInK+AAChSWUsggiUnOBPy/QLguWg+RxSqNTyw8arwPoxZCoRAf/29Mkedfrfyu/vCv9d9YAn/0NeK6fdK2IYUggxSByiK1NVNM2CrF5XEDRH6HdZYTqILmdUvVedpJXvg0fXCetw2+fJ5w6JqK8Ja9LKz7kC5WbC1fJxCWKl8sEykEKlBiqcSvkIfXM8fNhHZbPbgf2rJAK/7H7MqqF4q4Xh39sdlVkGM0PxcIXt2Mv6mZCbD3OUh87a4Ah1wCj7pKey+dpoGPQ5SD52+5u0H6e5Qe155LckWjCTJXa/QLaUJzHJR2f16v/LgIV8Szy5704a4GDG7gk8yACSRZ+cjv5UC9gPpQS0EHyH7t8TsQlmBdI7OfKOmZel9hBGvsk0PdC9bnNoRcYrEBqqARePxd4+RTgmweDj+YKRGPzjqZsBDqdpF0WzEEq2SWNTp1zovTcyJnjr3Wi71UnkLj57UTu7mtnAa+fA2z5QJqQ+tAG47bGACSQYhB7nPS1tIlK2kYhki+mSFNlbHhDXVa6B/j4ZimcISJUB+mnuVInPu8M8eu7lgI7l6gdfaAcjnAEktBBcmsFktwhGyWgsxfzYALJTIIpv1+2nWwbeHFXU6p2JFVF+u15XAHERYP4NRszbYKZcAR/LrHHZ8ZBuvAZ9bHcecnfhagOEkttmd5BYpO02btpd522Ro/8mmgkF7uMDdN53cD8scAb5+i/90DuXvE26f8H1wL/vQDYwLhkgcTN9R8D/S9R9w1ozwHZNTHrQvGlLQKF2Gz28BwkzUSyBiG24X8D0jqpz/kaVoD2N1RVKOXEAdJ1SPQbMltEtbECyWLTu4XBcpD2rdE+N5vQL3LPAzlIRsd2dIu2zluMF5AkgRSDKALJ0wYEklEnvfV/0n95dImzRpqG4I9Pge/+LX5PqHWQ2Kk8RLA/+IbqwBf/Pz4DSvKNX5fRzMIuaKPHpd2vLAyM6iBpLnACty1QiC1Q/g7rVvgEAon9fBuqgWd7Ak93l54nZui353WJE7Hl7QoFkl29wzXjIOkEINNeMw4SK6Lk8IfcMQcLsdWW6nOQZPfL7dR3GKxrqThIAhfFqOJ2Xbk0I/zRLdpkWCBwBy07SHJHuYm52TAqHupIB/qOCewgyU6m0Y1J5VHgl/fU71mT6O3WOmXuOumc0DhIYeQgsRiNYrNapfCojC1e/d5kNKE6NrncwCUxLZAaOd2PNU7vVgVzkKqZGw2fTz9djgz/OQodJG6ybvYm0WyyfqCpkPJXBHbtmwESSDGIo005SEGcHvkOqZpxJTQVchlCrYMULMGX/cFXHg7sILnrgZeHBd+nZv8GDhLb9leGS4UFjYb5B5uYkh8hx+/LCJEgM3Loju9Tl7nqgYQM/fa87sAOkmGIzX83vHe1cVuVfbi0nyl7cTXjIMWz6/jFpjKHHJekzYe1akvVTt4qGOZvJKwAtaP0cA6S16P9nFkBowm5cuexqIOWp9CQk3JFGH0/8nfAi0WzDlLFIWngwhd3SDcSgP5c4t9XX6kui3M0XiC5G4xrgmkEkshBMujsvW5xB25lzo0upwFn3QvcIphQuLE5SFab/rsOloNUw9xoeFwBHCROuLBiVUaTE8hdS4INCFC2a3DOff434N0r1ZzOKBF1gTR37lx0794dCQkJGD58ODZsCByTLC8vx+TJk5GbmwuHw4G+fftiyRJ1iGJVVRXuuusudOvWDYmJiRg5ciQ2btQ6BT6fDzNnzkRubi4SExMxevRo7N4dpLR/M2K3tSGBFMySl++Q2CRla5w4N8nMhK6afQdZh72gbv8ycNFFHjPDkkVhOVFnsfBmYwcp2JBets18vlegEgtBQ2xM29m72PpyICFdvz2P27iSs7vewEGKUzvGIz8bt1VmzbPArE7A4c3+ffrba40z7mDZzlAkopQQm/8zkIUO/90FdZACCSR/Z6L53n3+KUkMQmzsY74zswou68lZ0v9AHZdRG2Xxw4rF2jJg0d/VdeICCKRN89XHshOoS9IWjLAMJwfJ6HpSdxyGQ+l5gRTIQeIRuW6saElIA857AOh6uuC9jZ0w2moQYgtw08Set+56bQ4ji04g+T9Xm0Mfdgb031+gzyzQfmS2fSH9/2muue00EVEVSB9++CGmTZuGhx56CD///DOGDBmCsWPHorhYbKc7nU5ccMEFKCgowMKFC7Fz50688cYb6Ny5s7LObbfdhuXLl+Odd97Bb7/9hjFjxmD06NE4fFid0+eZZ57Biy++iHnz5mH9+vVITk7G2LFjUV9vcqbjJoZCbAzyxZ5PUhZdCEN2kIKsw+YsrHxM2yEEw4zNLnKQ+JowgGSDsw4LK2yChRIbwgyxOYOF2LgRKzJ15eKh0l6XcYdgNIrNZg/ukLH8NFdqy9aPtO21BRgFxYo5kdjUhdj87Rz6F+l/nzHS/9qSIDlIAfJN6o771+NdlAouB4nZBvtZ8uE70bknH5vRd+7zGX8/8ndgY0JsS2eobhC7juj3LAqPBqqDBPhrX8kCSeAgifbj9Rr/puXReyKhzAqkuBAcJBEWm/aGIdD52+gcJIveyQwWYmNx1xuPuONzjtjvQj6//vhMnauR/z7MumOUg2TM7NmzMXHiRNx8880YMGAA5s2bh6SkJMyfP1+4/vz581FWVobPP/8co0aNQvfu3XH22WdjyJAhAIC6ujp88skneOaZZ3DWWWehd+/eePjhh9G7d2+8+uqrACT3aM6cOXjggQcwfvx4DB48GG+//TaOHDmCzz//vLkOPSBtK0k7iEiRLwD8nYbo4hJqDlJQB4lL6hTNcG2EkUBi7+CEo9jc+nbZU4xDbME+P2eN6raFHWKTR7EZfL5s2+orxNsNmKRtUChSdDdvBrmDkPcXn2Ds6HU5RRI7Z/1T6nD6X+Zffpr0n827Wf20Guod+Xdg4irgcum6onE8+FFsrADsOFjfBnliUN7Rc9UZj2JjOyC+M7LGAf/3vTr0HlCdAqNz/rO/wdBhkT9PKyMW+QmVAzlIbPvkc0M3F5vIQWKH+XPngehcCuRGy20QOSZszpzonDMKA4mIT9T+9o1CWGybGgPvIMUJRuEZ4a43HiVslKQdl6Ae3zf/kuZqdDv111vTDlJsmBJGRE0gOZ1ObN68GaNHj1YbY7Vi9OjRWLdunfA9ixYtwogRIzB58mTk5OTgxBNPxKxZs+DxSF+O2+2Gx+NBQoJWFScmJmLt2rUAgH379qGwsFCz3/T0dAwfPtxwvwDQ0NCAyspKzV9TYbdJJ31DWxBIwUSKEmITTPGg21aEc5ACzcEUDJuBQBLN3aV5XeCO2ZON6yAFE4KVh4FnegLrXw8xxGbSQfJ6tM5Dfbm4o/K6AyRpO8XhN1u88bxigZCTceWLtCPNuDaQzQ5cPhc471/S8/FzgYtnA9f6J0SV37f/B2D1LPV9CelA55P97oM/8V4WT3IHIgqxsbPWyygCifvcXLXGo9jYGwT+ZsFiA3IHAyOYwnyKgyT4zuvK1UERIkQOkubztGhrPvFopvyQp4jhk7TlEI5/O/W8g8QJXKFACjAKT/6MRE4iH2IzW7WbpUMf6f/Q67WfTUCBFIHpRfgk7YT0EBykhgA5WwZJ2nF2/W+p8nD4IbaN/wHeusRcSkQUiJpAKikpgcfjQU5OjmZ5Tk4OCgsLhe/Zu3cvFi5cCI/HgyVLluDBBx/Ec889h8cffxwAkJqaihEjRuCxxx7DkSNH4PF48O6772LdunU4evQoACjbDmW/APDkk08iPT1d+cvLywv72IPRKh0kZ41U+bhom3a5kvDpk34sa+dII15krDbJzn/3Sv32eEKdiy1UBykUzDhIRrVF+IuNPcU4KdfMcdaVAV/fG+IoNkHOEz/M/+vpwLO9gLJ96nL2zl+zr0BJ2gEcpHDuMOWCgIpASjWe8Z53JhLSgFNvBVL8OTtyhyqLGBm547PaVAdCHnEZKMSWkg1dIcL6Cv1Qd0ASSOw5upEpeRFoslu5A7MKQj2icz5YR61L0nZrO2arjXHLBNtvEDhIfJK2vFwecl9xKHAlbVE4MGDZilrtsbCwAkmU+GyGv34GXPkGcMGj3OfexAKJ3Zc1Tnpu1kFy1RkLJF2ITeAgyZTv11+HgrljHQepjwu+B3YvD97eKBD1JO1Q8Hq9yM7Oxuuvv45hw4bhmmuuwb/+9S/MmzdPWeedd96Bz+dD586d4XA48OKLL+K6666DVZS4GAIzZsxARUWF8nfwYJBKpI2gVeYg7fxaqny86gmt6yFf1I7+Ciz+h1Rz6Is71NctNuCnV/TbE11cQq2D1KQCyWjWbDY0JboLFuRj6BwkdnhtCBXDww6xyXf9Tu2y9a9K+TNyIU1AEieiO/lw6iBZ480N7+eRc3pkB9CRZrxusNFR8vfIJ2Wzw6Pbdee2GSBJ254sztHiE7IB6TMxMxUPLxbkDkwT6vELJNH2giULy9+//FlseAM4vEl93RJEIPEhNr4qMysOc6V0CRRt03bKvKgUnS+B6jgFcpDYUZduZ3gCKSUHGHy1IMQWKAepkUnaAJcQ7g+phuIgGX1muiRtpiaVTiAdEOSQBXCQzvonMOxm7bJIzqgQQaImkDIzM2Gz2VBUpC0qV1RUhI4dOwrfk5ubi759+8JmU1Vz//79UVhYCKdT+oB79eqFNWvWoLq6GgcPHsSGDRvgcrnQs2dPAFC2Hcp+AcDhcCAtLU3z11SoDlIrqqQtd1a1pdqOWf5hsdMAFDNDkY068f+cD/zxObD/R+CzSVKhwlAraQfrfOQRYPyP2QyGITZWIBnUFuEvNhZr+DlILKEUihQmaRuINFYQ1ZeLhz57AwgkT4BCkTWcQGrf07jNbBsArYNkRLDRUUadJfs+OQ+Jf4/IQYpPEreHHQUn46wJHAY1bLPsIDFtVxwkwfbY7zpFcA1Uwl/+7fm48gMWKxN+E4XYuFIToikr5GVyZeii37U5SHy+XqAcJKHo9efaiEK2rIhxVotHAQaDPR9Yd82ozpC8r8bCJmkrAslsDlIAB4m/NnkCuHnH9+tD/YGmtElI04cePU5g/oXAqlni90SJqAkku92OYcOGYcWKFcoyr9eLFStWYMSIEcL3jBo1Cvn5+fAyeRy7du1Cbm4u7Hbtl5acnIzc3FwcP34cy5Ytw/jx4wEAPXr0QMeOHTX7raysxPr16w3329w4WuMwf7kzbqgWDw9lO2u2zhE/iSLLxzcBb14IbHkfWHZ/6DlIZh2k1Nzg2+IxSn5kL/TKRd4CjJHCxMI5y9x13Cg2NsQWgohubJK2USVtvgqysOpumFONsA7SzV8Dg642brOMzkEKJJCCOEhGQpcN2WX3B9K7Mu+RHSR/R+Vu4Bwk5uZKFjG1pYIQm0kHiUfkIMWZcJDa91LLAbDI7zFyRa02fRFJFk2IzaP/rtlCkblDpf/HdjKJ1Qn68/zHF/Xnk/z5xScZT4UTZw88FUiHXuanCpGxxmnPB9HnLkI0SCNU2P02h4MUZ9f/nsoP6M+raq0BoYGtbyazfRFw4EdgzdPAiyeJ3xcFohpimzZtGt544w0sWLAA27dvx6RJk1BTU4Obb5bu2G+88UbMmDFDWX/SpEkoKyvD1KlTsWvXLixevBizZs3C5MlqMuKyZcuwdOlS7Nu3D8uXL8e5556LE044QdmmxWLBXXfdhccffxyLFi3Cb7/9hhtvvBGdOnXC5Zdf3qzHb0SrDLHJFy9nldgBMeoIzIa5jhdEfpi/3MGmCDqNYFQcBF4YIt1dsYhykNjEUFGIzVVnXAcpEiG2gxuBGm6EnihJ2+jzZdtbV646SNf9DxgxRV3HTCVttuK1LR44427p8dC/AN1Gmgt/iHKQjAjqIJlM2GUv+EoOkmCy2vgk6Q5aRnZs2KlKZPgcJLMoAslsDpIs3pLEyezye4w+K02IzcQoNj60xDpIHXpLBTs9DcAB/6AZm11/7m77HPjxZa6dTGFJI5FgEyQZA8DffgCueVdysIwS+o3gzxGjJO0rXpNyknqeG9r2zSKHCps6B4mvSl9+QP/9BBJI1jh9bhZ7TpTtNX5vMxNGsDVyXHPNNTh27BhmzpyJwsJCDB06FEuXLlUSqA8cOKDJHcrLy8OyZctw9913Y/DgwejcuTOmTp2K++67T1mnoqICM2bMwKFDh9C+fXtcddVVeOKJJxAfr57E//znP1FTU4Pbb78d5eXlOOOMM7B06VLd6Ldo0SqTtOUfYkOVeDRVY0cxWOPCSNJmLg4+n3o3VlMi3dHL4iw5O7w2HS+QKsH++U2mXVyhNkDqeOSL6o7F+osTf6ccbg6SKMRWsBZ462KpU/oXOz+YqJI2+3kZjMarL1fb70iTJoBd97I2xJacpZ1bzd2gipmEDO00H2f+Q+pQcv3D40WdV3ySNo+moVI6p8wIpGCdidkChWyHLLtO8jJ3vRrG4h2k1I5A5SHpfEvO1G7TVRuaQygjuydGOUgad9PChP+Sjae/AYzdNisbYuPOMX6klNetz3nyuNQbpDgH0H0UsPsboNQ/dU9cgrio6iFtAWBNiC3OIc6tkgsd8sKg44nSHxC6g8SfIyJhCgBDrgVO/JNUOHPvqtD2YQYjB+ni56T8Tp6QHCT5WmUHHJxAqjio/94D5Q6KHKRATil7bW5moiqQAGDKlCmYMmWK8LXVq1frlo0YMQI//fST4fauvvpqXH11YBveYrHg0UcfxaOPPhpSW5uLVlVJ21UnXXCMQmyA5CyE0tGLsNoal6TtcalJtc/20q4nCjuYhRc3miRtRiApHYzggqULSYQ4ik30Pvm5XOiNL2QoTNI2uIix262v0N7Jy64RO4rtvAeAisNSR/j2eAA+VTClZEmCAVDv9vNOVbcvEkgdegOFW7XL6itUBzAhQL5gsM7QrJvA1s6RHQVZlLjqtQ6SnclLSZUdpFJ9O521gTsOwzbLOVBMx62ZIsIgn8eeFDi3x8i9C+Qg8ZW7RQKJPb9t8VKphVdGqHXH4hzi85xPjnezAsnIQYoP7kLyJQzk/KWMbtKILd363PYC5SDZ4syL7lCRR1PyieHDbpFuPD65VbvcHSCEaxhiE3yuzmr9ORUofGiL1+cg8Q62Zt/1gcslNCEtahRbW0F2kFp8HSRXvTSB6YsnqT8wT4M+1OKqj5CDxI2yCkagUvks/J19SHC5SKICi9Z4cShHLiroqjN2x0LKQfLonxsJBFGStpnvqJZJlrcxx+VhBFJie6nuUN5w9X1ypynPGSa/n4dv7+mTxRfP+nJtHSRDDHLFZETfy5gn9Ms0DpKcg+Rvl7tOTVrl69QoAqlMUCiysSE2g1wYUTI4IHXmIvEgn29GHTs7zF+3bW40kygXjRVM1nipFEK7btq2i85zXlDyDpIIthK0EaLEZwDocqp+XUDgIAUZxWZ2XrlQETlIFqvf4RPsM9BIM/5GTUnSduh/T6760IS8TTAdSlWAXFOz87o1ASSQYpBWk4NUsksSAZWHtB08O2IN0BfEMw1ju9ritT/qUOdiM1pfFHNvDGyoQO4oRENnAeC8B9X1+KlWDm6UbOzGhtiMHBK20xIN8zeieJuaWM9O8eFlcpDku2rRiCJWjIou6uzn1O8iYNwssYipO24uxBYMvvP705vASIHjLcpBkpe56qRiegCQkacVdEn+422o0H++rtrwEnmDCSRRrhMgfS8iESSf/0b5WJYAITaRg8SX6GAFk/yds66taBQb/z6AcS4DOUgGvzUWq4EDlHeawfoBBJKoDpIZgRROsUrRKDY+H44lUH6nfL0u2iZ9X+yIQj7E5glQcFKEaL64ugCj3iIx2i9Moh5iI/S0mhwkzYgtrtoyi7ve/A8sLlHtaBPbqT8snYMURDjwtViM1o9PCm+6C3Y/mueCYf62OPFoKfkO2evSdioH1gM/vy1d9NgaLsEQhdhEd9o+n/aObvVT0l1jqLVK4rjkc3bqD0C6s7XGq+2yp0h5MDJCgcQVxgO0n11ytlQawKxAMhptyO9Dhp2WgkWUgyQLofKD0mdnsUojItlOU17HIxj+HsrkyJo2yzlIbC4M8z3z+2GTtOuZ473o38CG14Gr/AUqDUf02YyH+fMuhahgqEYg+beTxAjlOIfYQXI3AEe3SvvoPirIMH+orwV1kJjPjW1/dn/1sSNNDeHyn0uwStpmric2e+g3jSIHia/qziI6v+IS/KNKG4A9K4F3rgDyTlcn241LMAizyTl2KcEFjc0euD6UbtvkIBEMrSYHiU1IZgWSPAybfc1svRf2Qs/PGs+7LIFwN0ATXjHq/O3JoU2YqiNQiM3fXqtBXgRrZbPHU7JT+u9xNnIUm0cbTpC/r/pybe2a2hLgs9uDu3KDr9U+tznUzoINrbCdBvvZJrbTOhiiz0QkkFiRk97Z3+YytQNojIPEt4E/52SEDpL/2Ep3S/9Tc/35Fwn693kFoxfDLVQqcpBsdiiOq87BYZK02fcMvAKYslEt3hgwSdsgB6nikPa5KAdJfs4Ol0/uoL5uJJB2LQNeOwtYcKk0WpSdnNjoN2smxMa+zoYI2cEamurbgUaxhRliCyVPST4ne50v/ReJdbMOkuyYHd8HvOOfveDgT9oRt7yDBKhC0ky+pi0utGsqhdgIFkdrCbGxHbJGIJVr1xMVyTOE6QzZi2ZpvjZ8FSw3RzSSRvS++KTw5gOT0TlIzHPRMH8WMx17KDlIutGDXIhNFmzlB8TvD9Zhp2qn79HMocWOYmPDFqywSMwQdOoc7N09O/WFTLp/CqDakqYJsRk5dqIcJFkIyu2T28Y6SPLxiqYaCXcuQPkzYj9LK5MczJ/7rIPEhq358KthdXiIQ2xHtwCf3qZdVyiQmFCzjMZBSlALSALA2Cel/xUHpJ37PJJY0szdZiBC2BGjRhi9nsIIJPac4vfFnqPCEJsJ8WN2qD4A3PUbMHUL0L6H/r3WAAJJdH5p0gnYG0g2xCb4Pcm/taT20FU95wmURC+CHCSCpVWG2Ng6F3yIrXSv+WRUVm80MB32sR3a9YI5K/xFWjSUHfDXhrGGN/0AoM+dEBWKtMWJtx+onotMKDON60Js3Jxacnv42k0yVUfFy2X4cgh8fSd5+3ECBwXwO0h27ft5RA4Se+7IRT1rSkwmaQdB5yBliNdj26qENbjvLr2LfzlzzKywUEKN/g4oXAcp6wRtOwA1nAlw575Pm4PEwgsioxCbzyN2kHYu1a/r9ejrICkOErO/ZE4gnXs/cPZ0YNKPYvGwe5lWEBvmIJlJ0mbOMVmopXTUfvcil0YmEknaoSRyJ6RrR/TZBG6mSJSJzi97kn4ZoI4yS2yvnp8s8mdvcxiHodk2kUAiwqXVCCT2YsnmGfAOUmm++VBRjzPVx4E6kKACiRMWr44E9n2vF0hyTky4LpKuKJ4oB8ku7nysJqzoUPKCROUCWNEkd1RGDlKg4m+AdgQawDlIbn2StryODB9iE13UeVdE3raM3LHWFKvhkUiOYjMqGSAcxWYgkNjjZ0d/yUJP7mDCzUEa4g918mJSPsfYc9LrUb93O5P/Jb9H89zA+fCyAok5n0SdLesgyb8p5UaBFUhckrYjBTh3BpAzUJzXs+979briSA08ii0jyETj7FQjN3wkha7+8om0/Nx/SaHkbsysCwFDbILPwFSSdiPSg9kbLpGDJAtAoYOUrF8GqDmJqR0Dh9isNm34Udi+EB0kCrERLHIOktvrg9cb5AIey7Aj19g6O3wOUulucUffrod+2Ul/AU673XifOf5ib8FCdnwehrseWHCJPgwlX+TDTdTm735EdZCMcpBs9sBzOYngh/hq2sKHFd3axHa5ozISSIGG4gL6cghs1WJnjRoCNZuDFCzEpggk5rtO8ueusMdgdNE3AytcE9sbh0dEOUi8eyALJHY0lKaCuv+7kAVdqA6SzSGFn2QRx55TFpvYQfK61PNC5yBx56TRsXvd4hAb+xvrf6m6rnyeye0UCST5ewT0namoc/U0qCMFHWnGvxtbPHDpi0Cv84AbPhGvw55jnYcBf/1ULSJ59j+BK18TC2IZa7x0s+BIFzuOZkJs1jgooSpRmC4YcvtEOUhJ7aX/IgFu9LkpAilXHGJji7sGFUjxMJzv7pLntc/b92pkDmjjIIEUg8gOEtDC85BYx4J1bHQhtnxxiC1noH5ZfKIkkozI6if9D5abc+QX8XKdgxRgSLoZ+FE8mqlG2EragotmqKM9AK344C9kfFix4qDaqbCvy+KCrznEf288/P4sFvW4WGHItpG9cCdkaD8HoYNk1b/Oilq5Y61gjivgfFghjGKTaxaJCFQHSUYWkJ2GAjcuAv7+s1ZYyOeenHTLF++0OaQOw4j7DwMj7mDaziW8y/tixaPHxYTYErk5xczmIHkYocf8fuRzf+TfgQGXS49ZB0kWgoqjZBBi44Wy0fdZ6a8E70gFBl4uXsfmd5D++hnQZ7R4HTPFQVlBzLfHagUmrgT+b41BiM3EtcRqU9sRTpFEuX2ioqGJskAShdiMHCR/eD21o7jsieIgxWkFkqjOWiCBmM1d8+/8GRj8Z+P1mxgSSDEIK5BadLFI1kFi3QvZCpdt9PKD4jjz2CekO4rr/qcui0sMXCNE7lyMQmw7FktzOH3/nPh13nmSLxisgzRxJXDyTcZtYOGPS1Qo0qi6ry0+9LtHdn0+V0C+o5edpYLvgV/eUV+XRawshPiQWdB9izqDeP06RhWedTlIjQixycLPZhffrcr77W3QSSr7YNoQUCAJEmP5zpEVkD3PliZGZZPY+RCbTEIGMHkjcP8RqcMQhl8sgpAY+1kxDtKSe9TlHqaEBN858tM7GDpIXnEOknzu21OZEYdeVRApZSz83x/7WbNJ2vw0I/GcSyrnvikOUipwwsVSHTHehTbj3piZaoQ9b9M66V9P76ImTfOYCbFZbGo7whJIcikNQR0k+SZCFGIzGtAgXxdTOwZO0rbGqwIMEAuuQMffmAEVTQAJpBhEDrEBLTwPSRNiEyRpp8h3Iz6gbJ/+/e26A6fcAmQwM6XHJwSOzzu4iy6Lzwf873rgm39J7kl8snbbgL7kvfwDZ+/60roA3c+EKTQVqX3Q5Ly4mBCbKAfJYgn94sh2HnyugPwdGIku+XX5ewt534L1+e+KvwCywjOxnfZzCCvE5u9YlRFNBm7D3X8Aty6X6ucEQuNqZBuvJ0q85j9nh6BEgGiSYr6UgC0eyOqrfjZGYpoXNKwTYrGKzzGNgxQknGskLnwecYhNzh1xpGjFrJNzkJTtM9+3PQkYeoNUDJSfUkRzE5CiCi1WIAHAWfdILp3mvSbcm5NvlP7nnW68jkYgdQ6+TRZTITZrhB0k7ncGiK+RcQnA1e8AfS/Uv5acJbWddZDkc8YoB8nMNYElxgQSFYqMQSwWC+w2K5webysKsQkcJFucdMfvrFYTgE/8kzTf0ZnM5IrsXUhcovFoGkD9gYl+/PwdU3Km/gd5bKf2udJpMMImPtGcDQ/4i2C6pTbzYb9gITZ5X6HAdx4sSq5Jgj58A6gOktzJhSOQLDZtOC2YQGLzpNp1l4SrTLBRbKIQG58HZdQhJmeam0KG3R+bF8OjKc4nCyRu36KLv3wMR3+V/gB93oouCTgeAJdwH6zquDVOfI6xOUjBcrWMnBVNkrZT+g1Z47TFA1mBxDtIyjFw58rlr4j3x36u8Unq5yqHjNjP2WqVzjHZhTIT3up4InDPbq0TwsN+3iIHKRD8d5XUQSp1wuKD+nlHJAeJ+e75z50tvmuNAwZcBvS7EPjqLuCXd9X1ZAeV/XzjE6Xv0ygHKWQHKYKzFkQAcpBilFYxko11kFixJAska7za6chJgNn9gdu+lX6gMmxHH6zQm+IgCXKQ+CRjvu4OoC8XIP/AWZs/PjG0USbyaCq28weCh9iA0BMUWQeJFzhKQUADp0ARSGE6SAnpelHA3y3zImHf9+rjbqO4vBmzITbGtUhsB00dlsYmeGqGngcSSKyDJIfYeAcpgEBiSe4A7TQ6ASo1B9oOH2ITreNxBj8v2HVFsMP868qAuacBL52s3pDYk8UCiXfUzA5tZz9Xe7L+c+WdqWB5bSJSsgPfiLHnlZx8bxb+OM+9H0jtBJzK1IzyedXQcKh5iEBgB0n3ebGCkhFU4+dqxU6qXwiyokcOwxvlIMWLBJL/Ozhjml6wikoIRBESSDFK6xBI9eLlcv0ia5wqkOSZu0UXMM2F22csJiw2ddSZKOmbr+PDj5oCgKLfxftmBRcvaEY/op14laehGti/DnhxqHa5IpDsxhfukB0kNj+DC7nIToGRaJA7LmVOqxAuzAnp0oWTv/jzIofvvLqcIv3vfAp0U64IJ6tlLlmiOkhWmzpKBwit4J4Io5FVPCIHiRcyohIBIlFgT9Xmr+jqEYnEkAkxaTQRrVI/KMjdu5GAYkexsTcSbNK0qKI6H0o0O/8Y+1nbk/XnFC8ANDlvjTwfRNsJ2UHijjOtMzBtGzDuKXWZj5lIOhyRHygHiU8rEAkkGfY7lwvBWizAFa9JIyblQTGaHKQgITb5+Ec/BNybz2w/N7AojQIkkGKUVjHdCOsgibDatMmYgPgiGZ8oxcS7nwmkdw0QjkpSXxOF2HgHiR81BQCHNmmfy4KLTxRlLySZfdUChSKcNcCHN+iXy5+PNc44ZMcm7JoJDwS6mLqYEJvwdT7EFkKJAfnuku+A+OPiO6/xc4Ez75FGFQFckrbJQpH89AbsBbrRDhLzPfPnKosoB4lHdDdtlE+Uxcz7pRslZTDiUbdtNgfJwEEC/ILYIuUEBiKzNzD6Yf1yn1e8bTkniA+xyaE3tjI1YN7d0TlIIQikUAowBoK9HoSagyRyWS1ckr3Xw+QgMb9Ds3MvyvtQ8taYc6HjIKB9T2abzOfH/17Zz5r9nQ25VhoxKYf/5BChPYkLsQmuIez5a09Wj++SOYaHEy1IIMUoioPkCWM271jByEGSscZp7/YBA9fAAlz/P2DCV9rkRR42N0gokHgHKUO/P34ou9yp8SE7dmSU1Rb4wlu6W59jAKhJ2ja7cVkCNg/CTHw+kOMULBl359eSaAsnSVu+u+RFHH/h5zuvzD7A+Q8ytXuCDfMXOEx/fgvochrw18/97TYoRCkn+wYSszysCxeowKCoejGPaDSd6BhtdiD7BPU5P4u8SFSJcj2MRrGJSM01V+vrjLvF57pomVLXic9BqlP3GWwbIjRi1B44ZARoO+xICST292w0P58RRi4re66xDhJ7QzN+LjDoz8AtywLvQ3GQBOdKWme17AKg/bx415m9BogcVLlt8ndtTzERYmOrztuAv3wq3SD1G6dfN8rElp9FKMgCqdUM8xdhixcUFzQzwsPgtLUnMRdigeDgp9BIyAi+P8VB4gUSW4TPGkQg5YuXszlIRu9nBaQ9RSy0WFi3gR91FSzEtm8N8MG14TlIspAThTCs8apgDTZKJaRCkf51cwYAty1Xl2sEEnOsf/kUWDsbGHVX4DbwjJ0lDSLoONh4HVEOkhmMvnfWQep3Efcewfb5sAkgyEEK0K5g1aVZQq1tY09RC5J63YDXf13gyyaYdZD4uez40CV/jiVlAmV7/fuIkECSQ0uAXlQEw2rjEscFbTJykNK7AFf9J/g+lBwk5jO9/mOpwnxmHynf6Zd3pecdegP7vvPvly+pwOxblLSuG6mZYsJB4s4ftip5jEECKUZpHSE2Mw4Sd1diJg/BMISRpL1TZfn2YWDzm9pliRnB9yfKQQI4gWTRtsmeqp0FnC1ayKJU0o6TOqhzHwBWPc61kXWQTCQwxjmkoc1eN7BurvY1ObQRyBnas1J9HEpyaFIAgWSLV0fJiIrM8euKHstoQmwBnEQZtj0dekl34KEyYnLwdUQ5SGYQif2qo1IdH5keZ2lfF4VaRQKJ/fyMRrHJpIcgkIRJ4gGEhz1FHWHGTm2SnMUJBbMCiXXrbMEdJE1V7ggJpO5nAn96U1zM1gw2uzYHkcfnFecgmR0cInKQ+o5RH6f7856O/CrdYGya798vP1m3SQdJxp7KOUgCgRSqoIwiFGKLUZLs0o+jztmCQ2zB5gmz2vQ/usY4SIEE0trn9esnZGjvqrMH6NdRRrEFc5CYdt/6DXDlG0CXU6XnFYfE7eUvkGffC1z4jHYd3kEKhtUmCQH2DldGHq1kNi/HaHgxP4UJoF4U+Zo1QOAQm27b7DB+k8P8eTRznUUoKTcYZnKQRAgHJSRKHe8VrwM3faXvhDqfrH9PMAcJlsDtEr3fCKGDFGTottwWd4MqlhLSteeD2fOS7WAtNm0OUnyyXsCxow8jdT5YLMCJV4p/Z2bQ5NqJkuc9zCg25nw2LZC4HCRhG+KBvFO12+evm+xrfDoEIHCQUrUhx8ZM8xMDkECKUdITpYtZRZ3JWe5jEVMOEp+kbeICEGhIvGjoNyDZyDz8MH/hHZLsIAVI0rbYtEmbGXnA4KtV0cAP75eRBSTbcZ1yqzT89aYv9W0y4yBpOi+DaTSMJlzlMXSaBHeA8rFe9G+g9wXA9R+pr2kEksl9Awb5aIIkbR4jB6kpCecuH9ALi+yBwLCbpcdDrtFOzizTZ4x+mVAgcedCoHaFEmIT5VLJYSMei1V741JTLHXCFpu/KjPTmfLJ9qbawjlIot8Ie42JVIitsQQLJRvlIDXGQTKCFZy8Ux5MIOmqxadIokz+XsMZJHH2fdL/oQGmlGomKMQWo8gCqbxFC6Rgo9jiw3OQLBZ9QUIAmvmL+B+6fBHqcZYab0/I0AobkUBShi8L9qW0x6rdn3xXJV9cjAQSvw9AuriMfkh9biZJmy30xmI0z1iwySRljAQSP6IPkOpXAUBaLvCXhdrX2OMLpVJu0OKHBueK3SAHqSkJ10Hij+HK14Mn4/c6T78sqIMUpF3pjXSQAG3YSMaeok/UB6QEbatNEuvylGBmCnfq2mLVim7R+cVuN1IhtsYSLKnf65EKVlYeBjIZl8psfpsoB8kMvIPEil5hDhIfYvOfuylZUjkXUQ5SMM6+D+g7NnDOXzNBDlKMkp7UVhwk7kdn9gctujNiJ+Tkf+iyWDvhEnVZYgY30angAsDOIWW0f4tV61gphQL9F4dgs7IHOmZNTR8DwcIKGbadnU4Sr29aIBld3Bjhde0HwPkPAT3PNd5OsDt8o20La/uwIbYAoVaZZnOQgo1iM8i7EM1VF4yENGlINPuZBxNIPl/g80x2kMzkhxjlfom2L3eY/HvS/UPjWXETaCqXQG1hHdGugulBYtFByjtVfSwSrj6vlOP0j53aQpRN4SCx6Kr9MzdeotF6RsVQxz4pzYaQOzS0/QPSd9p5WGg3Gk0ECaQYRXGQaluyQBI4SJoQiU0fcjH7ozBK4DXKQZLDWayNn9hOux6f4zNgvBqaC5ikbRWPmjM7TD7QRZute8KHDUX7YQXSyTdJxefYmieAWCBZ46RijQoWc3fbJ1wEnDktcMfahdluKA6SKJQTcoitmRwkTQXwEHJ0dALJZAd+ys3AZS+pz0XhqZAcpBCqQRs6SCKBlCxui1w7iBU3YYXY4rTnlCihnnWGY0UgyUUh7Sli59rnH8WWmMENTDApeOQK14Gqv4vgnXIXc5Mr+o3zvy/5u+g7Bjh/ZotKyBZBIbYYJcMvkCpbm4OU2E6tmm31V05mQ0RmBZKoE2KrBRs5SGxxOkeaVnSwzsPAK6T6OjLn3g98+5A6kSUv9ER1l8zay4GOmXVJDJPe2fopjANjiwNOnwQc2qgOcwbEAun/vgcObwYO+wtl2uzmZjU3Q9eR6pxOwQRSsBpFms7CRJJ2czlI7HcoCm0aVeHWVckOob0ZedLEosmZ4o6IDY8EmqInqYMqZM6ZAWz/Ejj9DuP9GjlIIvEhO1v8vmUHKaGROUgWm1QSYehfgPbd1VAvCysSmut8CEZaJ+Afu6Trniikyt5wiarHB2PoDdL1rc8FobWLv465BKF7Fv4mkL/JNIjytxRIIMUorSPExjlIFqt0QWQFEiBdIJTJEs0KJCMHySAHSZ5fLDlbqtzs80rhK3aaCvbHzl/sR02VLjZyPkCgHCRleyYFktmLHhsOtNlVweRhPmdRfhB/LCKBFOfQJzeHas8b0W2k+jiYq9ahlzR6yygfxczddDQcpMR2UvjW59W2/Zp3geUzgav+K34fLzZC7cAHXGb8msUiCZ6aY1LtG6PPix3inzMQeKA4cDuMXIGUbKCaq1bffZT0X+cg+R0rTYgthBykU26RhqafOU1yGi8PUL4hFkNsgFpcVQR7PWEFt9nfpD1JSvIPFf46xk4yLkJXYoEXey1bIZFAilEyEqUfcnldkKHysQzvINns2h+QfNftSJUu4uyyYIguFJYAITa5UF2cXarcLMOupxkezrXDYtHWPOHrIIkcJLMhNrOdIltYL6ObVKEb0ApRoUDijkUkkGzxWjFhizd2CkKlXXcpfFd1FGjXI+jqAS/smjIAMTSKzWIBrn1Pv7z/pdJfoPexRLq950xnnhh0VvwItmBtMHIWT7lFmgGepZuBQJJDeuzxh+IgXTxbKuBp5jfG5vFFSvQ3NZpQVxgCKVz461iXU4EjPxuvz+e+8Q5SoPkLWwCUgxSjpLWKYf6cuLPZtXeMcgfM/qjMXgAMk7T9d4i8eyW7LHwIQyOQQij2ZyoHyaSDFKxWyHUfAoOulu6WZYb/n/qYtcH5HAJAf8yiZEubgxNIjsiF2CwW4NblwJ2/hDczOQs/AasIdnqD5nKQIkVT1m0SiXggtBFsgLFwHnKdJNxZ5IECutpEfjHE/k5DGfFksZi/AXGkAmOeAM57UDwQIxbROEjMTU9TCyT+Buu8B4CzpwN3rBevn8blrvHfc+eTpc+9hdJC5HTbo3UkafMOUrxYDLE2rekkbZFAsql3v2y+jset/vD5u2NDBymIFc/XQRIlFPMCyebQhsNkggmkfuOkP59PGuLtcUkJ2Evu8R8Dc44EC7HZU8XHFmfXipdIOkiA9PlYI9D5m8pBioKDFClE51Gk8BgIpFBqIAHGwjk+AZj0g/R49VNS4VVluDn3e5XP+WDFZCPFyCnNs59I4WtmgTTkemDL+1INNpaENODcGcbvM1N24Kx7gMKtwLYvGtfGKEACKUbJ8OcgVdW74fH6YLO2wNEAvIvDh9jkHzsrmszmCBg5SLJj4K6XBIXFor0I89tnOw1NDlIIDhIAjH4EOLRZO4qG3V58snSHLIcSWUQTOoqwWNRZ740IFmJzpIiFhc2uLSNgs4sL/0UbPjleRDSStFsC7M1AZj+g7rhUuFFUQT4QgYSzMsz7icDvkd2iUKY4aatocpAieNPCcvkrwIVPhT7xLqDNhzRi9CPA/nXA6X8Lr31RggRSjCI7SABQVe9CRlIMJReaJaiDJOcgRSrEZlMFkM8rdQi2eK1ro3OQjJK0gwkkrkpxh17S3EZsToWmCm0HcfgLCK+YmhGiUB97zPYUg2HoDu16kUzSjiSathvcNEQjSbslwAqkKRuA6mNA4Rb9XG/B4B2kGxaK12PhzyX5pmDUnUDVEWnUKGEAI5Caati8xRKeOAKkJPiqI4HXad8DuGdXixv2H4O3iAQAxNusSPbPx9Yiw2xejz6cZLNr7XxRDpLpJG3BerlDtR2iLNCUXChBRV+29o9mzqMQHCTZteF//JqJHtsZH5uZOdbMInKQ2ORuR6q4HbY4vUBsqrvVxqAZPWiwDjlIYvgcpJQsoPfoMGajZ7qNCYvNDSXnRZV8U+BIlSYQ7j06tDa0JYwq4scKZhOxW5g4AshBimnaJdtR46xDcVUDume2sEn/nNX6ZTa7VpCIcpDMDvNnf2x//Qwo2gYMm6Bdx+0EHFCFWpxD/yMd+4QkIAZfrXW8guYgMRd8owsYm1uU1MG4pojZZG4ziNrCFoo0CrEBoSdpRyMEZzHhIEVjqpGWgMhdDAf2OzCbyM/nVkXynG/t5JwY7RYE5oKHgXevkvIiWxkkkGKY3tkpOHS8DjuLqnBajxYy+kKmQSSQ4rXTX9SVSf8DDa83ghUCXU7Vzk9ljZdCZ7yDJBohlJihDvsv2W2+Hfw0DiI0DlIHoLpYvF4kZ7wWOUisQIpPNg6daSZctQV3kKIhPvjyCiJacpJ2U2I0ii1U+Bpgjd0GEZjkDsC07ZG9TkSS3qOl9qV0DL5uC4NCbDFM/1xpSPyOo5VRbokJyg8AX04Fju2SnjdU6dexp2inFijeIf1np1cwm/fC5vPwwkfuuA9tBJy1jIMUxBUKJQfJwuUgCbfH5SAZhtjCvPCJBJ9IIMnTOgBAQ6XxSCl2FJvPZ9z5nekfPXfxbHPtjCRmOmeN4CaBpBApgWQmUZ4Ij+GTpP+j7tIuT+sUfo5Qc5DWqWlHYEYJcpBimBM6SqGn7S1BIL1/LVD8B7B7uZSsLAqxyR3Xaf8HbHgNGOGfzkAT2jGZjM6GC3TzWTkAZxXw8U1A3unAuCf96wXpLNmONdidMXsxEIkSQO8giY7N5gi/k4lL0Od5iUQgu33Zxep3EVBxUJo5W65dw34PPq+xWD3vAWD436QcluaG/V4MBZLJ+jhtDaO5/EIlEg4SIWbsE8BJNwDZA4OvSzQ5JJBijW8fAbZ+BIz8Owb0uAEAsLOwCl6vD9ZYHupf/If0v/Kw9F/oIPmdkgufljpmeY4kvoKzGVgHKVA14oM/qUNQQ3GQQrnbNqwLwzpI7cUCqTG2eZwDkPXRJc8D616RCuIFosYvkK59X/rPfnaavCqPsXCzWKIjjuR997sYqC4yHp7OliswEq9tkTP/Aez7Tio62hg0c4OFIe5JVBljtQEdB0W7FYQfEkixRn05UHkIqC9Hj8xkxFktqHF6UFzVgI7pLSjh1CjEBkidnNEEkmYvuIESTvm8E7keUzAHiRVqZgTS8ElA+X5tXhWLLsQWYYHU/1Jg038lB+iUW6Q/I0bdBfwwRxVQwUaU+Lxa4Zc7BDi6Jfy2RpLr3ldrXIlgi9fFYqmCaNHzHOCe/NDmPBOhcZDCEEgU9iRaCHT1iDXkEUYeF+JsVqQkxKG81oXqBheAFiSQRCE2o3o/cWGERIxqCgH65GGzDhLb4RpVHWa58KnAr9vipQ7E5zHOQWqMQBrzuDQ/XL8Lg697/kOSgGrXLfi6gD/ExnR+o+4CSvNDnx28qQgm8EbeCZTukRL4CZVIOH+NzUEK9jskiBiBBFKsIXei/k492S4LpAgN0W1y/B2XaBSbkRgIZ6SRN0DoJFwHSbP9CCS0WiySa9ZQYSyQGjMSzJ4EnHqruXWtVvPiCJAcOrYjtCcDZ/8ztPZFkzGPRbsFrZfG5iCRg0S0EEggxRpyJ+rvoFMc0ldU0xChESiRYv1rUhvZqTUANY/HGSAHiSdvuPTfbA0kIHBuic5BkgVSCHeukUpoPfteabReVn9xxxCp2jSRxufj5j2j0UqEn3DqILFQ6QWihUACKdZgQmwAkOyQLkBV9TEkkJw1wNd+N2Hwtdp8IlkgyTlI8UmAq1Z6bFQxOjUHuPuP0CpKBwyx8Q6SyRAbS6SGRI/8O/N4CvD7QqD/ZcD2RdKy5pqsM1T4EFso4pVo3WjOi3AcJAqxES0DGk4QaygOkiSQUhKk5zHjILnqgbK96nN3HfDH5+pzOTFZDrElttO/JiK9i1S00SyBBAzv1HhCCLG16yH97z/efFvM0ukk4J/7gD8vYNoWwwKJdQfMji4kWj+aUgvkIBGtF3KQYg2b1kFK8TtINc4YEUhvnKcO6QekkgQrHlGfy+EtJyOQ5KH/TV0xWmlDIxykST8AlUeBzN7hty0QSVxFdE+MzrNHDhJhRGNDr+QgES0EcpBiDT7EZpc0bHWsOEisOAKA3d9on8vVmOUQW0KG+lokJ2UNmKTN5SC5/XOgmXGQ7MlNJ45E8IUeYwWfhyomE2IsjUzSpvnxiBYCCaRYgwuxJcdqkraMrs6MPIrNL5DYsJnRMP9wCCUHSW5LLA4vjtUQmz1ZK4ooxNZ0XPRv6f9V/41uO8zS2DpIsfg7JAgBJJBiDVlwKCE2WSDFwGgn0aSscgK2jBwycgpykCIZYgtYKJK7Q633T9USS8OL5Rm6T7gkuu3g+dN8oEMf4PJ5FGJrLk6bCNx/BBj0p2i3xByNraQdS79DgghA1AXS3Llz0b17dyQkJGD48OHYsGFDwPXLy8sxefJk5ObmwuFwoG/fvliyZInyusfjwYMPPogePXogMTERvXr1wmOPPQYf07lPmDABFotF8zdu3LgmO8aQ4Ib5yw5STIxic9Xpl1Ue0T6Xh8eLkrQjGWILyUGqFC+PJn/5VHIOxgUpNtncnHgV8PdNQM4AStJuTmJ1pnYhTJHOcEJs7ITVBBHDRDVJ+8MPP8S0adMwb948DB8+HHPmzMHYsWOxc+dOZGdn69Z3Op244IILkJ2djYULF6Jz587Yv38/MjIylHWefvppvPrqq1iwYAEGDhyITZs24eabb0Z6ejruvPNOZb1x48bhzTffVJ47HDHSecoJjP7QS0pCDIXYRNOHVBVqn8shI8VBylBfCzSKLVRCmWqkvkL6H0vJoak5knMQy1AdJCIYoZwXFz4DbHgduODRpmsPQUSQqAqk2bNnY+LEibj55psBAPPmzcPixYsxf/58TJ8+Xbf+/PnzUVZWhh9//BHx8dIdbffu3TXr/Pjjjxg/fjwuvvhi5fUPPvhA50w5HA507NixCY6qkehCbDE0ik0kkMCF3eQQm7yug7lbjORdcmpHdXQcDx9iK9nlXx4jIriloEnSpgGvhIBQHKTh/yf9EUQLIWohNqfTic2bN2P06NFqY6xWjB49GuvWrRO+Z9GiRRgxYgQmT56MnJwcnHjiiZg1axY8HtVNGDlyJFasWIFdu6ROccuWLVi7di0uvFA7X9Xq1auRnZ2Nfv36YdKkSSgtLW2CowwDPsQWS6PYGiqCr+NxSrlKsoPEhmYiGWK77n9SBe4Ji/Wv8Z15ab6/LTHkILUEGjulBNH6CSdJmyBaCFG7LSwpKYHH40FOTo5meU5ODnbs2CF8z969e7Fy5UrccMMNWLJkCfLz83HHHXfA5XLhoYceAgBMnz4dlZWVOOGEE2Cz2eDxePDEE0/ghhtuULYzbtw4XHnllejRowf27NmD+++/HxdeeCHWrVsHm038g29oaEBDgzoku7KysrEfgRgrXwcpRkJs9ZXA758av37KLcCm+VK7XbVqnSJWlERy9EruYODWb8SvGdVIctdHbv9tjiCTwxJtB3aiYAq9Eq2YFuWbe71eZGdn4/XXX4fNZsOwYcNw+PBhPPvss4pA+uijj/Dee+/h/fffx8CBA/Hrr7/irrvuQqdOnXDTTTcBAK699lplm4MGDcLgwYPRq1cvrF69Gueff75w308++SQeeeQR4WsRhctBkpO0q6OdpP3JrfqaRywn/dUvkJzMRLWW6IRmjARS51Oatx0tHU1H2KIuFURzQQ4S0YqJ2lUvMzMTNpsNRUVFmuVFRUWGuUG5ubmIj4/XuDz9+/dHYWEhnE4n7HY77r33XkyfPl0RQYMGDcL+/fvx5JNPKgKJp2fPnsjMzER+fr6hQJoxYwamTZumPK+srEReXl5Ix2wKm/8r4UaxRT3EFkgcwQKk+JPqPS4m/ygVyDutyZumQ5TAfc79QN+xzd+WlkxiO2DYBClkmpIV7dYQsQg5SEQrJmqJBXa7HcOGDcOKFSuUZV6vFytWrMCIESOE7xk1ahTy8/PhZaoo79q1C7m5ubDbJeeltrYWVm4CRZvNpnkPz6FDh1BaWorc3FzDdRwOB9LS0jR/TQIXYktNUAXS1kPlTbPPxpKYoY5Q83nUXCV7CtCuOzBlszQHWXMhKgHQdbjWESHMcekLwGUvRrsVRKxCvymiFRPVzMtp06bhjTfewIIFC7B9+3ZMmjQJNTU1yqi2G2+8ETNmzFDWnzRpEsrKyjB16lTs2rULixcvxqxZszB58mRlnUsvvRRPPPEEFi9ejIKCAnz22WeYPXs2rrjiCgBAdXU17r33Xvz0008oKCjAihUrMH78ePTu3Rtjx8aAw8BV0s5KcWBIl3R4fcD/vbMZXq+gWGO0SeqgTcauPS79d/iTsjN76+cga0pEE9kmNuP+CYIgiBZPVBMLrrnmGhw7dgwzZ85EYWEhhg4diqVLlyqJ2wcOHNC4QXl5eVi2bBnuvvtuDB48GJ07d8bUqVNx3333Keu89NJLePDBB3HHHXeguLgYnTp1wv/93/9h5syZACQ3aevWrViwYAHKy8vRqVMnjBkzBo899lhs1EJShvlLnbzVasE7tw3HqCdX4mhFPX45WI5h3doF2EATEZdgnOSc1EFbabmuTPofyVFroZAuCH0mRuEzI4hWCblGRNsgLIG0YMECZGZmKrWG/vnPf+L111/HgAED8MEHH6Bbt26mtzVlyhRMmTJF+Nrq1at1y0aMGIGffvrJcHupqamYM2cO5syZI3w9MTERy5YtM92+ZodL0gaAtIR4nN0vC19tPYrl24oaL5B8PmD/j0BmHzV3KBjJWUDFQfFrie05B8kvkBypjWtnuJx8I1C6B9jwmuomNaeDRRAEQbR4wgqxzZo1C4mJiQCAdevWYe7cuXjmmWeQmZmJu+++O6INbHNwITaZCwZIrtqaXccav4+CtcBbFwEvCUZ1eb3AW5dIf25mItVAM3AndZCSNeURLXVRFki2eGDcLKDbSHVZJKt4EwRBEK2esBykgwcPonfv3gCAzz//HFdddRVuv/12jBo1Cuecc04k29f24EJsMid3lVyj/OIquDxexNsakT52cL30v6FCGvHFjkSpLgQKvpceb3wDGOHP73I3wBDZnbHZAXed6iBFK8Qm42Qm0qVkUoIgCCIEwuplU1JSlMrT33zzDS644AIAQEJCAurqBBOaEuYxcJC6tEtEiiMOLo8Pe4/VhL/9PauAaqa0Quke7euyuAGAda+oj90BvtekDtJ/OTxY669K7oiyQBJNrksQBEEQJghLIF1wwQW47bbbcNttt2HXrl246KKLAAB//PGHbm40IkSUYf5OzWKLxYJ+HaWQ1Y7CMKt4H98PvHO5NGGkTOFW7Tq1zJQrVUfUmkIuf4L2+Ln67SoCye9+RTvEJuOqDb4OQRChQWYs0UYISyDNnTsXI0aMwLFjx/DJJ5+gQwepg9y8eTOuu+66iDawzSG7MD6vlA/EIAuknYWiSWNNIIfWWAIJJJ8XqPfXNJJHsHU5Vb8NnYMUIyE2EkgEQRBEmISVg5SRkYGXX35Zt7xZpuJo7diYr8TrAqxq6YH+foH0+5EwHSR50laWEm5ZXZn2eU0JkJCuhvxEw+WVHCS/+1Un10GKsoN01r3AknuAISTaCYIgiNAIy0FaunQp1q5dqzyfO3cuhg4diuuvvx7Hjx+PWOPaJGw9IY82D2l4T8mp+WlvKWqdYUw9UrJbv8zDJV/XcgKptlRb/8ierN9GrDpIp94GTFoHXKYX8wRBEAQRiLAE0r333qvMZv/bb7/hH//4By666CLs27dPM18ZEQZsPSEuUbtPdgry2ifC6fZi7e6S0Ld9bKd+GSfCNCE2+bmLEUii4f68QHL5k8ij7SBZLEDOAK0rRxBEI6EkJKJtEJZA2rdvHwYMGAAA+OSTT3DJJZdg1qxZmDt3Lr7++uuINrDNwc6azokXi8WC808Isx6S1wOU7NIvP/IL8NFN6mg2nUAqUUewWeOlkgBTNgPj/SPcLFYpBAdoxR0gFZckCIIgiBZIWALJbrejtlZKgP32228xZswYAED79u0VZ4kIE4tFN2Ety9C8DABAfnF1aNutLtI5UgCAhkpg2+fA+9dIz+XwmMV/atSWqjWQ4qXioMjsDQy+Buh0EjDwCrWOEhsehAXoOCi0NhIEQRBEjBBW7OGMM87AtGnTMGrUKGzYsAEffvghAGDXrl3o0qVLRBvYJrHFS2JGIGi6dZAqQheUhlgLqfJo4NdL/flJsoOU2Rc4tkMSTHI9ITa8ZosDbl/NtduuPs7qF/06SARBEAQRJmE5SC+//DLi4uKwcOFCvPrqq+jcuTMA4Ouvv8a4ceMi2sA2ieIg6ROxe2RKSdJFlQ2hJWpXHTG3nuwgZfaR/teUqEnagaYbAbQhtk4nmW8bQRAEQcQYYTlIXbt2xVdffaVb/vzzzze6QQTUpGKuWCQAZCTZkZEUj/JaFwpKajGgU5q5bQZzkGRkB6lDH/W5LJDigwkkxkHqdLK5/REE0bKgaXuINkLYw3s8Hg8+//xzbN++HQAwcOBAXHbZZbDZbEHeSQRFFhqinCEA3Tsk49fachSU1pgXSGYcpPoKdQRazkDpf+lu1VUiB4kgCIJoI4QlkPLz83HRRRfh8OHD6NevHwDgySefRF5eHhYvXoxevXpFtJFtjgAhNkAKs/16sBz7SkLIQzLjIFUclv4nZAA9zgLsqcDxAuCjv0rLgwmkGmZkXccTzbeNIAiCIGKMsHKQ7rzzTvTq1QsHDx7Ezz//jJ9//hkHDhxAjx49cOedd0a6jW0POcRm4CDltZNGkx0uD2EyVjMOUqV/nfQuQEo28NdPJZEkEyzEVvg7s26i+bYRBNFysFJdMaJtEJZAWrNmDZ555hm0b99eWdahQwc89dRTWLNmTcQa12YJMMwfADqmS+KjsKIeP+SXYO6qfHi9vsDblMVPfFKAdQ5J/9OkpHvknQZc+JT6elwQ0eMOQbARBNEyOeufQHpX4LwHot0SgmhSwhJIDocDVVX6CVOrq6tht9sF7yBCQs5BEiRpA0BuhuTkHK2oxw3/WY9nl+3EZ78c1q94+Gdg4a1A+QE1j0gWPyLkEFs6s07HwerjOAcCcumLkri7/qPA6xEE0XJJywXu/k2a65AgWjFhCaRLLrkEt99+O9avXw+fzwefz4effvoJf/vb33DZZZdFuo1tDyXEJs5Byk2XBNL2o2pRzo0FZfoVN/4H+H0h8NvHarFH0WSzMpV+gZTWSV0mD/cHAGeQnKdhNwH3HwH6jg28HkEQBEHEOGEJpBdffBG9evXCiBEjkJCQgISEBIwcORK9e/fGnDlzItzENkiQEFtumj7U9evBcv2K9RXS/9oydai+PC2IiAo5xMYU+2Rzicr3G79XJo4cRIIgCKLlE1a2XUZGBr744gvk5+crw/z79++P3r17R7RxbRZ5uLxBknZaYhwS422oc3mUZTsKq1BS3YDMFCYMJjs+NSWAz79uIIGkJGkbhOGOmxBIBEEQBNEKMC2Qpk2bFvD1VatWKY9nz54dfosIdZSIgYNksVjQMT1BN8x/U8FxjDuxo7pAFkjVheqyhAB1k+T1Hdw6J1wC7PgKOPmvZlpPEARBEC0e0wLpl19+MbWehaqsNh4lSVsskADgeK2awH3eCdlYuaMYm/eXiQVSVZG6LJCDJCeF27gw2RWvAfnLgd4XmGk9QRAEQbR4TAsk1iEimhg5xGYwig0AJozsjhdW7MbTVw5GfJwFK3cUY9P+49qVnP6RhrKDZLMHHuYvCzJeIDlSgIFXhHAABEEQBNGyoYpfsYg8nF4eeSZg6vl98NfTu6FDigMHy2oBAAWHj8I793RY+10IjH5IdZDq/MIpLiHwUH3FQYo3XocgCIIg2gBhjWIjmhi5IKM88kyAxWJBB39Cdpd2ibDbrLgSq2A9th1Y688B44flxzkAmxmBRCPRCIIgiLYNCaRYRJ7SI4BAYrFYLMhKdSAeTN0kj1v//rgEwBpgMmF5pBsJJIIgCKKNQwIpFokLTSABQGaqAz4wCfIuQVHHYJWwZSjERhAEQbRxSCDFIrJAcpkXSFkpDmhmY2uoFmw3EWBHGVoM3CRykAiCIIg2DgmkWERxkMxP/prFO0iiaUHiHAC7jrwfHnKQCIIgiDYOCaRYRMlBMh7FxsMLJG99pX6luAStg2QVDGK02ALnKREEQRBEG4AEUiwij2JzmXeQslO1+UW1FccE2+VzkHz6dSi8RhAEQRAkkGISE3WQeCQHSaX6eLFguwmq+DKCBBJBEARBkECKSeLlOkhBHKTC34EfXgA8LqQlxLPZRaivFDhI8QlSReyuI4Gz7gV8IgeJ8o8IgiAIgippxyJmR7HNGyX99zjRc+jf8T1TB8lVVSrebnwCcMvX0vOf5unXIQeJIAiCIMhBiklCrYO0ezly0hJw42mdlEXemhLBdk3UQSIHiSAIgiBIIMUkIVbSRpU0GW3HZDXItrtgPwBoh/7rhvVTkjZBEARBiCCBFIuE6iD5BZIylxqAbEu59JI9m9muGQeJBBJBEARBkECKRUKtpO3xj3ZjBFIPy1EAwL64nsx2g4xgAyjERhAEQRAggRSbKKPYzE81Ap9PI5CyLFKhyB2+buo6vIMkHMVGDhJBEARBkECKRZQ6SEEEUmI79XFtGeBx6VZZWZHLbNdgahEWEkgEQRAEQQIpJoljHCSRyyNjYb6+igPCwpJ/MA6S10aj2AiCIAjCDCSQYhE2FBaomjbrGNWWakJsAFDuS8ZRXwfleUGFG0EhB4kgCIIgSCDFJPFMMnWgatqsIKqv1AmkQ74seGBDlU/aXmkD/3VTJW2CIAiCEEECKRaxxQMWm/Q4oIPECKIGvUA64nePKpAs/XfZTOybHCSCIAiCIIEUqyhD/Q0cJK8H8HnV5/WVgFsrkJAi1UA67MsEACzKd+OzXw4F3i8JJIIgCIKIvkCaO3cuunfvjoSEBAwfPhwbNmwIuH55eTkmT56M3NxcOBwO9O3bF0uWLFFe93g8ePDBB9GjRw8kJiaiV69eeOyxx+Bjkp19Ph9mzpyJ3NxcJCYmYvTo0di9e3eTHWNYBKumzblFWD4T2L9Ws2jkiX3wr4v6Y/3gx/F/zruxqKQj7v5wC4qr/NukyWoJgiAIQkhUBdKHH36IadOm4aGHHsLPP/+MIUOGYOzYsSguLhau73Q6ccEFF6CgoAALFy7Ezp078cYbb6Bz587KOk8//TReffVVvPzyy9i+fTuefvppPPPMM3jppZeUdZ555hm8+OKLmDdvHtavX4/k5GSMHTsW9fUh1B1qaoJV09aF3vRiJyUjCxPP6om03N5Y5j0V8E87Ul6rLwegQA4SQRAEQSAumjufPXs2Jk6ciJtvvhkAMG/ePCxevBjz58/H9OnTdevPnz8fZWVl+PHHHxEfLzkd3bt316zz448/Yvz48bj44ouV1z/44APFmfL5fJgzZw4eeOABjB8/HgDw9ttvIycnB59//jmuvfbapjrc0AhWTVtQ80hHUnsAQLtkreh5fPF23DyyO84VvYcEEkEQBEFEz0FyOp3YvHkzRo8erTbGasXo0aOxbt064XsWLVqEESNGYPLkycjJycGJJ56IWbNmwePxKOuMHDkSK1aswK5duwAAW7Zswdq1a3HhhRcCAPbt24fCwkLNftPT0zF8+HDD/UaFYNW0+RCbCH8hyfacQPpu1zHc/NZG0Cg2giAIghATNQeppKQEHo8HOTk5muU5OTnYsWOH8D179+7FypUrccMNN2DJkiXIz8/HHXfcAZfLhYceeggAMH36dFRWVuKEE06AzWaDx+PBE088gRtuuAEAUFhYqOyH36/8moiGhgY0NKhhrcrKytAPOhQcqdL/2lLx66YEkuQg8QJJxufz+YNuDOQgEQRBEET0k7RDwev1Ijs7G6+//jqGDRuGa665Bv/6178wb948ZZ2PPvoI7733Ht5//338/PPPWLBgAf79739jwYIFjdr3k08+ifT0dOUvLy+vsYcTmMy+0v/i7eLXzYTYDBwkGWGNbhJIBEEQBBE9gZSZmQmbzYaioiLN8qKiInTs2FH4ntzcXPTt2xc2m1rPp3///igsLITTKTkq9957L6ZPn45rr70WgwYNwl//+lfcfffdePLJJwFA2XYo+wWAGTNmoKKiQvk7ePBg6AcdCtkDpP/F28Svm3GQ5BykJAPRw5YJ8FNaH2BqE4IgCIJoI0RNINntdgwbNgwrVqxQlnm9XqxYsQIjRowQvmfUqFHIz8+H16t27Lt27UJubi7sdkkE1NbWwmrVHpbNZlPe06NHD3Ts2FGz38rKSqxfv95wvwDgcDiQlpam+WtSciIgkBIypH/x4gKRHq9eDK3dV2GmdQRBEATRqolqiG3atGl44403sGDBAmzfvh2TJk1CTU2NMqrtxhtvxIwZM5T1J02ahLKyMkydOhW7du3C4sWLMWvWLEyePFlZ59JLL8UTTzyBxYsXo6CgAJ999hlmz56NK664AgBgsVhw11134fHHH8eiRYvw22+/4cYbb0SnTp1w+eWXN+vxByR7oPT/eAHQUK1/XQ6xxSXqX5OJU52j8UM76V6u8+kTsl3RHdhIEARBEDFBVHvDa665BseOHcPMmTNRWFiIoUOHYunSpUoC9YEDBzRuUF5eHpYtW4a7774bgwcPRufOnTF16lTcd999yjovvfQSHnzwQdxxxx0oLi5Gp06d8H//93+YOXOmss4///lP1NTU4Pbbb0d5eTnOOOMMLF26FAkJCc138MFI7gAkZwE1x4DSfKDTUO3rsoOUnAlUBA/3vXDtSbh0cCfc9vYmZdktznsx1/4ivrWMxA2Qim26fCSQCIIgCMLi84nKKRPBqKysRHp6OioqKpou3DZ3OHBsB3DjF0DPc7Sv5a8A3r0SyBkEFP0mfv/D2nDZzweO48pXftSt1sVyDGsdUwEA72Tfi7/e8QCWbytCdqoDQ/IyInAgBEEQBBEbmO2/W9QotjaHw//F1QtKCighNjuQIkguH3qDblEik4s0YWR3vHvrcAzJy0Chr526S0819pfWYOLbmzB+7g9wefSJ3ARBEATR2iGBFMskpEv/G0QCyR9is9mBv28GzldDiLhvPzB+ru4t/XJScf4J2bjutK54+LKBOKNPJk7slAY3E2lNcZXhWJVa72ljQVlEDoUgCIIgWhKUcBLLJARykGSBFA84UoCMbupriRnCzVmtFvx3wqmaZdmp2ryrHZYeSHaqlclX7SjGyF6Zum35fD5YLLoykwRBEATRKiCBFMvIITahg+QPscmFHe3JYe2iQ4r0/rMansdJlt3Y7j0dfevVIpTr9uoreU/93y/YdqQSX/79DMMSAgRBEATRkiGBFMsYOUheL1C4VXosC6Se5wLtegBZ/ULaRQd/le0Dvhwc8OUgq96Dqnq38vrxGm3Fbq/Xhy9+PQIA2FRwHGf00btLBEEQBNHSIYEUyygOEle8cdXjwE+vSI/lyWXjE6RcJEtoaWX8NCQVdS5UMQ5SdYNb83pZrVqgMiGeUtgIgiCI1gn1cLGMnKTNO0jfP6c+ZudOs9qAEPOCOqQ4NM+dbq8mSbu6wQ22EkRRZb3y2OWhChEEQRBE64QEUiwjykGq0s4h19jJZTsIJrI9WFanPPZ4fahzqUnbxZWqeKpnlhMEQRBEa4IEUiwjykHau0q7jk0/XUgopCfq37/nmHZqk9fW7EWx3zkqrlIdpDoSSARBEEQrhQRSLCNykIq3a9dppINktepDcruLtQLphRW7ccN/1gMAihgHqc5JAokgCIJonZBAimVEDhI/75q1cQ4SS2aKA/Y48SkhiyY2B4kcJIIgCKK1QgIpllGmGmFGsZVzAsnTgEiRm56AEzqmGr7u8/lQXEU5SARBEETrhwRSLCM7SJ4GwO0XJryDVHe80bu59tQ8AMDU8/ugV1aKspwfEFda41RykQAKsREEQRCtF6qDFMs4mFmG6yulYf9Vhdp16sobvZtZVwzCXaP7omN6AnYUquG8TumJOFyujmjbV1KDA2W16q7JQSIIgiBaKeQgxTJWm1oLqa4MqDwEwAfEJarr1Jc3fjdWCzqmS3OysQ6SvEzm5/3HcbxWLSJJAokgCIJorZBAinWS/FN51JSo+UfpXdTXM0ObWiQYXdolKY9zOYG0ckex5jnlIBEEQRCtFQqxxTrJmUDZHqC2BHD6w1vpnYE/vwn88h5w1r0R3V3/3FSc0DEVCfE2JNu1p8fm/dp8p1rKQSIIgiBaKSSQYh3WQfL4w1uJ7YGOg4ALn4r47uJsViy580wAwLSPftW85vZKU4vEWS1w+yetrWnw4D83nRLxdhAEQRBENKEQW6yT3EH6X1uqDvdPSDNePwJYrRZYrRY0uL3C1wd2Uvf/7fYi1HAT2hIEQRBES4cEUqzDOkhyRW05cbuJMSoa2TtbWyupoLSmOZpDEARBEM0GCaRYJ9kvkGpL1BFrjqZ1kGT+cUE/dOuQhD8P66JZ3r1Dkub5xS+uxSebDzVLmwiCIAiiOSCBFOsoDtIxdcqRZnKQunZIwpp7z8XU0X00y7tlJuvW/cfHW5THvx4sx7w1e+Dx5ywRBEEQREuDkrRjHTkHqaYUgL+0dTMJJJmMJO2EuF3aJRqsKXH53B8AANmpDlx5cpeA6xIEQRBELEICKdZJYkJscX6h0swCKdlu0zxPcYhPm3qXBw4mb2nvMcpNIgiCIFomFGKLdZQcpFJ1WpFmykGSsTCTstmsFiTG24TrnfDgUryyeo/yPDWB9DdBEATRMiGBFOuk5AAWK+B1A8f3Scua2UFisdusSGAE0vu3DUcnpuL2s8t2Ko9rBIUkfztUgVvf2ojdRVVN21CCIAiCaAQkkGIdWzyQ2km7rInrIAXCHmdFQrx62uRmJCKvfZJw3Ypap27ZVfN+xIodxZj03s9N1kaCIAiCaCwUA2kJZOT5J6r1E00HKc6KFEccTu/ZHk63F93aJyEjKV64bnmdS7fM6S8+ufdYdUj7LatxwuP1ISvVEXqjCYIgCCJEyEFqCWR0VR9brIA9pdmb8MDF/WGzWvD81UNhsVjwwcTT8cmkkbBaLTheqxdCAFBc2YBap7jKtlEekwiP14cRT67AqU98izqa/40gCIJoBkggtQTS89THjjSASZpuLm47syd+e3gMzugjJY1bLBYlefukrhkAJHfptjN6KO9Zt7cU5zy7GvUuD0qrGzCZCaslhCCQSqsblGlP9paE5jwRBEEQRDhQiK0lwDpIUcw/SrKLT5cp5/ZGQpwNlw7JRY/MFJzeswNue3sTAKC4qgG7i6rxyc+HsPi3o8p7jARSVb0L760/gIsH5Sq5TUcr6pXXD5bVYWCn6IUYCYIgiLYBOUgtAVYgsW5SjJCaEI+7L+iL3tmpsFkt6J6pTdo+XF6L4qp6g3dreWllPp76egfG+4tNAkBhpfre/TTvG0EQBNEMkIPUEsg5EYhLABypwNhZ0W5NUPjK2/tLa3WOUYUggRsANhaUAZCSsmUKGQepoLRWeezyeBFvI41PEARBRB7qXVoCKVnA1C3Anb8CnYZGuzVBSU/Ujmr79WA5DpbVapZVN7jh8nh17+2UnqhZBxA7SKt2FGPgQ8uw0D9J7qwl23HZy2spiZsgCIKICCSQWgqpHQFH849eCwfe1fn690JsLDiuW69S4CJZrWoC+s5CaXLeo+V1yrL9fgfp/97dDKfbi3v8k+S+/t1ebD1UgaV/HAVBEARBNBYSSESTMLJXB+FydvoRUZ2kcqa45LYjlXj8q234/NcjyrLD5XUor3UijhFSIieKIAiCIBoDCSSiSXjr5tPw7bSzdct/nH4e8tpLYbRypn6S2+PFU1/vwPe7S5Rle47V4D9r9+m28cuBcs2kuMeZfCWblU5pgiAIovFQb0I0CfY4K3pnp+Dl60/SLE9NiFdylCrrXPB4fbjlrY3o/a+vMW/NHs26/Mi380/IBgBs2l8GR5ya9F1SrQqkOqcbPp8PH286iJ2FNN8bQRAEER4kkIgm5ZLBnXD7WT01yzISpVFufxypwJs/7MPKHcXC9+4qUotC/jTjfIwekAMA2FRwHA5mPrjSmgblcXWDB99uL8a9C7di7JzvInYcBEEQRNuChvkTTc7kc3vj98MVuHhwLgCgQ4okkP79za6A78svlgRSZooDHdMTMKhzurJc3gagLQNQXe/GriJyjgiCIIjGQQKJaHLSE+Px/sTTlef9OqaG9P6O6dIEtZ0ypNyl0hqnRiDlMxPfVje40D0zWXleWe9CWoJ4Ml2CIAiCMIJCbESzMyA3tOlSclITAADtkuIRb5NGr+1nCkbmF7ECyQ0L1BFuR8vNVfAmCIIgCBYSSESzw86l1iMzGV9OOQMr/nE2MlMcynIbM4w/J10SSBaLBdl+sSRPXgtoHaSqejdqnW7l+eFybYHKSOB0U1kBgiCI1g4JJKLZyUpVhVD/3FQM6pKOXlkp6J2thsY6JKshNNlBAoCcNPW9MqybVN3g1lTTPhxhB+n17/Zg0MPL8PMBfeFLgiAIovVAAomICjeN6AZ7nBV3je6rLLtokJTEnZli17hJcg6S9FgVSyKq692odTEC6XhdgLVDZ9aSHWhwe/HPhVsjul2CIAgitqAkbSIqzLx0IKZf2B+JdrWe0Q3DuyE1IQ6ndm+P8/69Rll+Rp8s5XF2ahCBpHOQtALJ5/Nh5Y5iJMTbMKp3ZtjtpznfCIIgWjcx4SDNnTsX3bt3R0JCAoYPH44NGzYEXL+8vByTJ09Gbm4uHA4H+vbtiyVLliivd+/eHRaLRfc3efJkZZ1zzjlH9/rf/va3JjtGQovNatGII3nZFSd1QZd2Sbjh9K4AgMuGdELnDHUC25y04AKJzUHadqRC8/q0j7bg1gWbcMtbG1Hv0oucbUcq8d76/fB6fQH3w+6DIAiCaH1E3UH68MMPMW3aNMybNw/Dhw/HnDlzMHbsWOzcuRPZ2dm69Z1OJy644AJkZ2dj4cKF6Ny5M/bv34+MjAxlnY0bN8LjUTu/33//HRdccAH+/Oc/a7Y1ceJEPProo8rzpKSkyB8gERZTz++D4T3aY3T/HM1yNtzGkpYQh8p6t18gqd/9nmM1OFbVgKxUB8pqnPjsl8MApCTvmgY3EuK1Iu2iF78HINVWOu+EbJzUtR0AyXlic51qyUEiCIJo1UTdQZo9ezYmTpyIm2++GQMGDMC8efOQlJSE+fPnC9efP38+ysrK8Pnnn2PUqFHo3r07zj77bAwZMkRZJysrCx07dlT+vvrqK/Tq1Qtnn62dGywpKUmzXlpaaMPPiaYjI8mOcSfmIs6mPUU7ZyQx66j1jU7rIU2OW13v1omX9ftKUVxZj2eW7tAsDyRyXlqZjyte+RHHqqQq3W/9WIBz/r1aeb2BRrIRBEG0aqIqkJxOJzZv3ozRo0cry6xWK0aPHo1169YJ37No0SKMGDECkydPRk5ODk488UTMmjVL4xjx+3j33Xdxyy23wGKxaF577733kJmZiRNPPBEzZsxAbW3kh4QTkaVXljrSzWqx4OO/jcBVJ3fBI+MHAgDcXh/K/JPXyqPlNu4rw32fbMX/Nh7UbKuOC7E1uPXn0O+HpRDdI19ui9xBEARBEDFPVENsJSUl8Hg8yMnRhlFycnKwY8cO4Xv27t2LlStX4oYbbsCSJUuQn5+PO+64Ay6XCw899JBu/c8//xzl5eWYMGGCZvn111+Pbt26oVOnTti6dSvuu+8+7Ny5E59++qlwvw0NDWhoUOf8qqysDPFoiUjQnhn+X1bjxKnd2+PU7u3h9fpgsQA+HxTXZ2heBpZvK8L+slqs3nlMt62S6gZ8u70IZ/fNwsBO6SiubNCtU1BagxdX7G66AyIIgiBikqjnIIWK1+tFdnY2Xn/9ddhsNgwbNgyHDx/Gs88+KxRI//3vf3HhhReiU6dOmuW333678njQoEHIzc3F+eefjz179qBXr1667Tz55JN45JFHIn9AREjwLqCM1WpBemI8ymtdysi1nv4pRzYVqDWLzu2XhV1F1ThcXofr31gPAPh+Vwk+uP10FFXqaya9/t1eHK0Q11Ly+XyG7SEIgiBaNlENsWVmZsJms6GoqEizvKioCB07dhS+Jzc3F3379oXNpibX9u/fH4WFhXA6nZp19+/fj2+//Ra33XZb0LYMHz4cAJCfny98fcaMGaioqFD+Dh48KFyPaHoSucRqGba4JCBV6QakkW0AcGr3dnjz5tM0LhQArNtbCgAoEjhIRuKI3W44+HyBR8kRBEEQ0SWqAslut2PYsGFYsWKFsszr9WLFihUYMWKE8D2jRo1Cfn4+vF41SXbXrl3Izc2F3a7t+N58801kZ2fj4osvDtqWX3/9FYAkwEQ4HA6kpaVp/ojocFLXDOHyDsnaEW7spLUAMLiL9D6+vECc1QKP14dCgYMUiHV7SkNaX2bt7hIMe/xbLP39aFjvJwiCIJqeqI9imzZtGt544w0sWLAA27dvx6RJk1BTU4Obb74ZAHDjjTdixowZyvqTJk1CWVkZpk6dil27dmHx4sWYNWuWpsYRIAmtN998EzfddBPi4rSRxD179uCxxx7D5s2bUVBQgEWLFuHGG2/EWWedhcGDBzf9QRON4tk/D8HIXh3w35tO0SzvkKIVyJ3SE2GPU0/xwV2kOeB4B8rt9aG0ugHFAQTSzEsG6Jbd/s5mHCwLPbH/xvnrUVbjxN/e/Rkl1XrXiiAIgog+Uc9Buuaaa3Ds2DHMnDkThYWFGDp0KJYuXaokbh84cABWq9rJ5eXlYdmyZbj77rsxePBgdO7cGVOnTsV9992n2e63336LAwcO4JZbbtHt026349tvv8WcOXNQU1ODvLw8XHXVVXjggQea9mCJiNA5IxHvTzxdt5wPnSU7bMhJc+BgmZSTNDQvAwCQZNeH6I5W1Ad0kAZ1SRcu33OsGnntQ6ufxdagPOXxb/HOrafhTKZaeGuDcrUIgmiJRF0gAcCUKVMwZcoU4WurV6/WLRsxYgR++umngNscM2aMYZ5HXl4e1qxZI3yNaLnwOUhJ9jh0TEvAwbI6ZCTFo6tfyPAhNkASSIe4edtO6JiKk7pmYHCXDCTbxT+V8lpXo9v9/PJdrVYgvbhiN95bvx+f3TEKnZiK6ARBELFO1ENsBBEpOjAT3FosQEK8VZmaZFDndMXFECV5H62ow+6iKs2y9MR4PHnlYFx3WleNqHLEWXHJYClXTa651Bg8rThfe/byXSiqbMDzy3dFuykEQRAhQQKJaDWwIbbEeBssFgv6ZKcCAE7v2UF5TRRi23KwHJX12lFprChiRZUjzqrs63htcIH0xOJteHjRH4avt4URbU4PVR4nCKJlERMhNoKIBGySdnqiNA3J7Wf1xImd0zCqd6byWiITLstJc6CosgErthfrtpcQJxZIcTYr2iVJ+wrmINU0uPHG9/sAAJPO6SWcbNcTZGLc1oC7DRwjQRCtC3KQiFYDO8x/3IlSHa1Euw3n98/RTErLip0zeku5P1WCmkYaB4l57PH6FDEWzEFiayXJj/l85bagHTytOY5IEESrhAQS0WrITlUF0o0juhuux4bYzuqbiWTmeZ/sFOUxK6ribaqq8fp8GgdpR2GlsAp3fnEVPthwQHleUScldPPjueQQ2/JtRVi7u8Sw3S0ZcpAIgmhpUIiNaDW0S7bjuT8PgT3OqlTRFsG6QRlJdvTtmIpfDpQDAK45NQ+PL94OQErylmGHqft8ar7TloMVGDfnewBAwVPagqSjZ3+neV7hH/FmkSeN8+Px+nC0og4T394EANgz6yLYrK1rWLzHSzlIBEG0LMhBIloVVw3rgkuHdAq4DhtiS3HEYcq5vZFst2HWFYMwqHO6cD0WH+Mg1bk8mtdqGtz4ausR1AhCduV1UjiOlz4enw+7i6qV56U1ra94JDlIBEG0NEggEW0ONsSWlhCH8/vn4PdHxuL64V0Nc5VYvD59UUoAcHu8+OfCrZjy/i94fPE23evlioOkXd7g8mLPMVUgFQvmhAuHY1UNGPP8Gvzn+70R2Z5MZb0Ly7cVocHtCb6yHzflIBEE0cIggUS0OTQOUoIUZZZDaKxASjAUSD60S47XLa9p8GDxb9L8ah9s0E9mrAgkzkOqrHdhd7EqkI5VNeBIeR3u+XgL/jhSYeqYRMxdlY9dRdVKyDBS/O2dzZj49ibM/sZ8baO2MFKPIIjWBQkkos3B5hOlJmiFDiueEgT1kgDAB8ARZ0NGkva91U59WI2los4Fn8+nqwlU3eDGrkK1SGVxVT3u+XgLFm4+hKte/THgNgMhCvOFwvPLd2Hy+z/D6/Xh/fUH8MuB4wCAH/2T9P5vo14EsngZUeSmHCSCIFoYlKRNtDm8TIJ0EucSsYnZCXHi+wd51FnvrBRs2n9cWS4aycZSXutEg1svFHw+YMuhcuX5saoGbDkoPa93hS8sGuvZvLBiNwBgWNd2ePQrKWS4ZeYY5fVgeeQuRhRRhI0giJYGOUhEm6NnljrCzcr18g5NQUixApCNkT45qZrlV74S2O0pr3OhzinO23ExCqK4qkHXrh2Flfhyy5GA29e3U6tKqurNzRu3YV8Z7v/sN+U5K/z+s1bNZ7IGmYCWPSYaxUYQREuDHCSizZGbnogvJo9Sqm2zsA6SEbLw6JuTEmRNLUfL6/HAF78HXa+4skE30k0uJdAuyY4z+mTq3ySC0UfvrCvAg1/8gXl/ORnjTswN+LarX1uneV7PjNT7autR5bElmEBi3LJgSdperw81Trcu5EkQBBEtyEEi2iRD8jLQXVAryW5jah/pZIqEbMz05RykYOwsqsJiRmAYcaxa6yC5mJyljQVlpvfHSpKNBVIo8If8UtPvlylhplPZV1KjPA6ijzTtdgpCiyy3LNiIQQ9/g4NltSG3jyAIoikggUQQDIFcEbni9gkdJWHUK0vvIP1pWJew9y27V0WV9ZpRX2yIqzZIIrjP51OSo9lJcEuqpdIBBaU1wvcFoqRKXHYgWA4Sm4zO14viWb3zGADgk58PhdY4giCIJoIEEkEYkJaojUB/csdIXHlSZ7z+11MAAB3TE/DUlYM063TvkBT2/k7r0QEAcOh4HarqVSHElgCoDjIy7e8f/IKz/70KdU6PZo63wgpJZLECqd7lCSq4AFVc8YSSgxRMIJndJkEQRHNBAokgOB65bCCuOrkLzumbrVl+Qsc0zL5mKLoyIuja07ri6lNU1ygzxYG0BH1q30vXnYTZVw8JuN8BuWma+eRk2BIARyvqcaS8DmU14klyv9p6FAfL6rB6Z7EmxHakog4AcPh4HZxuL5xuL87792qMef67oKKrpFraVyp3XG6vD8UBRu6xIbZaJjm9otaFOz/4Bat3FgPQOl2tbYqVWOf3wxX4eNNBzXdAEIQECSSC4LhpZHc8d/UQ3UgyI5IdqnBon2yHPU5fPykx3oYrTw4cfuuY5sCATmm65TuLVIG07UglRs9eg3P/vVqTPA1A18m5GYEilwvw+oBDx2tRWtOAIxX1OHS8Dm98t9dwG4A6yW6Xdlp37FhVA06btQI7CiuFx8PmHTndXiVsOHv5TizacgQT3tyoaRtgzkF6YvE23PW/X6j4ZAS45KW1uHfhVnzfDJMkv7/+AC59aW3QchgEESuQQCKIRpLCCSRRSGpgZ73wOaFjKuZef7LyvEOKAwNy9evtOMoWkWxArdODijoXrnn9JxwoVZOa2RpL//r8d3z9e6GwvftLazUhvA+Zgo+iOk0yXdolCpd/slmcN+TiCmLKgu5weZ1meVWDufID8jbf+H4fPv/1CL7ffcz0+4jA7GRcyqbi/s9+w2+HKzBvzZ4m3xdBRAISSATRSHgHiWXDv87H8rvPQm66JC4yU9QQ2tK7zsKFJ3ZktmPDwE7p4Nl2VOzQbDlYjmtfX6cIMjaMZRSCA6Q8JFYgVTL1kWoN6jQBxgLJYrHg9e/24KNN2sra/Mg1NQ9J6xJVM20Jlqsku1mAVK+JCB/WLTTrlkZmv+bXzS+uopGNRNQggUQQjYQtDdA+2Y7MFEkkndE7E9mpCZqCkneN7gMAuGiQJIysVgsevGQALh3SCWf1ycL5/bNx9SldMLp/Dp77c+CcJQA4UlGP2culOdHMTi1SUFKjyTuqc3mUzjLQNvgQm8zBslrMWrID/1y4VRP2cnG1j+QimXxfzLal1v+4tLpBWBqgvFYVfmvzmz4s1Jz8frgCr6zO1zlvTQUrhuOaWCCxwlY00bPRe0bP/g5nPrOqWXKkfD4fHvrid8z+ZmeT74toGVChSIJoJOxw9rSEeLx182l4b/1+TLugn27d60/rihM7pyulAgDg1jN6KI/jbMAzf1KF0Sur87HnmH5o/hUndcbFg3Jx29ubsH6vVNsokPvDUlBaq3FtfD4ptJZfXB2wtlHnDLGDxDtXWf5Ec76jl90hPs+IbUuN04OjFXU44+lVOKVbO3z4fyM068oT/gLAb4cr4PZ4EWdrHfd5l7y0FoA0zx97TjQVrHPoDjGf60BpLaZ++AtuO6MnLh4cuPAoIOW9hQo7AKCqwY20Ji4iuudYDRas2w8AmDq6Lw0YIMhBIojGwjodVqsFJ3ZOx5NXDlaEAovVasHQvAwkxIsnwuUZx4TgWNon23FS1wwA0oV9Z2EV/rfxQMBtpfpDgWt2HcMXvx7WvPa/DQdwyUtr8cDnxpW+O6SI7/zZjpbNv+In5ZWFlJW56jjdXlSyITanG4u3HoXH68P6fWWaCW8BrUDy+aB5bzjct3Arzn9uNf7z/d7gK0eIilpXwPIKv/rn4WtqKusYYRrixMZPLd2OXw6UY/L7P5ta/2CZmndmVsh72DpeBrW4IklFnepO8gMgiLYJCSSCaCT9BYnVkcJo5Fv7ZDs6pDiQ115ydcbO+Q5v/lAQcFtD/YIKAL7ZVqR57eEvpclofzlQbvj+ZLvYcD7CJF2zAol3kCrrXFi5owjbjqg5VdUNbk2Ircbp0RTrlMsTyJTXaRO62ZCbzIcbD+DOD37B8QB5WBv2lWH2Nzvx4aaD2HOsBo8v3t4sYZxapxtDHv0GJz+23HCdBqZz3nKwHKUGdagaCytsQxVIVSEKU9ZBMlN7S2qT+jmUBvguIwUr3EggEQCF2Aii0Yzun41n/jQYgzrrE6wbS6+sFGSm2FFS7cTIXh3w4x4pnNbBn8cxNK+d5u48EAM6pZkezt0zKxln983SiC6+DpJMUaXagQcSSJv2H8eLK3ZrllXXu1HNdNR1To9mGPi+khpN7hMviFjBtPT3o3h19R5sOVQBAPj5wHF8/89zhdXR+fnmAMnxcghKNEQSeaqWepcXDW6PcH+y8/bLgeO44pUf0T7Zjp8fvCDibalg3LhgtbB42HCXy+NFfJAw56HjoTtI7MTOzeEgse5kfZCpcYi2ATlIBNFILBYLrj4lr8mcpOV3n40PJp6OSwZ3UpbJia5sLlMwMpP1IT8jctMTMKRLhmYZO1rPiJIqVcC43FpHZqNg1FlVg4tzkNyaMgAFJdr8K7YTA6ROvqCkBi6PF39792dFHAFSp3yAGwEVKAG6tqHpXYM4Jr5o5MI0+OtCrdohFdIMNCKxMbAOUqgCKd6mis6j5cHrGrFz+Jl1kNj12PkAm8rdYcV3Q5j7OFxehzW7Wlb5iZ8PHMedH/yCoxXmbrTaEiSQCCLGaZdsx4heHZCTpgocWSAZDb0X0SHFjv/edIqpdZPscbo8qWRHcHelpMY4B+m4IBxWVe9GlWYUm0cTstvLC6Q67TYW/nwI5/x7NSa9u1nYnuOMoPr6t6MYOHMZFhrUbaox2XE3JhTH5qsZCST5c2OTz5uiKGZlXfghNnZUGitCH/j8N9z61kZde3czxU5NO0iMSJHDjB9uPIABM5fi69+CT/rMs2pnsTC/692f9uPq19ZhP1NTjC1eGgqjnlqJm+ZvaFE1uq585Ucs2nIE//rMOP8wVJZvK8KTS7a3+GKuJJAIooWQk5agPJYFUl5783O/tU+24/z+OZhybu+g6ybbbUi0q4Io3mYxFX56bc1ezP5mJ6ob3Lph+qJ6NlKIjRFILjcOM+GYfUEcpMVbpY7y2+3FwvawImDKB7/A6fHino+3CNc103HnF1fhlMe/xevfiYsd/m/DAazaKW4LANS71X1U1okLZMqfGxsYLK3Rh5ieWLwNM7/4HR6vD//bcAB7jlXr1gkEm+AeqoNULhBIPp8P7/50ACt2FOPnA8eZ/bhwpIKZcNmkU8d+H3Lo9r5PfoPXB0x6T0oOL6tx6gqPijhYVoub39yIy+f+oHvtgc9/x4Z9ZfjP2n3KMvZ7CoeWWKOLd2sbw8S3N+G17/biq61HIrbNaEA5SATRQmCLTIblIPlDbKLRdQDQOzsF+f6JcRPtcUiIU++fslMlcXZW3yx8FySE8OLKfLy4Ml+3vEYgQL7bfQzvrVdH35XXujTOSnGlVhjIzkVivM3UBLgVdS4s3HwIA3LTEG+zBLyjNeOi/OOjLSitcWLWkh24/axemtf2HqvG9E9/AwDse/IiYe4TGx6q0pRaUNu1r6QGu4uqtKMDq5zKdwAAx2uceON7qUPvlJGIp77eAQAoeOrioMcgwwq0UAUSm78kCyS2CvsxJmdod5FWuNW6zIbYWAdJHGY85fHl8PqAnx+8IGB9JVZEeby+oEP4GxvGC5aTFYuYHVkbCkdMhF9jmZb3LRJEGyUnzYErT+6MPw/rgowkqTPISjGfV9TeP0w/0+A9g7uoSeYer1fjIPXMSgYAzLlmKP51Uf+Q227E2/66MzJ82KlCN2pNet6tgznn7Itfj+Cej7fgohe/VwSiEa+t2Ws4r5zMb4crDF9j22406opNPK5iBBArLqob3Ljg+e+wl6l/dYxJfvd4fZoO/wcTBTMr6lxo4FwR7Si20AQB+70UV0mdICtoNhaUKcn2cnjN4RfcZhykN77bi8e+2qY8lx0kdqBAvcsDWe+yIyNFsFHR0bPX4J11BQHXbwgzxCZj9x9rZb0LE97coEzHU17rxLfbinTlK0R880chHvtqm2ZOxaaE/b1HCh8oxEYQRDNgsVgw++qheJapsC1yKYyQR76xDlJCvHoJ6JSuulHFVQ1IZO4oe2enAJCcq4ln9Qy4nw8mno4JI7vr9hsK8mGxHbHX61M64+4dkk1t58c9qngIlkO19I9CjJvzvW75rCXbcecHv8Dp9sKoX3t//QFNhy6HE1ftKMbFL36vdODs6KjKeheOVtTB6fYK58D7/YgqxmRH5vnluzDkkW80icBs58/nR/l8PjyxeBtOfmw5+j2wFGc/u0oJe1SE6SD5fD5NiE0up8AmVb/5QwEue1kqfLnL7yANzcvwrxdcID2xZLvmeYnfQXIwriZbkoIXfzxscv6+khq8v+FggLXDc5DYNsgO0n+/34fVO4/hH/6w7r0Lt+K2tzfhVRPz0d3+zmb8d+0+/G9j4LY2BlZ8sdeCUCmtbsBTX+/QhcSboXJGk0ICiSDaAMl2m2KhswKJDdukJap35yXVDRrLvVdWStB9nH9CNj6fPAojenVQiljy+zPiySsHaZ7Lk/ZWN7hxoLQWc1fl4/0NB1BU2YAURxxO6d4u6DYBbWfMFkYMBCsyKupceP27vVi05QiWcInBbo8XJdUNWLz1KO7/7Dds2q/m3cjD2m9+ayP+OFKJKf6CimzH+80fRRjx5Eo8s3SHsINnyyf8c+EW7D1WjRdW7EZ1gxvPLlOnw3B71U6Oz9HaXVyNN77fp4QW95fW4n1/SNOoUGRlvStgInp1g1sTqizz77OOEz5FlQ2od3mwu1hykGSBZDYZnqWwoh4er08zom+dv4I8oE3GF8GHT0UTSrOEk4PEunB2/yg/fsTecn/9Mfb7C8bvAVzLxsJ+no0JC973yW+Yt2YP/jzvx0g0K2YggUQQLZz7LzpBuPyqk7vgipM6A1DDa4BWsCQxtnpaQjz+fp6UwD19XH9tiC1T69jMumIQenDLbji9q9IJdmQSys0IpFO6tdNMc3JCR7VkwuWv/IBnl+1UqnzfdmaPkJLTZQorzeVDsMJkBzNR8JZD5Zr1jte6MOndzcJq0mzdH0DNgWGHj6/wD+P/z9p9QUM6Xh8ww5/fxMN2csVcvSA5WTiT+f7l9VkXqNbpwQcbDmDemj046dHleGjRH8pr89bswfiX1yqOEy/CVAdJLyqOlNdhV5FWINU5PQEFmChPrM7lQX5xtcbB++aPQuVxMMHDO2Sl1Q3weH2GZR/CGcXGijB56ha2NIbP59PMeWc2dMZ/p5GkpDoy5RPW+Z3akmpnsxRcbS5IIBFEC+f2s3phy0NjdMvHD+2EgZ0kocHm3yTbbcqFmq3dlJYYj3+M6YetD4/BGX0yNeKpGyeGrh/eFavuOUdTHDPFoRYPZEfcmcmTykxxaCp1d22fpOSb8HWAzu2XjYzEppuXay8zGmw7I5C2HtLeya/cUYSNBcchgp97TO4wjTpeMyGu9QYjowqZEWJj53yH1cwoOlkg/eX0bvhg4umatvCVxmd8+hue+noHPF6fJjfsqa93YMuhCrz9YwEAfV6YXL5BJJC2Ha1UBOdgv0Bye31KKQOXx4vnvtmJX5hRb0bJ9+w6ALCjUC0dEKiQ5Ls/7ce9C7dqlnl90shAI1EQjlhgc9DkkGkKI5BqnR4lVA1AU7MrEEUmhX04sKMjQ81DY2GFK1veo6WLJRJIBNEKSBcIhmRHnHKBZl0ci8WCn2degI3/Gq1xFuTqyPL/JHsc7jyvN+48r7fhRLVn981SHrMJtB3TVYHkCDI6xma1ID0xXtN5dMpIEB4TAGSnOZQk9VCx26y4a3SfgOvIw+W9Xh9W7VRzfbZwNXTmrTGev+299Qc0+Rgerw/fbisy7PyDJYcHgp+PbsKbG5XHGwskgXRaj/bK9yOXVRDVpQqELOJkB0muy1VV74bL40WdYHTaSr9LlpuegBzmHJTDca+t2YOXVubjilfU0EytgViUSwd0bZ+ky5cJ5CAZzS94rKpBFxaUCctBYsJpcqkGdrRcWY1TI7zMTuDbWAcp0MhNdnRgOKFPGS8jhPjyHmbZWVil5BjGCiSQCKKVkuywYezAjrhheFfccY52SHpaQjyyUh2aRGw2B0lm2ph+mDamn+E+zumnCiT2bpnNX2pwexBoVHWHZDusVgvO6pOpLOvcLhEZSXqBZLFIblOgId2A5JKJaJccj7tG98X8CcYFM/f4R4/du3CrJhman/FeFkD3jOkr3A4bpgKA297eZFgX5rdDxgJp+oXiEGogymqccLq9OOp3lwbkpinfT2FlPS564XvF5RB9zoAUAmJDUK99txfXvLZOESPdOiQr3+vxWqfQQVrtF5h9clIRZ7Mqo7vkdTcwDpwccuK3Iydmy0nZnTL0Vd5LDMoABBIHx6oaDAVrOA4S6wLKIoEVC/xnxIcqA7UzXP67dh8GP7zMcAJkVliGWiyUhTWK2GM2WyfylwPHMXbOd7htwaaw29AUkEAiiFbCAxf3R78cdeoRu82Kdsl2PHHFIJzUVZzUnMDlIIXK0LwMZKc6kJliR3aaOJR2vMaJmZcMwCnd2uGyIdJ0KSN7dVBel6+hZ/RRxVan9EShg9Q+yY54mxXtkuIhGsB3SjfpOO8dKxZ17fzOExvOs3PJqSt2FMHt8WLNLnHBxyH+UJHMmIEdcfHgXN16e4r1hRt3FYmLOf52uFy4PDUhDref2VMztYcZVu0oVkJhFov03bL5MNv8ocN4mwWDObEh89GmQxjx5ErNsvX7ypRQY8e0BMXJO17jUtyYc/plKaUg5PBoN3/OmBy2lZOX2TCfXDWdF0jydDq7/Z9nZooDnbn6X0YOUnWASXWPVTUYjqjjk7RrnW7dCK3qBjfqXR78uKcENQ3agqdymIkdnVha49Q4VryDV+/y4MstR1Ba3aDLT2IFm9vjxa8Hy5WpQSpqXThQKnajHvtqG2qcHjztr5PFwwrLxky1o3GQmLYHmtqH5TW/G8uHsaMNFYokiFbCbWf2xE0ju6PPv74GAKSaEDysOEgLI68nzmbFqnvOgdvrM6y0bbNaMWFUD0wY1QMA8Oj4gUhNiEev+5cAUAsWntQ1A32yU+D2+iQHKVHvEsmhwjibFe2S7Lr8pDdvPhUer88wIVt2nlixkJli11R6PlhWhw82HFA6j7EDc7DsD2n0UWK8DQNy05Rwm9Ui1WRKZbZ32ZBOWLTliKkKz906JGF/aa1SX6lr+yQMzcvAoi2S09QxLQFWqwW56Ym6eeV6ZSUrbhfPrqIqRcilOuJgtVqEkw1nJNnRJztFWPzz/s/ESeEH/aGh7FQHMpLiUVbjxPFap+LGJNltugKmcu2tZHscymtdqKhz4f31BzR1pbYfrUTfnFRdqK5vTqomX6ddkl13LEYCia31xHOs2thB4pPmH/j8d3z2y2EsuPk0nNU3CwfLajFuzndK8dOLB+fizN6qAypykMqqnah1aR0kn8+Hp5buQN/sVDg9XiUR/9tpZ2v2X1hRj+7+PMCPNh1Svpv/3nQK7vvkN5RUN+CH6ecZhsKNahyx+WQ1TjfKa52oqneHPAjCKMQmKl/B4/P58ANTjsPp9ipOY7SJjVYQBBER4m1WvHjdSXj2T4NNjR5j7/bSBB2oGZIdcUK35+XrT8KJndPwwMXawpIZSXZNboZ8EY23WfHl38/AN3efhXibFemC0A8buhOF2VIccchIshvmL7Xzv4dNQM9kPqfzT8gGADz4hRQey2ufiFymPlRuRoImbyuvfRIccTZNeLF7ZrLQ3RIx+Rxp1KCc85Kd6sDJTImETv4OL5fJ6brutDx8MPF0/OX0bpptje6frdSfKqysR4V/3jrZ5XHEWTWjqADJkWNzv8wgOylZqQ60VxwkNXyUGB+ntFumQ4r2c7/q1XU6ASa7WnyycHdugECyI07zeQCSUyVyK4zmuwOkKu1GOUi/HizHGU+vVApK7jhaBZ9PGtEHAAt+LNBUhl+89agmxCaXbWDLNxRV1WvLI9Q48UN+KV5bsxf/+HiLRgDP/0Gd9gRQw3c+n08pmwAAGwrKFHH4Y36JRpywrpNRSJqtpu71Aac/uQJnPrMq6MS1Pp9PcyxegxCbmUl/D5bVab6n8jonvF4f9h6rjnqSNwkkgmhlXDakE/58Sp6pdV1u9QIUF+HpES4Z3Alf/f1MXQcnc+r/t3fvcVHV+f/AX2fu3GaG6zDcREUQL6BA4nj5moqSS66Wu5rZalm5GZSpWWbrZbNv+Kuv5VqU1ZbW9iszW7t4qdCUvpGaoq7X8BqUgpjKReQ+n+8fwzlzzpkZQAVmtPfz8eCxOOfMzDkf2ObN+/P+vD/NvYxGNAclgC0A4vuxOAtyxIGHv9MaJa75mMZpkBIbYpuu8ZVkkOwB0qPDu0uCt9gQP0m2IthXK2lBwE/V+YrOMXip27Ry74+JYRgmquECAK1aIcn88YGG+C/0+wZ2gaV7oEOGcObtMUL/qdKKWiE7wI8jx3GS6wRs9UfiACm9t6nVv97FARIfcF4S1dd4a5QOAQw/xvLMz4DoACHTxU9Jyqe9QmSBvp9OhVCDNACzMmm/oMLSKiz+/LBD1k3swhXXU2wHfinHr5drhECZH8sfTl3ET6WVKHGSoZQGSI4ZpLOy1g+Xr9bjbLn9+sSd1YsuSjODNQ1NKL54FUlLc7E6/2fh8WMl9mBp3vqDGJ+TLwRl4lYTrn6m8gwbH6jnn7zo7HTBvW/vRvqK75wGpeIxFWeQSitqkfnhPuz9WboaU76HYMHPl5G95RhGLM/Dv3ZJO+13NgqQCPkda2uNQEd4fUoy5qXH4f9NSHB6vLUkTEt7R+nUSqfNLfs1BxDeogBJnFWJC9VLArbYUD9JMBXsp8WYPqHC1OSArgEApAGXj5MAQe7FCQn4xz39EOKnlWTutCqlZKoz3Gh7Hb526+GhXdE7zNZaQR5s+GiVQv+p85WOAZL8OgHbOMWIxmn5xH6YkBTe4rXzmQNxBsm2IswWIHhrlAj01UrGNdhP03zN9mvxUiux7hELZo20ZdH4aVH5FFugrzT74aNRSvps8bYcLkVtg63HUvqK7/DeziK8nOu6IeOmgyV4+P2Wi4L5jJc407Im/2fsL7rscK648SYfGIkDBPmUa/nVBkkGS7xvmbyPVnVdI1ZsO+7QEPOQrDfX0ZJKfNTcCFS8ObSrAmx5y4bWHgdsKxB3nr6Ik2VXcOhsBWat3S85Lq6tqmu04vDZCoz4nx0YmL0Nmw6W4E+rdkrOlwdIM///PmGfwSWyhQ6djWqQCPkda+ueZh0h2E+LzOExLo//V2wwXt9xyjal1Lw1hPiDsbXNNfuE6YXNd3mJzfvNeUtW2dk/xHw0Siy6sxeKLlbj+PkrSO0aIPlgC/bTQqHgsH3e7fhgVxEeaJ7SEgcr3loVzAavFvvcaNUKIdsVa/ITunBrVQpJwMRP792b2gWDY4IkzTkdAiSNSliVWFpZK2wo21KAVNvQBH8fDVZO7g+u+XiwX8vBnXgs+OzTsZJKIUukUyuhVHAw6XXC2PF9uMTXzK+aDNXb7rGkOUCQT7GZZdkiH61K0kail1mPoyWVeOu70zhWUonpzbVugOui+LYyG3RosjJUiQIMV1t/iKfFnNUgiXtqAbZA4pIo4BEHNPIAqaa+CY1NjtNNzjqI/33jUXx24JwkE1pd14g56w7g9IVqvDd9gPA7UekiEJL3yAJsvyu/Xq6RbPeyYusJh/o1cYBUfrUed776vdP34LmqowPcv+kvBUiE/I7dnRSBs+U1GNgtsPWTO9nAboHYt3AU/L3VGBwThNX5P+NZUT2TPEDyk334d3OSQeLrcRSiDw/xf4Q5jkNkgDc2PT4UpRW1iAzwFgqmAXuReLjRC0/fYV9+L26S6aNRSj7Ah8cF48n0OLy+/RQ2NW9XIr72HqIASadWOp1iUyo4h/uRrzr01aqEYtzaBiuKL9k+ZFsqvueLlPkMFeA4peVKiJ9O2OCYL2IH7FkXvZdaCJD4Oi/xvfHXz2fbLjb3CeKzKiF+Wvz3XX0dgnhfrUqyv19ipEGoX/rfE7+5rCu6HtV1TZKpr56hfpIGla4Iq9hEGVpxh3bA1oOoVFTrI54OlLcnqK5vanNdG2NwWNZfWduIrcdsqzKfWv8fvPkXW5sLV5mikgrHKcRnNxzGp/t+xew0e1sLZ8X9l6rtr9mWAFWeQRJzd4BEU2yE/I4pFRyeSIv1yAAJsBWXchyHOxPC8OnMQYjwt39Y6kR/yd4/KBobMgdJnpvcxd7aoFuwDxbe2UtynK/L+FtGPAZ1D8TcUfb/8KuVCmEljzjwclVbJK7t8daoEGa0B0gmvQ69wwyS7uLiAClKtGJIq1JIsiyuViUBjjVaPloVdGql0NeI3+JDfJ68iZ+z4t22BEgqBQejlxp9RJ3UeXyAJG5NwPel0ksySLbrMnqrhaxEWaW9LmhkvAmjepngpVZK+mj5NK/K4/0xMRxP3WFv67DXyfRXW8kzbNV1jUIQ4a1R4uGh9o2a/5YRj2gXGdgdhRfw6rYTTreQ4ce8pqEJ6/b+Kjze0oqvmvrGVqecW1Imqpn6+sh5/HLpKh56b6+QgQqSTWOKa6MAW1H2p/ts1/rK1uMtvle5KIPkqoeT+PfwdHMGSdyihKe6xvYW7Y0ySISQm5J4qf6SP/Z2OD6oeyCeHB2LyABvjOvnWFezZ0EaKmsbEBngjQ+bt+FwRhz8uFoZKKlB0ioxpo8ZGw+W4FhJJYY293cyifpEiRt0ipfEa1UKofAZAEwG18GKfKUYH/CF6nUov9qAQmcBkiijkdzFH0vGOo5biJP6HrlAX1tzTx+t40eIV3PhurgGiZ9OlEyxNX/PcRzCjF4481s1SipqcLW5BokPqjiOg69WJXQM538en2cORuH5KgzsFgBL90B0C/LFIx8UtHrtgG2snHV89vdRS4qtq+sbJbVcdyaa8W7+GSgVHKYNisZDQ7uh58ItTjtvL889LmS/EiIMQo+fED+tQ3uK1lTXN0HR1hSSE+L6JgC4561dkqljs8FL0hPp18s1uFRdj6c/PYgwgw53J0W0+b3E91bvosaxrKoWEf7euFLXKKzC6x9lFH5neQ3X2ZW7vVAGiRByU3pkWHf4e6slNSdiHMcha0QPp8ERABi81W3q9yL+UA9xUZ/jJ8sgRQZ444usIShcOkZoIimedhNvlSEJkNS2lgGfPGLBhkcHuewtBdiyf+KWADz+ffi/3sUBkrgo/9OZg5yuMJRnkJ4b1xvHnx+Dx0fY68XEq8jkTTntGSTHjxfxFJv4e762rKSiVmhYKG7FID6XD0YTI42YmBIpBF8jeoYIU28hftoWm2u6OuIv28LGyuxTY3qdGlqVEpseH4ovsoYI98c3xXx4aFesvv82yfOLmhs4Rgfax1mepWqLq3WNLoMNMfHWPwCEGjH5c8XBkVrJSbKbgO3n8NZ3p5F79Dze21mEu9/4AW3Vli1s+P0D+ZV9Bi+1wzUAtsDw6g1sgXKjKEAihNyUQg067P3bKCwa26v1k2+At/raM0g88VSQOLjSSTJI9iCNTxLcFh3gsvu52J+SHds5yFfvibcSaXBS6CsnbnsQFeCNqZZoaFQKSbbILPowyxweg/WPWIR/83VQWc0B1VhRfZOzIm3AXod0trxG2JzVS9TtXDq+zgMMjUqBu/rbguGUaH9Jhu2RYd3xrwcHNN+fxuUWJFYnfXfOlds/xJ2ZPCAKX2QNxjNj4l0upxcHol4aJf4i62El5mzhRM6OU9h4sMTlc3jzx/TExJQI5NybhFX3JWPlPf1bfQ5gX2XIa7IyoecT/++2ulztegUcj69x4qfywo1eLgOhG9lq5UZ5RICUk5OD6Oho6HQ6pKam4scff2zx/PLycmRmZsJsNkOr1SI2NhabN28WjkdHR4PjOIevzMxM4Zza2lpkZmYiMDAQvr6+mDBhAs6fP+/s7QghHkrZ0iZv7SRAVJ/hquGeeMrMVWGpeIpNJ8oMies/nK0easnkAZH4W0Y8PnwoVXhMXssh/mBvS38mjUoh3Kc4iPF1sRkxYGuHwOOnRYb2CMb/PjUcr0xMFI45K9IWv95LXxfim6O2/w6LA01x4OGrcZ2BmZXWA4+PiMFT6T3RTRSUxJp8MbRHMHY8ebvQ+d2Z22NDEOynxeheJiEo4wMkV8XuKqUCCRFGKBSc6wBJFPSolQosHd8Hx58fI6yqFHPWnsJZgHJH71AAwPh+YZiXHoe/DuuGeLMeL/4pERkJZtzRJxRBfs5/X8UampiwyrA9tCWDxDei5DNI4f5ekqllMXcGSG6vQfr4448xZ84crFq1CqmpqVixYgXS09NRWFiIkJAQh/Pr6+sxatQohISEYP369QgPD0dRURGMRqNwzp49e9DUZF/JcPjwYYwaNQp//vOfhcdmz56NTZs24ZNPPoHBYEBWVhbuvvtu5Ofnd+j9EkJuLr5aldDd21VAZvRWY3y/MFgZJCusxMRTCOJyEk70j2v9MOA4Dg+JCocBabACSIO6Fff0w/xPD7a4ATFgr5PRO5naAuDQ50nvZOUdAIcpTD8nRdrya+SJg05OUqTtetrRT6cW7u1PyZHY3rxZLh+4uGpaKr6OH+aPgErBYWD2NlypaxS2oXG2mbOcfF8/njig5FfFaVQKfJ41BDnbT+Klr239mrw1SoeCaVeev6sP/pQcgeE9Q1z+XrZ1Ok/ea4qX0sUf//m1XMg8xpp8HVamjekTitmjYrFi63FsPlTqdJXfsNhgfH/yNyHQ49sY8P8b4e+FaZZoHDlXieQofxRfuoov/nMOl6rrf98B0ssvv4yHH34YDzzwAABg1apV2LRpE959913Mnz/f4fx3330Xly5dwg8//AC12vZ/sOjoaMk5wcHSedhly5ahe/fuGDbMtr9NRUUF3nnnHXz44YcYMWIEAGD16tWIj4/Hrl27MHCg64JNQsjvT6yTFTZiHMdhRSvTGT5aFaakRqG8psFhrzKe0bttH44tiTXZMxC+WpUkoxRv1uPzrCGtvkawnxY/lVZJAh+/FjJIALBl1lCc+a3a6co2nt5FBsnZ9JU4GyP++G9rx/c7+oQK38t/fk/dEYcXv3JsIqlUcEIG0DaVV9fqFJuYVu382sS1ZOWy3kXiQNFPp2rzptFBvlqk9TK1eA6/ArC1GbJAF5nFcH+v5uJy2wss+WNv3Pv2bsk5PloVYk1+kqlZOUv3QKyc3B/fHCnFvPUHUdgcRP3aPLbhRi/4aFXIuTdJeM75ylpsOVyKst/rFFt9fT0KCgqQlpYmPKZQKJCWloadO3c6fc4XX3wBi8WCzMxMmEwm9OnTBy+88IIkYyR/jw8++ADTp08X/lIrKChAQ0OD5H179uyJqKgol+9bV1eHyspKyRchhFyL/76rL3LuTZJkjQDggwdTMaqXSdJb6Xp5i6agxiaaJXVQbcXXS4mDAh/R6zrrZB1v1uMPfc0tvq6rGiR5cTSAG1q1BdiCnd0LRuLjGQMdAqS//ld3bHxsCA7/PR0bH7MHjOKh4rMvBc1tA9oSuLjKIImbK5bLeg8ZvaRBY1s2mW4rjuMkPzdX1xbkIusZatBJCrwt3QIlneYB+ziN7++6A7tep4bBS414s22bnp9Kq8AYE6bYnP3BMNUSjZx7kxzerzO5NUD67bff0NTUBJNJGgWbTCaUlpY6fc7p06exfv16NDU1YfPmzVi4cCGWL1+O559/3un5n332GcrLy3H//fcLj5WWlkKj0Uim5Vp73+zsbBgMBuErMrJte10RQkhrhvQIwttTU5xmZq7HP+7ph4wEM+aPiW/9ZCe6Bdumosyifk6SIm2D6/5MLdHLthrh+ftIg4L03iZJBuh6mfQ6pDrp8aVUcOgTboCvViXJeIkDV3lg4ar+TMxVDZI4QJJnWsQ/c46TBpE6Fxmpa+GqqD1reAwmJEVg3V8tkgySOEg063V4ZFh3AMC4fmHgOA5vT01B5vDuote3/RyTovwl/ajE+GA4JsQXSgWHipoG7Pn5spBJEi9U4Fm6ByIjwdymlaYdxe1TbNfKarUiJCQEb731FpRKJZKTk3H27Fm89NJLWLx4scP577zzDsaMGYOwsDAnr9Z2zzzzDObMmSP8u7KykoIkQohHGtcv3GV7g7aYNiga4UYvjIi3//UurnMJ0V9fUa+40FucIJJPLa6c3F9a7H6D2aS2Et+jOLDQqBStZsf485zRqpRY91cLXsk97tCzK6WLP8b1C8PnB86hf6S/ZMrN31vjtKv1tRDXbOl19n5ScaF+eLK5RQPfiwiwrVz8ubk9QajBC1MGdkH/KCP+q7mfl1LBSbKU4nFyVX/HB8Y6tRJdg3xwsuwK7n17FxqtDP2jjOhl1jt9nru5NUAKCgqCUql0WD12/vx5hIY6/+vBbDZDrVZDqbT/0OPj41FaWor6+npoNPYfUFFREbZu3Yp///vfktcIDQ1FfX09ysvLJVmklt5Xq9VCq22/Sn9CCPFUvlqVw5RJrMkPg7oHIszo1eo+eK4oXbQ9EE8zaVUKh/5PndVPWTx16CsKLD6eMdBliwcxrdL5uGhUCgzoGoCPZjjWt3IchxWT+uGxETGICvDB9sIy4ZjBS33DAZKvKGsXGeCNI+ds5SHiaU3x90ZvDdAcIJkNOqiVCqT3ln4uintUiTNtAS5Ww4mnavk9EhutDHEmP+Tcm3Rd08Cdwa1TbBqNBsnJydi2bZvwmNVqxbZt22CxWJw+Z/DgwTh58iSsVvu86PHjx2E2myXBEWArvA4JCUFGRobk8eTkZKjVasn7FhYWori42OX7EkLI75lSweHDhwfif/6c2PrJLXh7agoWj+0lmdoSf4A6qz3it8LpqM/R16ck4dHbu+P2OPsCH3F37LjQlov0ea6LtFv+qOU4DjEhftDItppxVpsFQGg+2hYDuwUI34trfcTTmtLMmT34ka9W5ImnR8UZJFfTkOKs2NzRcXh8ZA98+HAqvnpiqENHeE/i9im2OXPmYNq0aUhJScGAAQOwYsUKVFdXC6vapk6divDwcGRnZwMAZs6ciddeew2zZs3CY489hhMnTuCFF17A448/Lnldq9WK1atXY9q0aVCppLdpMBjw4IMPYs6cOQgICIBer8djjz0Gi8VCK9gIIaQDjXKy8kol2TDY8TmzRvaAv7e61VVb1+sPfc0OU2i/XLbvR+bdSqEzz1WRtqupN2fEdVriJp8AEGbQYc30AejaSrsCsftSu+DNvNMApBkyV8HXkJhg5J+8CMD16jYvUQZJnGlzPcVmH7/IAG/MEe176MncHiBNmjQJFy5cwKJFi1BaWop+/frhq6++Egq3i4uLoVDYf7kiIyPx9ddfY/bs2UhISEB4eDhmzZqFp59+WvK6W7duRXFxMaZPn+70fV955RUoFApMmDABdXV1SE9Px+uvv95xN0oIIaRVzpJEXhol/jqsu5MjHcek1wnTUW3laqro+gMke8Dx5l+SMbBrIAze17bKjQ9ICoouI7VbIN7bWQTAMUDaNncYjpVUIqOvGZev1sNs0Lnsr+Qqg+Ssn5JOrWiX9hXu4PYACQCysrKQlZXl9NiOHTscHrNYLNi1a1eLrzl69GgwJ23jeTqdDjk5OcjJybmmayWEEHLrWzK2N9RKrl0CM9U1zA0629AXsK3qamuPJLnHR/YAAOQdvyA8Js4CAbYO3nwX7wV/aHn1o6sibXFjypgQX4zvF4Y/p0R2Ssf7juARARIhhBACwKFHlLtEBXrjzb+kXPfzuwf74NSFagDXdk/SlX62ZfVA2/owtWZQ90AM7REk9CO6Xl4ae0ZMXKQtvs8hMUHIGtHjht7H3ShAIoQQ4jHCPbhoty1enJCAn0qr4KNV4tVvT17z88XtDWobmpzWbF0vtVKBfz2Y2vqJrfBSizNIzlfu1dQ7b958M/GIzWoJIYT8vn3wYCqSu/hj5eS27UDvqSbeFolFY3u1eR+0ltQ1Wls/yQ3USnumSH6fmcO7w0+nwszbO7dmrCNQBokQQojbDekRhCE9gtx9Ge1meM8QZG/5SdIz6FrVe2iA5KqhJgDMS++J2Wmxbd4zz5NRgEQIIYS0s1iTH756YqikIea18tQYo2uQD+5MMMPorZZ2PG92KwRHAAVIhBBCSIfoGXp9xdCLx/bCv3YW4Yk0z+wXxHEcXrs3yd2X0eE41tJaeOJSZWUlDAYDKioqoNd75j4yhBBCCJFq6+f3rZEHI4QQQghpRxQgEUIIIYTIUIBECCGEECJDARIhhBBCiAwFSIQQQgghMhQgEUIIIYTIUIBECCGEECJDARIhhBBCiAwFSIQQQgghMhQgEUIIIYTIUIBECCGEECJDARIhhBBCiAwFSIQQQgghMhQgEUIIIYTIqNx9ATcrxhgAoLKy0s1XQgghhJC24j+3+c9xVyhAuk5VVVUAgMjISDdfCSGEEEKuVVVVFQwGg8vjHGsthCJOWa1WnDt3Dn5+fuA4rt1et7KyEpGRkfjll1+g1+vb7XWJIxrrzkHj3HlorDsHjXPn6KhxZoyhqqoKYWFhUChcVxpRBuk6KRQKREREdNjr6/V6+j9eJ6Gx7hw0zp2Hxrpz0Dh3jo4Y55YyRzwq0iaEEEIIkaEAiRBCCCFEhgIkD6PVarF48WJotVp3X8otj8a6c9A4dx4a685B49w53D3OVKRNCCGEECJDGSRCCCGEEBkKkAghhBBCZChAIoQQQgiRoQCJEEIIIUSGAiQPk5OTg+joaOh0OqSmpuLHH3909yXdVL777juMHTsWYWFh4DgOn332meQ4YwyLFi2C2WyGl5cX0tLScOLECck5ly5dwpQpU6DX62E0GvHggw/iypUrnXgXni87Oxu33XYb/Pz8EBISgvHjx6OwsFByTm1tLTIzMxEYGAhfX19MmDAB58+fl5xTXFyMjIwMeHt7IyQkBPPmzUNjY2Nn3opHe+ONN5CQkCA0yrNYLNiyZYtwnMa4Yyxbtgwcx+GJJ54QHqOxbh9LliwBx3GSr549ewrHPWmcKUDyIB9//DHmzJmDxYsXY9++fUhMTER6ejrKysrcfWk3jerqaiQmJiInJ8fp8RdffBErV67EqlWrsHv3bvj4+CA9PR21tbXCOVOmTMGRI0eQm5uLjRs34rvvvsOMGTM66xZuCnl5ecjMzMSuXbuQm5uLhoYGjB49GtXV1cI5s2fPxpdffolPPvkEeXl5OHfuHO6++27heFNTEzIyMlBfX48ffvgB7733HtasWYNFixa545Y8UkREBJYtW4aCggLs3bsXI0aMwLhx43DkyBEANMYdYc+ePXjzzTeRkJAgeZzGuv307t0bJSUlwtf3338vHPOocWbEYwwYMIBlZmYK/25qamJhYWEsOzvbjVd18wLANmzYIPzbarWy0NBQ9tJLLwmPlZeXM61Wyz766CPGGGNHjx5lANiePXuEc7Zs2cI4jmNnz57ttGu/2ZSVlTEALC8vjzFmG1e1Ws0++eQT4Zxjx44xAGznzp2MMcY2b97MFAoFKy0tFc554403mF6vZ3V1dZ17AzcRf39/9s9//pPGuANUVVWxHj16sNzcXDZs2DA2a9Ysxhj9PrenxYsXs8TERKfHPG2cKYPkIerr61FQUIC0tDThMYVCgbS0NOzcudONV3brOHPmDEpLSyVjbDAYkJqaKozxzp07YTQakZKSIpyTlpYGhUKB3bt3d/o13ywqKioAAAEBAQCAgoICNDQ0SMa6Z8+eiIqKkox13759YTKZhHPS09NRWVkpZEiIXVNTE9auXYvq6mpYLBYa4w6QmZmJjIwMyZgC9Pvc3k6cOIGwsDB069YNU6ZMQXFxMQDPG2farNZD/Pbbb2hqapL80AHAZDLhp59+ctNV3VpKS0sBwOkY88dKS0sREhIiOa5SqRAQECCcQ6SsViueeOIJDB48GH369AFgG0eNRgOj0Sg5Vz7Wzn4W/DFic+jQIVgsFtTW1sLX1xcbNmxAr169cODAARrjdrR27Vrs27cPe/bscThGv8/tJzU1FWvWrEFcXBxKSkrw97//HUOHDsXhw4c9bpwpQCKE3JDMzEwcPnxYUkdA2k9cXBwOHDiAiooKrF+/HtOmTUNeXp67L+uW8ssvv2DWrFnIzc2FTqdz9+Xc0saMGSN8n5CQgNTUVHTp0gXr1q2Dl5eXG6/MEU2xeYigoCAolUqHav3z588jNDTUTVd1a+HHsaUxDg0NdSiKb2xsxKVLl+jn4ERWVhY2btyI7du3IyIiQng8NDQU9fX1KC8vl5wvH2tnPwv+GLHRaDSIiYlBcnIysrOzkZiYiH/84x80xu2ooKAAZWVlSEpKgkqlgkqlQl5eHlauXAmVSgWTyURj3UGMRiNiY2Nx8uRJj/udpgDJQ2g0GiQnJ2Pbtm3CY1arFdu2bYPFYnHjld06unbtitDQUMkYV1ZWYvfu3cIYWywWlJeXo6CgQDjn22+/hdVqRWpqaqdfs6dijCErKwsbNmzAt99+i65du0qOJycnQ61WS8a6sLAQxcXFkrE+dOiQJCDNzc2FXq9Hr169OudGbkJWqxV1dXU0xu1o5MiROHToEA4cOCB8paSkYMqUKcL3NNYd48qVKzh16hTMZrPn/U63a8k3uSFr165lWq2WrVmzhh09epTNmDGDGY1GSbU+aVlVVRXbv38/279/PwPAXn75ZbZ//35WVFTEGGNs2bJlzGg0ss8//5wdPHiQjRs3jnXt2pXV1NQIr3HHHXew/v37s927d7Pvv/+e9ejRg02ePNldt+SRZs6cyQwGA9uxYwcrKSkRvq5evSqc88gjj7CoqCj27bffsr179zKLxcIsFotwvLGxkfXp04eNHj2aHThwgH311VcsODiYPfPMM+64JY80f/58lpeXx86cOcMOHjzI5s+fzziOY9988w1jjMa4I4lXsTFGY91e5s6dy3bs2MHOnDnD8vPzWVpaGgsKCmJlZWWMMc8aZwqQPMyrr77KoqKimEajYQMGDGC7du1y9yXdVLZv384AOHxNmzaNMWZb6r9w4UJmMpmYVqtlI0eOZIWFhZLXuHjxIps8eTLz9fVler2ePfDAA6yqqsoNd+O5nI0xALZ69WrhnJqaGvboo48yf39/5u3tze666y5WUlIieZ2ff/6ZjRkzhnl5ebGgoCA2d+5c1tDQ0Ml347mmT5/OunTpwjQaDQsODmYjR44UgiPGaIw7kjxAorFuH5MmTWJms5lpNBoWHh7OJk2axE6ePCkc96Rx5hhjrH1zUoQQQgghNzeqQSKEEEIIkaEAiRBCCCFEhgIkQgghhBAZCpAIIYQQQmQoQCKEEEIIkaEAiRBCCCFEhgIkQgghhBAZCpAIIaSd7NixAxzHOewlRQi5+VCARAghhBAiQwESIYQQQogMBUiEkFuG1WpFdnY2unbtCi8vLyQmJmL9+vUA7NNfmzZtQkJCAnQ6HQYOHIjDhw9LXuPTTz9F7969odVqER0djeXLl0uO19XV4emnn0ZkZCS0Wi1iYmLwzjvvSM4pKChASkoKvL29MWjQIBQWFnbsjRNC2h0FSISQW0Z2djbef/99rFq1CkeOHMHs2bNx3333IS8vTzhn3rx5WL58Ofbs2YPg4GCMHTsWDQ0NAGyBzcSJE3HPPffg0KFDWLJkCRYuXIg1a9YIz586dSo++ugjrFy5EseOHcObb74JX19fyXU8++yzWL58Ofbu3QuVSoXp06d3yv0TQtoPbVZLCLkl1NXVISAgAFu3boXFYhEef+ihh3D16lXMmDEDw4cPx9q1azFp0iQAwKVLlxAREYE1a9Zg4sSJmDJlCi5cuIBvvvlGeP5TTz2FTZs24ciRIzh+/Dji4uKQm5uLtLQ0h2vYsWMHhg8fjq1bt2LkyJEAgM2bNyMjIwM1NTXQ6XQdPAqEkPZCGSRCyC3h5MmTuHr1KkaNGgVfX1/h6/3338epU6eE88TBU0BAAOLi4nDs2DEAwLFjxzB48GDJ6w4ePBgnTpxAU1MTDhw4AKVSiWHDhrV4LQkJCcL3ZrMZAFBWVnbD90gI6Twqd18AIYS0hytXrgAANm3ahPDwcMkxrVYrCZKul5eXV5vOU6vVwvccxwGw1UcRQm4elEEihNwSevXqBa1Wi+LiYsTExEi+IiMjhfN27dolfH/58mUcP34c8fHxAID4+Hjk5+dLXjc/Px+xsbFQKpXo27cvrFarpKaJEHJrogwSIeSW4OfnhyeffBKzZ8+G1WrFkCFDUFFRgfz8fOj1enTp0gUA8NxzzyEwMBAmkwnPPvssgoKCMH78eADA3Llzcdttt2Hp0qWYNGkSdu7ciddeew2vv/46ACA6OhrTpk3D9OnTsXLlSiQmJqKoqAhlZWWYOHGiu26dENIBKEAihNwyli5diuDgYGRnZ+P06dMwGo1ISkrCggULhCmuZcuWYdasWThx4gT69euHL7/8EhqNBgCQlJSEdevWYdGiRVi6dCnMZjOee+453H///cJ7vPHGG1iwYAEeffRRXLx4EVFRUViwYIE7bpcQ0oFoFRsh5HeBX2F2+fJlGI1Gd18OIcTDUQ0SIYQQQogMBUiEEEIIITI0xUYIIYQQIkMZJEIIIYQQGQqQCCGEEEJkKEAihBBCCJGhAIkQQgghRIYCJEIIIYQQGQqQCCGEEEJkKEAihBBCCJGhAIkQQgghRIYCJEIIIYQQmf8DIjAPcgreq7UAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KkK9YhY8cczF"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1guXfL9SyOD",
        "outputId": "9ec4bc64-1a77-4be6-9feb-25e84ef919ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (Batch  (None, 1, 16)             64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 1, 8)              800       \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 1, 8)              32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1)                 40        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 938 (3.66 KB)\n",
            "Trainable params: 890 (3.48 KB)\n",
            "Non-trainable params: 48 (192.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2a5getG25JS",
        "outputId": "8200503d-6115-4b09-e594-eae6f7203ad7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cp.ckpt.index', 'checkpoint', 'cp.ckpt.data-00000-of-00001']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "-iQpmPMW2ud1"
      },
      "outputs": [],
      "source": [
        "# demonstrate prediction\n",
        "\n",
        "x_input = testing_data[feature_name].to_numpy()[0]\n",
        "x_input = x_input.reshape((1, 1, feature_num))\n",
        "yhat = model.predict(x_input, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzspljmm2uhY",
        "outputId": "a6a0500b-ebac-48bd-b626-341ea4fb8975"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.44045895]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "yhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ssU8UTs_48U",
        "outputId": "e4343705-ecf1-4adc-8d60-4c19bf26385c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.4522057 , -0.47984764,  0.46191893, -1.24162677,\n",
              "          0.03392359,  0.45767058,  0.04107991,  1.78423152,\n",
              "         -0.38767234, -1.25416297,  0.04493209, -0.38210972,\n",
              "          0.90044276, -0.11761674, -0.60463932, -0.00439272]]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "x_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Fry09GnP__Cb"
      },
      "outputs": [],
      "source": [
        "y_input = testing_data['direction'].to_numpy()[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOuZCTsCAL00",
        "outputId": "6acd1bc0-8ccb-45e5-c34e-19e74dc345a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "y_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl6UT9mhB2vi"
      },
      "source": [
        "#### 4.4 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRoaIwI6AMvt",
        "outputId": "23cc3b18-f538-4c0a-e288-9c645c10536a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 [==============================] - 0s 2ms/step - loss: 0.6888 - accuracy: 0.5517\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6888299584388733, 0.5517075657844543]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "model.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fgQQwM9xE0Nh",
        "outputId": "7d893b9b-5d9b-405f-8412-0d7909fbb62b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2079"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "y_test.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2drk87NBpPW",
        "outputId": "c80ea2bd-8e38-4c7d-fffc-ec5be051df15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Groundtruth: 1, Prediction: 0.4404589533805847\n",
            "1 Groundtruth: 1, Prediction: 0.5810912847518921\n",
            "2 Groundtruth: 1, Prediction: 0.3925958573818207\n",
            "3 Groundtruth: 0, Prediction: 0.6724091172218323\n",
            "4 Groundtruth: 1, Prediction: 0.5592527389526367\n",
            "5 Groundtruth: 0, Prediction: 0.42915162444114685\n",
            "6 Groundtruth: 1, Prediction: 0.41476917266845703\n",
            "7 Groundtruth: 0, Prediction: 0.5488376617431641\n",
            "8 Groundtruth: 1, Prediction: 0.582677960395813\n",
            "9 Groundtruth: 1, Prediction: 0.5542317628860474\n"
          ]
        }
      ],
      "source": [
        "y_predict = []\n",
        "for i in range(10):\n",
        "  y_hat = model.predict(x_test[i].reshape((1, 1, feature_num)), verbose=0)\n",
        "  print('{} Groundtruth: {}, Prediction: {}'.format(i, y_test[i], y_hat[0][0]))\n",
        "  y_predict.append(y_hat[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_training_predict = []\n",
        "for i in range(10):\n",
        "  y_hat = model.predict(x[i].reshape((1, 1, feature_num)), verbose=0)\n",
        "  print('{} Groundtruth: {}, Prediction: {}'.format(i, y[i], y_hat[0][0]))\n",
        "  y_training_predict.append(y_hat[0][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHRO0ZpckC30",
        "outputId": "27cb64cb-7a2e-4291-eb07-cbb7fb444dc7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 Groundtruth: 1, Prediction: 0.5340666770935059\n",
            "1 Groundtruth: 1, Prediction: 0.5546633005142212\n",
            "2 Groundtruth: 0, Prediction: 0.5852945446968079\n",
            "3 Groundtruth: 1, Prediction: 0.4988904893398285\n",
            "4 Groundtruth: 1, Prediction: 0.6393535137176514\n",
            "5 Groundtruth: 1, Prediction: 0.2579743564128876\n",
            "6 Groundtruth: 1, Prediction: 0.5477629899978638\n",
            "7 Groundtruth: 0, Prediction: 0.658052921295166\n",
            "8 Groundtruth: 1, Prediction: 0.5492590069770813\n",
            "9 Groundtruth: 0, Prediction: 0.36829233169555664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHNGiS0vElZ9",
        "outputId": "d40330f4-a7e9-49f0-c22c-b00dbdfa3ea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Close             -0.03723\n",
              "Volume           -0.671208\n",
              "return            0.847462\n",
              "lag_1            -0.373449\n",
              "lag_2            -0.370068\n",
              "lag_3            -1.548071\n",
              "lag_4             1.221172\n",
              "lag_5             3.369552\n",
              "lag_6            -1.219573\n",
              "lag_7              0.04323\n",
              "lag_8            -0.372693\n",
              "lag_9             1.307025\n",
              "lag_10           -0.802315\n",
              "momentum         -0.106133\n",
              "volatility        0.444832\n",
              "distance          0.705628\n",
              "data_type     testing_data\n",
              "ticker              AAV.BK\n",
              "direction                1\n",
              "Name: 2024-03-21, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "testing_data.iloc[14]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbRm0tUrHlaU",
        "outputId": "b925e919-ca84-406f-cb68-1d12ecf6988a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Close            -0.155794\n",
              "Volume           -0.576198\n",
              "return           -0.381111\n",
              "lag_1            -0.370068\n",
              "lag_2            -1.549329\n",
              "lag_3             1.219158\n",
              "lag_4             3.335776\n",
              "lag_5             -1.21702\n",
              "lag_6             0.051037\n",
              "lag_7             -0.37449\n",
              "lag_8             1.308623\n",
              "lag_9            -0.803466\n",
              "lag_10            0.893071\n",
              "momentum          1.061379\n",
              "volatility        2.488042\n",
              "distance          0.431586\n",
              "data_type     testing_data\n",
              "ticker              AAV.BK\n",
              "direction                1\n",
              "Name: 2024-03-20, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "testing_data.iloc[13]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "mGU4kVNhJQct"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISdWlD4lySxR"
      },
      "source": [
        "### 4.5 Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "liyf-fOPyaoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5005862-0a96-4720-ee59-8115c0a0d437"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['cp.ckpt.index', 'checkpoint', 'cp.ckpt.data-00000-of-00001']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "os.listdir(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Jju_jLNFROGK"
      },
      "outputs": [],
      "source": [
        "latest = tf.train.latest_checkpoint(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "nXj440Yhz8d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74c89f25-7386-44b1-c16e-b52a9114755c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:5818: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 - 1s - loss: 0.6888 - accuracy: 0.5517 - 852ms/epoch - 13ms/step\n",
            "Restored model, accuracy: 55.17%\n"
          ]
        }
      ],
      "source": [
        "# Create a new model instance\n",
        "new_model = sequence_model(learning_rate, feature_num)\n",
        "\n",
        "# Load the previously saved weights\n",
        "new_model.load_weights(latest)\n",
        "\n",
        "# Re-evaluate the model\n",
        "loss, acc = new_model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "OWonqpYyRUuG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ddf0672e-8f7c-40aa-ff80-1147a4cf1dc8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 264ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5810913]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "new_model.predict(x_test[1].reshape(1, 1, feature_num))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKVo_sqaT3gG"
      },
      "source": [
        "#### 4.6 Save entire model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biBUEh8WT8r-"
      },
      "source": [
        "Call model.save to save a model's architecture, weights, and training configuration in a single file/folder. This allows you to export a model so it can be used without access to the original Python code*. Since the optimizer-state is recovered, you can resume training from exactly where you left off.\n",
        "\n",
        "An entire model can be saved in two different file formats (SavedModel and HDF5). The TensorFlow SavedModel format is the default file format in TF2.x. However, models can be saved in HDF5 format. More details on saving entire models in the two file formats is described below.\n",
        "\n",
        "Saving a fully-functional model is very usefulâ€”you can load them in TensorFlow.js (Saved Model, HDF5) and then train and run them in web browsers, or convert them to run on mobile devices using TensorFlow Lite (Saved Model, HDF5)\n",
        "\n",
        "*Custom objects (e.g. subclassed models or layers) require special attention when saving and loading. See the Saving custom objects section below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ud0BNovrTKxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12e3fa2f-f04a-48fa-b4ac-081563b1e1b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('lstm_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZS4qljXkUMHS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4de0a18-81e6-4413-b86c-d4c0ae8e0893"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " batch_normalization (Batch  (None, 1, 16)             64        \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 1, 8)              800       \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 1, 8)              32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 1)                 40        \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 938 (3.66 KB)\n",
            "Trainable params: 890 (3.48 KB)\n",
            "Non-trainable params: 48 (192.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Recreate the exact same model, including its weights and the optimizer\n",
        "new_model_2 = tf.keras.models.load_model('lstm_model.h5')\n",
        "\n",
        "# Show the model architecture\n",
        "new_model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "-aq4lQVwUS8R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0c0857-5cfc-403f-c37e-54c700f6d34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65/65 - 0s - loss: 0.6888 - accuracy: 0.5517 - 469ms/epoch - 7ms/step\n",
            "Restored model, accuracy: 55.17%\n"
          ]
        }
      ],
      "source": [
        "# Re-evaluate the model\n",
        "loss, acc = new_model_2.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"Restored model, accuracy: {:5.2f}%\".format(100 * acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "vuCOzsueUXtR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68e03848-fce7-4986-82e0-416e1a40d39c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 270ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5810913]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "new_model_2.predict(x_test[1].reshape(1, 1, feature_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "n5PMeM3QUaOo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184fe0be-4d76-4e11-d283-43e4cc80fc7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.43952834, -0.66675257, -0.24400217, -0.00720878, -0.23854902,\n",
              "        -0.01423099, -0.25013675, -0.0199213 ,  0.45234521,  0.21352479,\n",
              "        -0.26163919, -0.49981088, -0.02946479, -0.38046786, -1.83491229,\n",
              "        -0.29548628]])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "x_test[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "EhaNsyMyNLkS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2388f92f-c6df-4b25-f0d5-3838bd32857f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5351146]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "new_model_2.predict(x_test[-1].reshape(1, 1, feature_num))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "cX-lSWJfNSOv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}